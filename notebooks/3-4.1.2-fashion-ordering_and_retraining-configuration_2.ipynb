{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f216e2a2",
   "metadata": {},
   "source": [
    "# Ordering by metrics and retraining phase\n",
    "\n",
    "## Dataset: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790af13b",
   "metadata": {},
   "source": [
    "## Experiment configuration 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1386e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0aa2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ == '2.5.0' # Version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa923a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\guided-retraining\\utils\n"
     ]
    }
   ],
   "source": [
    "cd ../utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723735cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "keras\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# utils for project\n",
    "import utils_guided_retraining2 as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6a307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd '../notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1bd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fashion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2b3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/fashion/x_train.npy\n",
      "x_set len:  48999\n",
      "D:/guided-retraining/data/fashion/y_train.npy\n",
      "y_set len:  48999\n",
      "D:/guided-retraining/data/fashion/x_val.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/fashion/y_val.npy\n",
      "y_set len:  14000\n",
      "D:/guided-retraining/data/fashion/x_test.npy\n",
      "x_set len:  7001\n",
      "D:/guided-retraining/data/fashion/y_test.npy\n",
      "y_set len:  7001\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = utils.get_data(dataset,\"Train\",True)\n",
    "x_val,y_val = utils.get_data(dataset,\"Val\",True)\n",
    "x_test,y_test = utils.get_data(dataset,\"Test\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f6f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary.npy\n",
      "x_set len:  55998\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary_labels.npy\n",
      "y_set len:  55998\n"
     ]
    }
   ],
   "source": [
    "x_train_and_adversary,y_train_and_adversary = utils.get_data(dataset,\"Train_and_adversary\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dcdf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_training = x_train_and_adversary[len(x_train):]\n",
    "print(len(x_adversary_training))\n",
    "y_adversary_training = y_train_and_adversary[len(y_train):]\n",
    "\n",
    "print(len(y_adversary_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8fd2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "y_set len:  14000\n"
     ]
    }
   ],
   "source": [
    "# Obtaining adversarial examples for testing \n",
    "x_test_and_adversary,y_test_and_adversary = utils.get_adversarial_data(dataset,'Test_adversarial',True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27698e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_test = x_test_and_adversary[len(x_test):]\n",
    "print(len(x_adversary_test))\n",
    "y_adversary_test = y_test_and_adversary[len(y_test):]\n",
    "\n",
    "print(len(y_adversary_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b185436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del x_train, x_test, x_val\n",
    "#del x_test_and_adversary, y_test_and_adversary\n",
    "#del x_adversary_test,y_adversary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2bff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb4e3b",
   "metadata": {},
   "source": [
    "## ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1560941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model \n",
    "\n",
    "model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06/\"\n",
    "if(dataset == 'gtsrb'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06\"\n",
    "elif(dataset == 'intel'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/intel_model_21_10\"\n",
    "elif(dataset == 'mnist'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/models2\"\n",
    "elif(dataset == 'cifar'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/model_02\"\n",
    "elif(dataset == 'fashion'):\n",
    "    model_dir = \"D:/guided-retraining/models/model_fashion_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5478616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "Model loaded correctly\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "model_original = utils.My_model(dataset,True, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f5589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea0bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55998, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_and_adversary.shape)\n",
    "len(x_train_and_adversary)//20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983373d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = 2800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edd1c7",
   "metadata": {},
   "source": [
    "## Loading LSA and DSA values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd62896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/lsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe684c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_values = np.load(lsa_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ec186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtaining top n images by LSA values\n",
    "top_images_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),x_train_and_adversary)\n",
    "top_labels_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),y_train_and_adversary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262a4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_lsa = []\n",
    "label_sets_lsa = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_lsa)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_lsa)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_lsa)%m))\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m])\n",
    "    image_sets_lsa.append(top_images_by_lsa_n)\n",
    "    label_sets_lsa.append(top_labels_by_lsa_n)\n",
    "    print(len(top_images_by_lsa_n))\n",
    "    n += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55e3a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55998"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_lsa[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a68e",
   "metadata": {},
   "source": [
    "## Training guided by LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa4de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_sets_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daef1b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_lsa = []\n",
    "for i in range(len(label_sets_lsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_lsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50f907b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 7ms/step - loss: 0.2254 - accuracy: 0.9190\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.2254 - accuracy: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2253975123167038, 0.9190115928649902]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[-1].evaluate(x_test,y_test)\n",
    "models_lsa[0].evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dad30810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 4s 8ms/step - loss: 0.5032 - accuracy: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5032416582107544, 0.8342142701148987]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[1].evaluate(x_test_and_adversary,y_test_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5e6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 3s 8ms/step - loss: 0.5032 - accuracy: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5032416582107544, 0.8342142701148987]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[0].evaluate(x_test_and_adversary,y_test_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3665e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 6s 115ms/step - loss: 0.4617 - accuracy: 0.8643 - val_loss: 0.2832 - val_accuracy: 0.8894\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 119ms/step - loss: 0.3073 - accuracy: 0.8982 - val_loss: 0.2828 - val_accuracy: 0.8910\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.2417 - accuracy: 0.9189 - val_loss: 0.3025 - val_accuracy: 0.8869\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 121ms/step - loss: 0.2407 - accuracy: 0.9171 - val_loss: 0.3039 - val_accuracy: 0.8846\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 5s 124ms/step - loss: 0.2127 - accuracy: 0.9293 - val_loss: 0.3117 - val_accuracy: 0.8852\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 117ms/step - loss: 0.1928 - accuracy: 0.9307 - val_loss: 0.3125 - val_accuracy: 0.8877\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 5s 117ms/step - loss: 0.1692 - accuracy: 0.9436 - val_loss: 0.3277 - val_accuracy: 0.8862\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.1483 - accuracy: 0.9482 - val_loss: 0.3351 - val_accuracy: 0.8873\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 117ms/step - loss: 0.1508 - accuracy: 0.9529 - val_loss: 0.3422 - val_accuracy: 0.8862\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.1418 - accuracy: 0.9529 - val_loss: 0.3383 - val_accuracy: 0.8863\n",
      "Duration: 0:00:52.420279\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7687bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 4s 8ms/step - loss: 0.4196 - accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.419632226228714, 0.8682857155799866]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[0].evaluate(x_test_and_adversary,y_test_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f79099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 0.2222 - accuracy: 0.9289 - val_loss: 0.2909 - val_accuracy: 0.8912\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 7s 85ms/step - loss: 0.1661 - accuracy: 0.9498 - val_loss: 0.3149 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 0.1414 - accuracy: 0.9582 - val_loss: 0.3135 - val_accuracy: 0.8812\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.1130 - accuracy: 0.9638 - val_loss: 0.3318 - val_accuracy: 0.8803\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.1092 - accuracy: 0.9659 - val_loss: 0.3360 - val_accuracy: 0.8794\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 7s 85ms/step - loss: 0.0896 - accuracy: 0.9716 - val_loss: 0.3527 - val_accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 7s 85ms/step - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.3811 - val_accuracy: 0.8734\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.4034 - val_accuracy: 0.8712\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 7s 86ms/step - loss: 0.0763 - accuracy: 0.9770 - val_loss: 0.4109 - val_accuracy: 0.8686\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 7s 85ms/step - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.4162 - val_accuracy: 0.8695\n",
      "Duration: 0:01:15.913650\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9f7fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 77ms/step - loss: 0.1984 - accuracy: 0.9379 - val_loss: 0.2898 - val_accuracy: 0.8892\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.1428 - accuracy: 0.9549 - val_loss: 0.3214 - val_accuracy: 0.8772\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.1252 - accuracy: 0.9620 - val_loss: 0.3774 - val_accuracy: 0.8691\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.1191 - accuracy: 0.9645 - val_loss: 0.3437 - val_accuracy: 0.8761\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.1025 - accuracy: 0.9685 - val_loss: 0.3395 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.0925 - accuracy: 0.9725 - val_loss: 0.3749 - val_accuracy: 0.8712\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.0850 - accuracy: 0.9717 - val_loss: 0.4060 - val_accuracy: 0.8689\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.0809 - accuracy: 0.9768 - val_loss: 0.4214 - val_accuracy: 0.8672\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.0818 - accuracy: 0.9750 - val_loss: 0.4053 - val_accuracy: 0.8722\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.0815 - accuracy: 0.9767 - val_loss: 0.4381 - val_accuracy: 0.8686\n",
      "Duration: 0:01:40.573514\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f1f84df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 13s 71ms/step - loss: 0.1515 - accuracy: 0.9544 - val_loss: 0.3158 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.1177 - accuracy: 0.9654 - val_loss: 0.3295 - val_accuracy: 0.8774\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.1075 - accuracy: 0.9706 - val_loss: 0.3223 - val_accuracy: 0.8809\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.0957 - accuracy: 0.9723 - val_loss: 0.3459 - val_accuracy: 0.8743\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.0883 - accuracy: 0.9745 - val_loss: 0.3966 - val_accuracy: 0.8734\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 14s 78ms/step - loss: 0.0841 - accuracy: 0.9764 - val_loss: 0.4113 - val_accuracy: 0.8661\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.0897 - accuracy: 0.9771 - val_loss: 0.4312 - val_accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.0817 - accuracy: 0.9790 - val_loss: 0.4065 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.0776 - accuracy: 0.9781 - val_loss: 0.4682 - val_accuracy: 0.8541\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.0863 - accuracy: 0.9757 - val_loss: 0.5499 - val_accuracy: 0.8429\n",
      "Duration: 0:02:08.060515\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23e0459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.2243 - accuracy: 0.9268 - val_loss: 0.3322 - val_accuracy: 0.8781\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.1920 - accuracy: 0.9402 - val_loss: 0.3482 - val_accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1863 - accuracy: 0.9435 - val_loss: 0.3785 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1765 - accuracy: 0.9441 - val_loss: 0.3978 - val_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.1726 - accuracy: 0.9483 - val_loss: 0.4583 - val_accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1671 - accuracy: 0.9486 - val_loss: 0.4604 - val_accuracy: 0.8544\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1634 - accuracy: 0.9505 - val_loss: 0.4507 - val_accuracy: 0.8443\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1681 - accuracy: 0.9502 - val_loss: 0.4945 - val_accuracy: 0.8307\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1695 - accuracy: 0.9512 - val_loss: 0.4535 - val_accuracy: 0.8401\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1665 - accuracy: 0.9516 - val_loss: 0.4858 - val_accuracy: 0.8366\n",
      "Duration: 0:02:28.788588\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4eccb083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 18s 66ms/step - loss: 0.2247 - accuracy: 0.9334 - val_loss: 0.3302 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 17s 66ms/step - loss: 0.1985 - accuracy: 0.9422 - val_loss: 0.3460 - val_accuracy: 0.8708\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.1969 - accuracy: 0.9432 - val_loss: 0.4124 - val_accuracy: 0.8499\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.1907 - accuracy: 0.9465 - val_loss: 0.4751 - val_accuracy: 0.8370\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.1928 - accuracy: 0.9473 - val_loss: 0.4664 - val_accuracy: 0.8361\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.1930 - accuracy: 0.9461 - val_loss: 0.4846 - val_accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.1909 - accuracy: 0.9480 - val_loss: 0.5185 - val_accuracy: 0.8019\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.1943 - accuracy: 0.9496 - val_loss: 0.4911 - val_accuracy: 0.8234\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 18s 69ms/step - loss: 0.2025 - accuracy: 0.9485 - val_loss: 0.5796 - val_accuracy: 0.7796\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.2099 - accuracy: 0.9473 - val_loss: 0.5902 - val_accuracy: 0.7756\n",
      "Duration: 0:03:07.556729\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c148cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 22s 69ms/step - loss: 0.2368 - accuracy: 0.9286 - val_loss: 0.3281 - val_accuracy: 0.8759\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 21s 69ms/step - loss: 0.2139 - accuracy: 0.9351 - val_loss: 0.3650 - val_accuracy: 0.8693\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 21s 70ms/step - loss: 0.2100 - accuracy: 0.9370 - val_loss: 0.3870 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 22s 71ms/step - loss: 0.2143 - accuracy: 0.9402 - val_loss: 0.4120 - val_accuracy: 0.8469\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 22s 71ms/step - loss: 0.2119 - accuracy: 0.9409 - val_loss: 0.4153 - val_accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 25s 80ms/step - loss: 0.2160 - accuracy: 0.9401 - val_loss: 0.5015 - val_accuracy: 0.8341\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 24s 79ms/step - loss: 0.2094 - accuracy: 0.9412 - val_loss: 0.4934 - val_accuracy: 0.8161\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 0.2186 - accuracy: 0.9424 - val_loss: 0.5432 - val_accuracy: 0.8111\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 26s 86ms/step - loss: 0.2154 - accuracy: 0.9424 - val_loss: 1.0369 - val_accuracy: 0.7433\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 24s 79ms/step - loss: 0.2229 - accuracy: 0.9420 - val_loss: 0.8458 - val_accuracy: 0.7123\n",
      "Duration: 0:03:52.770566\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e472398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 26s 71ms/step - loss: 0.2276 - accuracy: 0.9329 - val_loss: 0.3442 - val_accuracy: 0.8709\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2066 - accuracy: 0.9399 - val_loss: 0.3697 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 24s 70ms/step - loss: 0.2020 - accuracy: 0.9408 - val_loss: 0.4195 - val_accuracy: 0.8504\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 24s 70ms/step - loss: 0.2086 - accuracy: 0.9406 - val_loss: 0.4276 - val_accuracy: 0.8493\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2121 - accuracy: 0.9404 - val_loss: 0.5097 - val_accuracy: 0.8189\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.2160 - accuracy: 0.9413 - val_loss: 0.5070 - val_accuracy: 0.8131\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.2173 - accuracy: 0.9423 - val_loss: 0.5934 - val_accuracy: 0.7849\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2182 - accuracy: 0.9413 - val_loss: 0.6816 - val_accuracy: 0.7748\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2251 - accuracy: 0.9408 - val_loss: 0.5873 - val_accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2291 - accuracy: 0.9409 - val_loss: 0.6925 - val_accuracy: 0.7493\n",
      "Duration: 0:04:07.378189\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5cdc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 28s 69ms/step - loss: 0.2100 - accuracy: 0.9405 - val_loss: 0.3142 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 27s 68ms/step - loss: 0.1926 - accuracy: 0.9446 - val_loss: 0.4064 - val_accuracy: 0.8492\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.1932 - accuracy: 0.9475 - val_loss: 0.4355 - val_accuracy: 0.8369\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2029 - accuracy: 0.9462 - val_loss: 0.4717 - val_accuracy: 0.8176\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.1974 - accuracy: 0.9471 - val_loss: 0.9350 - val_accuracy: 0.7751\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2031 - accuracy: 0.9479 - val_loss: 0.5132 - val_accuracy: 0.8046\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2085 - accuracy: 0.9452 - val_loss: 0.6907 - val_accuracy: 0.7674\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2167 - accuracy: 0.9456 - val_loss: 0.6354 - val_accuracy: 0.7626\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2127 - accuracy: 0.9461 - val_loss: 0.7889 - val_accuracy: 0.7473\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 27s 69ms/step - loss: 0.2239 - accuracy: 0.9437 - val_loss: 0.7576 - val_accuracy: 0.6958\n",
      "Duration: 0:04:32.080816\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6edd628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.1974 - accuracy: 0.9442 - val_loss: 0.3562 - val_accuracy: 0.8716\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.1796 - accuracy: 0.9490 - val_loss: 0.3674 - val_accuracy: 0.8696\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.1873 - accuracy: 0.9482 - val_loss: 0.4848 - val_accuracy: 0.8239\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.1904 - accuracy: 0.9486 - val_loss: 0.4888 - val_accuracy: 0.8302\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.1960 - accuracy: 0.9496 - val_loss: 0.5685 - val_accuracy: 0.7891\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.2014 - accuracy: 0.9486 - val_loss: 0.6200 - val_accuracy: 0.7802\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.2023 - accuracy: 0.9494 - val_loss: 0.9686 - val_accuracy: 0.7081\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.2041 - accuracy: 0.9473 - val_loss: 0.7054 - val_accuracy: 0.7437\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 30s 68ms/step - loss: 0.2085 - accuracy: 0.9473 - val_loss: 0.8124 - val_accuracy: 0.7320\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.2149 - accuracy: 0.9467 - val_loss: 1.0964 - val_accuracy: 0.6519\n",
      "Duration: 0:04:59.638769\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b03a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 33s 68ms/step - loss: 0.2270 - accuracy: 0.9305 - val_loss: 0.4241 - val_accuracy: 0.8394\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 0.2196 - accuracy: 0.9331 - val_loss: 0.3809 - val_accuracy: 0.8529\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 33s 67ms/step - loss: 0.2162 - accuracy: 0.9365 - val_loss: 0.4707 - val_accuracy: 0.8279\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 33s 69ms/step - loss: 0.2221 - accuracy: 0.9381 - val_loss: 0.6322 - val_accuracy: 0.7826\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 0.2240 - accuracy: 0.9384 - val_loss: 0.6210 - val_accuracy: 0.7901\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 0.2248 - accuracy: 0.9366 - val_loss: 0.6313 - val_accuracy: 0.7707\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 0.2382 - accuracy: 0.9368 - val_loss: 0.6269 - val_accuracy: 0.7627\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 33s 68ms/step - loss: 0.2375 - accuracy: 0.9367 - val_loss: 0.8723 - val_accuracy: 0.7414\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 36s 74ms/step - loss: 0.2392 - accuracy: 0.9356 - val_loss: 0.7790 - val_accuracy: 0.6961\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 34s 70ms/step - loss: 0.2533 - accuracy: 0.9331 - val_loss: 1.1553 - val_accuracy: 0.6713\n",
      "Duration: 0:05:30.458618\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a437cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 39s 73ms/step - loss: 0.2402 - accuracy: 0.9288 - val_loss: 0.3711 - val_accuracy: 0.8539\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 39s 73ms/step - loss: 0.2298 - accuracy: 0.9342 - val_loss: 0.4098 - val_accuracy: 0.8456\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 38s 73ms/step - loss: 0.2364 - accuracy: 0.9354 - val_loss: 0.4606 - val_accuracy: 0.8252\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 39s 74ms/step - loss: 0.2406 - accuracy: 0.9368 - val_loss: 0.4899 - val_accuracy: 0.8231\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 39s 73ms/step - loss: 0.2441 - accuracy: 0.9351 - val_loss: 0.4925 - val_accuracy: 0.8034\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 39s 74ms/step - loss: 0.2533 - accuracy: 0.9343 - val_loss: 0.6347 - val_accuracy: 0.7522\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 39s 73ms/step - loss: 0.2640 - accuracy: 0.9337 - val_loss: 0.7329 - val_accuracy: 0.7362\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 38s 73ms/step - loss: 0.2676 - accuracy: 0.9307 - val_loss: 0.8877 - val_accuracy: 0.6664\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 38s 73ms/step - loss: 0.2719 - accuracy: 0.9309 - val_loss: 1.1736 - val_accuracy: 0.6498\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 38s 73ms/step - loss: 0.2758 - accuracy: 0.9304 - val_loss: 1.3428 - val_accuracy: 0.6251\n",
      "Duration: 0:06:26.324009\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f350a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 43s 74ms/step - loss: 0.2813 - accuracy: 0.9088 - val_loss: 0.3257 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 43s 75ms/step - loss: 0.2807 - accuracy: 0.9124 - val_loss: 0.3664 - val_accuracy: 0.8674\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 43s 75ms/step - loss: 0.2853 - accuracy: 0.9138 - val_loss: 0.3543 - val_accuracy: 0.8729\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.2874 - accuracy: 0.9116 - val_loss: 0.4335 - val_accuracy: 0.8474\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.2906 - accuracy: 0.9127 - val_loss: 0.6703 - val_accuracy: 0.7971\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.3026 - accuracy: 0.9125 - val_loss: 0.5324 - val_accuracy: 0.7936\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.3099 - accuracy: 0.9103 - val_loss: 0.7788 - val_accuracy: 0.6923\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 42s 73ms/step - loss: 0.3198 - accuracy: 0.9082 - val_loss: 0.6093 - val_accuracy: 0.7657\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.3264 - accuracy: 0.9055 - val_loss: 0.6901 - val_accuracy: 0.7029\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 42s 74ms/step - loss: 0.3267 - accuracy: 0.9055 - val_loss: 0.8071 - val_accuracy: 0.7297\n",
      "Duration: 0:07:02.640786\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e44708f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 46s 74ms/step - loss: 0.3031 - accuracy: 0.9054 - val_loss: 0.3157 - val_accuracy: 0.8856\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.2930 - accuracy: 0.9105 - val_loss: 0.3363 - val_accuracy: 0.8716\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.2926 - accuracy: 0.9119 - val_loss: 0.3769 - val_accuracy: 0.8589\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.2995 - accuracy: 0.9129 - val_loss: 0.4778 - val_accuracy: 0.8212\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 45s 74ms/step - loss: 0.3155 - accuracy: 0.9096 - val_loss: 0.5519 - val_accuracy: 0.8294\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 45s 74ms/step - loss: 0.3191 - accuracy: 0.9088 - val_loss: 0.5142 - val_accuracy: 0.7977\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.3272 - accuracy: 0.9073 - val_loss: 0.6312 - val_accuracy: 0.7991\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.3337 - accuracy: 0.9074 - val_loss: 0.5895 - val_accuracy: 0.7821\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.3338 - accuracy: 0.9055 - val_loss: 0.8793 - val_accuracy: 0.7606\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 45s 73ms/step - loss: 0.3483 - accuracy: 0.9033 - val_loss: 0.5973 - val_accuracy: 0.7670\n",
      "Duration: 0:07:30.927861\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eedcb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 49s 73ms/step - loss: 0.3260 - accuracy: 0.8919 - val_loss: 0.2995 - val_accuracy: 0.8849\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3278 - accuracy: 0.8927 - val_loss: 0.3179 - val_accuracy: 0.8939\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3271 - accuracy: 0.8928 - val_loss: 0.3326 - val_accuracy: 0.8794\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3363 - accuracy: 0.8939 - val_loss: 0.3752 - val_accuracy: 0.8781\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 48s 74ms/step - loss: 0.3451 - accuracy: 0.8926 - val_loss: 0.3628 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3519 - accuracy: 0.8925 - val_loss: 0.4340 - val_accuracy: 0.8524\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3683 - accuracy: 0.8873 - val_loss: 0.4563 - val_accuracy: 0.8424\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 48s 74ms/step - loss: 0.3776 - accuracy: 0.8868 - val_loss: 0.7499 - val_accuracy: 0.8157\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.3869 - accuracy: 0.8858 - val_loss: 0.5809 - val_accuracy: 0.8301\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.4036 - accuracy: 0.8790 - val_loss: 0.7618 - val_accuracy: 0.7485\n",
      "Duration: 0:08:01.278595\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7137d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 51s 72ms/step - loss: 0.3279 - accuracy: 0.8935 - val_loss: 0.2780 - val_accuracy: 0.9037\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3267 - accuracy: 0.8965 - val_loss: 0.2705 - val_accuracy: 0.9054\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3302 - accuracy: 0.8973 - val_loss: 0.3143 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3414 - accuracy: 0.8962 - val_loss: 0.3699 - val_accuracy: 0.8756\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3487 - accuracy: 0.8963 - val_loss: 0.3676 - val_accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3652 - accuracy: 0.8903 - val_loss: 0.3808 - val_accuracy: 0.8669\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 50s 72ms/step - loss: 0.3784 - accuracy: 0.8895 - val_loss: 0.4097 - val_accuracy: 0.8558.3782 - \n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.3846 - accuracy: 0.8879 - val_loss: 0.5091 - val_accuracy: 0.8219\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 51s 72ms/step - loss: 0.3890 - accuracy: 0.8841 - val_loss: 0.5545 - val_accuracy: 0.8406\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 51s 72ms/step - loss: 0.3969 - accuracy: 0.8832 - val_loss: 0.5694 - val_accuracy: 0.7961\n",
      "Duration: 0:08:27.574457\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb8f82be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 56s 74ms/step - loss: 0.3475 - accuracy: 0.8825 - val_loss: 0.2521 - val_accuracy: 0.9147\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.3467 - accuracy: 0.8841 - val_loss: 0.2808 - val_accuracy: 0.8991\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 56s 76ms/step - loss: 0.3542 - accuracy: 0.8837 - val_loss: 0.2795 - val_accuracy: 0.9039\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 56s 75ms/step - loss: 0.3727 - accuracy: 0.8815 - val_loss: 0.3819 - val_accuracy: 0.8920\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.3801 - accuracy: 0.8812 - val_loss: 0.3021 - val_accuracy: 0.9001\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.3953 - accuracy: 0.8770 - val_loss: 0.3903 - val_accuracy: 0.8959\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.3990 - accuracy: 0.8755 - val_loss: 0.3421 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 56s 75ms/step - loss: 0.4210 - accuracy: 0.8696 - val_loss: 0.3333 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.4274 - accuracy: 0.8674 - val_loss: 0.3443 - val_accuracy: 0.8925\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 55s 75ms/step - loss: 0.4401 - accuracy: 0.8633 - val_loss: 0.3680 - val_accuracy: 0.8820\n",
      "Duration: 0:09:15.090986\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff11737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 60s 76ms/step - loss: 0.3529 - accuracy: 0.8831 - val_loss: 0.2702 - val_accuracy: 0.9106\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 58s 74ms/step - loss: 0.3476 - accuracy: 0.8832 - val_loss: 0.2578 - val_accuracy: 0.9106\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 58s 73ms/step - loss: 0.3585 - accuracy: 0.8845 - val_loss: 0.2701 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 58s 74ms/step - loss: 0.3743 - accuracy: 0.8813 - val_loss: 0.3189 - val_accuracy: 0.8981\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 58s 74ms/step - loss: 0.3875 - accuracy: 0.8783 - val_loss: 0.2985 - val_accuracy: 0.9029\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 58s 74ms/step - loss: 0.3989 - accuracy: 0.8753 - val_loss: 0.3723 - val_accuracy: 0.8811\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 59s 74ms/step - loss: 0.4176 - accuracy: 0.8679 - val_loss: 0.3366 - val_accuracy: 0.8914\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 57s 73ms/step - loss: 0.4335 - accuracy: 0.8665 - val_loss: 0.5705 - val_accuracy: 0.8559\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 58s 73ms/step - loss: 0.4470 - accuracy: 0.8616 - val_loss: 0.4188 - val_accuracy: 0.8793\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 57s 73ms/step - loss: 0.4529 - accuracy: 0.8606 - val_loss: 0.3641 - val_accuracy: 0.8858\n",
      "Duration: 0:09:41.572525\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8737c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 65s 77ms/step - loss: 0.3353 - accuracy: 0.8858 - val_loss: 0.2698 - val_accuracy: 0.9054\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.3373 - accuracy: 0.8875 - val_loss: 0.2678 - val_accuracy: 0.9089\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.3571 - accuracy: 0.8845 - val_loss: 0.2870 - val_accuracy: 0.9061\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.3677 - accuracy: 0.8838 - val_loss: 0.3544 - val_accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.3846 - accuracy: 0.8797 - val_loss: 0.3134 - val_accuracy: 0.8990\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.3956 - accuracy: 0.8760 - val_loss: 0.2892 - val_accuracy: 0.9018\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 59s 71ms/step - loss: 0.4090 - accuracy: 0.8738 - val_loss: 0.3671 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.4253 - accuracy: 0.8697 - val_loss: 0.3617 - val_accuracy: 0.8879\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 60s 72ms/step - loss: 0.4288 - accuracy: 0.8681 - val_loss: 0.4113 - val_accuracy: 0.8877\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 59s 71ms/step - loss: 0.4439 - accuracy: 0.8634 - val_loss: 0.3632 - val_accuracy: 0.8895\n",
      "Duration: 0:10:02.507009\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "787a45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 64s 72ms/step - loss: 0.3219 - accuracy: 0.8928 - val_loss: 0.2448 - val_accuracy: 0.9138\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 63s 72ms/step - loss: 0.3281 - accuracy: 0.8932 - val_loss: 0.2686 - val_accuracy: 0.9104\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3372 - accuracy: 0.8912 - val_loss: 0.2708 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 63s 72ms/step - loss: 0.3503 - accuracy: 0.8886 - val_loss: 0.2751 - val_accuracy: 0.9043\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3672 - accuracy: 0.8849 - val_loss: 0.3359 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 63s 72ms/step - loss: 0.3920 - accuracy: 0.8800 - val_loss: 0.2820 - val_accuracy: 0.9076\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3988 - accuracy: 0.8785 - val_loss: 0.3379 - val_accuracy: 0.8812\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 63s 71ms/step - loss: 0.4069 - accuracy: 0.8757 - val_loss: 0.3008 - val_accuracy: 0.8935\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.4195 - accuracy: 0.8704 - val_loss: 0.3629 - val_accuracy: 0.8962\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.4281 - accuracy: 0.8694 - val_loss: 0.3618 - val_accuracy: 0.8994\n",
      "Duration: 0:10:27.009811\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fe2527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb139a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cf4ae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_lsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_lsa_dir  = \"D:/models/gtsrb_models/C1/gtsrb_model_c1_sep_lsa_e2\"\n",
    "new_model_lsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_lsa_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_lsa:\n",
    "    model.save(new_model_lsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52746ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "759bc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del lsa_values\n",
    "    del top_images_by_lsa\n",
    "    del top_labels_by_lsa\n",
    "    del image_sets_lsa\n",
    "    del label_sets_lsa\n",
    "    del models_lsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9b28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "402aa433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c44d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_lsa = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(10,20):\n",
    "        #model_lsa_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_lsa_e1_\"+str(i)\n",
    "        print(model_lsa_dir)\n",
    "        model =utils.My_model(dataset,True,model_lsa_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_lsa.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ef06e",
   "metadata": {},
   "source": [
    "## Training guided by DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14fc6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/dsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "585cd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_values = np.load(dsa_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5944946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_images_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),x_train_and_adversary)\n",
    "top_labels_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "099c7fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dsa = []\n",
    "label_sets_dsa = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_dsa)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dsa)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dsa)%m))\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m])\n",
    "    image_sets_dsa.append(top_images_by_dsa_n)\n",
    "    label_sets_dsa.append(top_labels_by_dsa_n)\n",
    "    print(len(top_images_by_dsa_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8713d09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_dsa = []\n",
    "for i in range(len(label_sets_dsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_dsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9990e037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 144ms/step - loss: 1.0105 - accuracy: 0.6218 - val_loss: 0.2991 - val_accuracy: 0.8884\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 139ms/step - loss: 0.7661 - accuracy: 0.7132 - val_loss: 0.3013 - val_accuracy: 0.8834\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 138ms/step - loss: 0.6739 - accuracy: 0.7425 - val_loss: 0.3019 - val_accuracy: 0.8843\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.6420 - accuracy: 0.7604 - val_loss: 0.2942 - val_accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.6009 - accuracy: 0.7682 - val_loss: 0.2893 - val_accuracy: 0.8891\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 139ms/step - loss: 0.5507 - accuracy: 0.7968 - val_loss: 0.2956 - val_accuracy: 0.8912\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 139ms/step - loss: 0.5163 - accuracy: 0.8125 - val_loss: 0.3003 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 138ms/step - loss: 0.4953 - accuracy: 0.8104 - val_loss: 0.3051 - val_accuracy: 0.8898\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.4778 - accuracy: 0.8279 - val_loss: 0.2967 - val_accuracy: 0.8924\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 140ms/step - loss: 0.4220 - accuracy: 0.8418 - val_loss: 0.3091 - val_accuracy: 0.8905\n",
      "Duration: 0:01:01.614436\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c24fa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 102ms/step - loss: 0.6776 - accuracy: 0.7493 - val_loss: 0.2835 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.5382 - accuracy: 0.8064 - val_loss: 0.2816 - val_accuracy: 0.8948\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 9s 102ms/step - loss: 0.5126 - accuracy: 0.8136 - val_loss: 0.2753 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 9s 102ms/step - loss: 0.4487 - accuracy: 0.8364 - val_loss: 0.2821 - val_accuracy: 0.8943\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.4369 - accuracy: 0.8429 - val_loss: 0.2875 - val_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.4013 - accuracy: 0.8577 - val_loss: 0.2855 - val_accuracy: 0.8943\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 9s 101ms/step - loss: 0.3613 - accuracy: 0.8684 - val_loss: 0.2932 - val_accuracy: 0.8972\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.3496 - accuracy: 0.8780 - val_loss: 0.2948 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.3151 - accuracy: 0.8889 - val_loss: 0.3006 - val_accuracy: 0.9029\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.3029 - accuracy: 0.8925 - val_loss: 0.2939 - val_accuracy: 0.8985\n",
      "Duration: 0:01:29.271955\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2582ba35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 87ms/step - loss: 0.5086 - accuracy: 0.8199 - val_loss: 0.2880 - val_accuracy: 0.8944\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.4165 - accuracy: 0.8526 - val_loss: 0.2767 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.3823 - accuracy: 0.8646 - val_loss: 0.2814 - val_accuracy: 0.8931\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 83ms/step - loss: 0.3585 - accuracy: 0.8696 - val_loss: 0.2849 - val_accuracy: 0.9014\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.3359 - accuracy: 0.8842 - val_loss: 0.2940 - val_accuracy: 0.8973\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.3111 - accuracy: 0.8943 - val_loss: 0.3094 - val_accuracy: 0.8965\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.2846 - accuracy: 0.9023 - val_loss: 0.2920 - val_accuracy: 0.9049\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.2815 - accuracy: 0.9030 - val_loss: 0.3206 - val_accuracy: 0.8992\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.2617 - accuracy: 0.9121 - val_loss: 0.2968 - val_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.2639 - accuracy: 0.9121 - val_loss: 0.3101 - val_accuracy: 0.9031\n",
      "Duration: 0:01:54.266489\n"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62d686d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 15s 82ms/step - loss: 0.4513 - accuracy: 0.8403 - val_loss: 0.2778 - val_accuracy: 0.8970\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.3805 - accuracy: 0.8662 - val_loss: 0.2754 - val_accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.3551 - accuracy: 0.8750 - val_loss: 0.2659 - val_accuracy: 0.9035\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 14s 80ms/step - loss: 0.3433 - accuracy: 0.8799 - val_loss: 0.2805 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.3334 - accuracy: 0.8887 - val_loss: 0.2769 - val_accuracy: 0.9089\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.3038 - accuracy: 0.8949 - val_loss: 0.2883 - val_accuracy: 0.9061\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.2882 - accuracy: 0.9024 - val_loss: 0.2820 - val_accuracy: 0.9053\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.2898 - accuracy: 0.9057 - val_loss: 0.2885 - val_accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.2690 - accuracy: 0.9104 - val_loss: 0.2972 - val_accuracy: 0.9022\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.2659 - accuracy: 0.9116 - val_loss: 0.2853 - val_accuracy: 0.9081\n",
      "Duration: 0:02:22.458211\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c84953cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 18s 78ms/step - loss: 0.4272 - accuracy: 0.8526 - val_loss: 0.2723 - val_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.3629 - accuracy: 0.8716 - val_loss: 0.2626 - val_accuracy: 0.9059\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.3403 - accuracy: 0.8834 - val_loss: 0.2704 - val_accuracy: 0.9051\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.3327 - accuracy: 0.8869 - val_loss: 0.2723 - val_accuracy: 0.9069\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.3113 - accuracy: 0.8956 - val_loss: 0.2653 - val_accuracy: 0.9089\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.3037 - accuracy: 0.9006 - val_loss: 0.2891 - val_accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.2940 - accuracy: 0.9042 - val_loss: 0.2788 - val_accuracy: 0.9078\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.2783 - accuracy: 0.9101 - val_loss: 0.3062 - val_accuracy: 0.9083\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 17s 79ms/step - loss: 0.2792 - accuracy: 0.9092 - val_loss: 0.3274 - val_accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 17s 80ms/step - loss: 0.2720 - accuracy: 0.9093 - val_loss: 0.3298 - val_accuracy: 0.9052\n",
      "Duration: 0:02:53.179003\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f934485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.3945 - accuracy: 0.8655 - val_loss: 0.2809 - val_accuracy: 0.8993\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 0.3583 - accuracy: 0.8752 - val_loss: 0.2657 - val_accuracy: 0.9079\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 0.3353 - accuracy: 0.8833 - val_loss: 0.2669 - val_accuracy: 0.9094\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 21s 82ms/step - loss: 0.3318 - accuracy: 0.8888 - val_loss: 0.2759 - val_accuracy: 0.9065\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 0.3056 - accuracy: 0.8953 - val_loss: 0.2751 - val_accuracy: 0.9054\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.3054 - accuracy: 0.9002 - val_loss: 0.2935 - val_accuracy: 0.9094\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 0.2890 - accuracy: 0.9040 - val_loss: 0.3107 - val_accuracy: 0.9032\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 21s 80ms/step - loss: 0.2773 - accuracy: 0.9099 - val_loss: 0.3773 - val_accuracy: 0.8999\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.2907 - accuracy: 0.9085 - val_loss: 0.2912 - val_accuracy: 0.9043\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.2923 - accuracy: 0.9068 - val_loss: 0.3360 - val_accuracy: 0.9052\n",
      "Duration: 0:03:30.215786\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50981582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 25s 79ms/step - loss: 0.3726 - accuracy: 0.8704 - val_loss: 0.2806 - val_accuracy: 0.9009\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3433 - accuracy: 0.8808 - val_loss: 0.2718 - val_accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3233 - accuracy: 0.8887 - val_loss: 0.2821 - val_accuracy: 0.9053\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 0.3191 - accuracy: 0.8935 - val_loss: 0.2811 - val_accuracy: 0.9055\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3084 - accuracy: 0.8977 - val_loss: 0.3058 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3033 - accuracy: 0.8973 - val_loss: 0.2875 - val_accuracy: 0.9070\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3001 - accuracy: 0.9006 - val_loss: 0.2834 - val_accuracy: 0.9046\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.3012 - accuracy: 0.9028 - val_loss: 0.2940 - val_accuracy: 0.9047\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 0.2955 - accuracy: 0.9056 - val_loss: 0.2990 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.2954 - accuracy: 0.9056 - val_loss: 0.3438 - val_accuracy: 0.9029\n",
      "Duration: 0:04:09.207887\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "688f57f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3650 - accuracy: 0.8752 - val_loss: 0.2611 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3276 - accuracy: 0.8876 - val_loss: 0.2579 - val_accuracy: 0.9088\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3291 - accuracy: 0.8892 - val_loss: 0.2793 - val_accuracy: 0.9054\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 27s 79ms/step - loss: 0.3200 - accuracy: 0.8933 - val_loss: 0.2624 - val_accuracy: 0.9092\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3080 - accuracy: 0.8977 - val_loss: 0.2799 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3067 - accuracy: 0.9006 - val_loss: 0.2785 - val_accuracy: 0.9061\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3063 - accuracy: 0.9017 - val_loss: 0.3070 - val_accuracy: 0.8982\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3129 - accuracy: 0.8998 - val_loss: 0.2901 - val_accuracy: 0.9074\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 27s 79ms/step - loss: 0.3097 - accuracy: 0.9036 - val_loss: 0.2788 - val_accuracy: 0.9058\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.3166 - accuracy: 0.8997 - val_loss: 0.3088 - val_accuracy: 0.8991\n",
      "Duration: 0:04:36.251347\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27a88171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 32s 78ms/step - loss: 0.3584 - accuracy: 0.8774 - val_loss: 0.2511 - val_accuracy: 0.9132\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.3289 - accuracy: 0.8869 - val_loss: 0.2666 - val_accuracy: 0.9060\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.3228 - accuracy: 0.8917 - val_loss: 0.2635 - val_accuracy: 0.9098\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 31s 79ms/step - loss: 0.3194 - accuracy: 0.8932 - val_loss: 0.2659 - val_accuracy: 0.9089\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 31s 80ms/step - loss: 0.3110 - accuracy: 0.8970 - val_loss: 0.2984 - val_accuracy: 0.9046\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 31s 79ms/step - loss: 0.3065 - accuracy: 0.8994 - val_loss: 0.2933 - val_accuracy: 0.9075\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.3130 - accuracy: 0.8987 - val_loss: 0.3391 - val_accuracy: 0.8977\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 31s 79ms/step - loss: 0.3119 - accuracy: 0.9008 - val_loss: 0.2926 - val_accuracy: 0.9014\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 31s 79ms/step - loss: 0.3262 - accuracy: 0.8981 - val_loss: 0.3281 - val_accuracy: 0.9057\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.3171 - accuracy: 0.9010 - val_loss: 0.3008 - val_accuracy: 0.9030\n",
      "Duration: 0:05:10.839885\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85b5daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 35s 78ms/step - loss: 0.3414 - accuracy: 0.8815 - val_loss: 0.2723 - val_accuracy: 0.9093\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 34s 78ms/step - loss: 0.3243 - accuracy: 0.8884 - val_loss: 0.2711 - val_accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3188 - accuracy: 0.8914 - val_loss: 0.3104 - val_accuracy: 0.9025\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3130 - accuracy: 0.8964 - val_loss: 0.2673 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3225 - accuracy: 0.8950 - val_loss: 0.3043 - val_accuracy: 0.9110\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 34s 78ms/step - loss: 0.3159 - accuracy: 0.8977 - val_loss: 0.2743 - val_accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3285 - accuracy: 0.8979 - val_loss: 0.3310 - val_accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 34s 78ms/step - loss: 0.3341 - accuracy: 0.8943 - val_loss: 0.2932 - val_accuracy: 0.9045\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 34s 79ms/step - loss: 0.3342 - accuracy: 0.8965 - val_loss: 0.2933 - val_accuracy: 0.9009\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3407 - accuracy: 0.8955 - val_loss: 0.3427 - val_accuracy: 0.8815\n",
      "Duration: 0:05:41.183402\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2579015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 38s 77ms/step - loss: 0.3413 - accuracy: 0.8822 - val_loss: 0.2497 - val_accuracy: 0.9132\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 37s 78ms/step - loss: 0.3257 - accuracy: 0.8907 - val_loss: 0.2654 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3260 - accuracy: 0.8894 - val_loss: 0.2864 - val_accuracy: 0.9063\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3319 - accuracy: 0.8934 - val_loss: 0.2828 - val_accuracy: 0.9097\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3289 - accuracy: 0.8928 - val_loss: 0.2728 - val_accuracy: 0.9060\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3337 - accuracy: 0.8942 - val_loss: 0.3083 - val_accuracy: 0.8956\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3434 - accuracy: 0.8919 - val_loss: 0.3049 - val_accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 37s 76ms/step - loss: 0.3451 - accuracy: 0.8900 - val_loss: 0.3138 - val_accuracy: 0.9003\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 37s 77ms/step - loss: 0.3526 - accuracy: 0.8910 - val_loss: 0.4071 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 37s 76ms/step - loss: 0.3571 - accuracy: 0.8913 - val_loss: 0.3328 - val_accuracy: 0.8891\n",
      "Duration: 0:06:10.625368\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23a41bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 40s 75ms/step - loss: 0.3377 - accuracy: 0.8827 - val_loss: 0.2431 - val_accuracy: 0.9121\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.3235 - accuracy: 0.8888 - val_loss: 0.2596 - val_accuracy: 0.9075\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3250 - accuracy: 0.8937 - val_loss: 0.2628 - val_accuracy: 0.9089\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.3245 - accuracy: 0.8928 - val_loss: 0.2756 - val_accuracy: 0.9079\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.3295 - accuracy: 0.8956 - val_loss: 0.3018 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3288 - accuracy: 0.8955 - val_loss: 0.2824 - val_accuracy: 0.9030\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3361 - accuracy: 0.8939 - val_loss: 0.3252 - val_accuracy: 0.9023\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3524 - accuracy: 0.8894 - val_loss: 0.2963 - val_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.3569 - accuracy: 0.8904 - val_loss: 0.3230 - val_accuracy: 0.8892\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3647 - accuracy: 0.8876 - val_loss: 0.2988 - val_accuracy: 0.9001\n",
      "Duration: 0:06:36.984713\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adf85f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 44s 76ms/step - loss: 0.3378 - accuracy: 0.8855 - val_loss: 0.2488 - val_accuracy: 0.9115\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3259 - accuracy: 0.8905 - val_loss: 0.2713 - val_accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3280 - accuracy: 0.8912 - val_loss: 0.2770 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3320 - accuracy: 0.8921 - val_loss: 0.2757 - val_accuracy: 0.9031\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3377 - accuracy: 0.8910 - val_loss: 0.2752 - val_accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3433 - accuracy: 0.8897 - val_loss: 0.2873 - val_accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3519 - accuracy: 0.8885 - val_loss: 0.3032 - val_accuracy: 0.9048\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3626 - accuracy: 0.8859 - val_loss: 0.2855 - val_accuracy: 0.9056\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3725 - accuracy: 0.8849 - val_loss: 0.3271 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3851 - accuracy: 0.8824 - val_loss: 0.3150 - val_accuracy: 0.8971\n",
      "Duration: 0:07:12.347709\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41082ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.3318 - accuracy: 0.8859 - val_loss: 0.2589 - val_accuracy: 0.9100\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.3219 - accuracy: 0.8919 - val_loss: 0.2573 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 46s 76ms/step - loss: 0.3246 - accuracy: 0.8923 - val_loss: 0.2592 - val_accuracy: 0.9096\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.3265 - accuracy: 0.8942 - val_loss: 0.2886 - val_accuracy: 0.9049\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 46s 76ms/step - loss: 0.3366 - accuracy: 0.8929 - val_loss: 0.2725 - val_accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.3429 - accuracy: 0.8898 - val_loss: 0.3217 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 46s 76ms/step - loss: 0.3568 - accuracy: 0.8884 - val_loss: 0.3048 - val_accuracy: 0.9020\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.3755 - accuracy: 0.8835 - val_loss: 0.5030 - val_accuracy: 0.8844\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.3889 - accuracy: 0.8806 - val_loss: 0.3407 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.3925 - accuracy: 0.8788 - val_loss: 0.3071 - val_accuracy: 0.8976\n",
      "Duration: 0:07:44.719800\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77a453d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 50s 75ms/step - loss: 0.3284 - accuracy: 0.8896 - val_loss: 0.2516 - val_accuracy: 0.9114\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3240 - accuracy: 0.8924 - val_loss: 0.2817 - val_accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3333 - accuracy: 0.8892 - val_loss: 0.2636 - val_accuracy: 0.9112\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3416 - accuracy: 0.8904 - val_loss: 0.2788 - val_accuracy: 0.9090\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3503 - accuracy: 0.8900 - val_loss: 0.5258 - val_accuracy: 0.8863\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3605 - accuracy: 0.8874 - val_loss: 0.2913 - val_accuracy: 0.9056\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3752 - accuracy: 0.8822 - val_loss: 0.3157 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3816 - accuracy: 0.8838 - val_loss: 0.3666 - val_accuracy: 0.8961\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3954 - accuracy: 0.8761 - val_loss: 0.3149 - val_accuracy: 0.8953\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.4067 - accuracy: 0.8736 - val_loss: 0.3112 - val_accuracy: 0.8930\n",
      "Duration: 0:08:15.626437\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e683b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e4b28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 48s 67ms/step - loss: 0.3249 - accuracy: 0.8891 - val_loss: 0.2547 - val_accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3238 - accuracy: 0.8898 - val_loss: 0.2596 - val_accuracy: 0.9124\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 47s 68ms/step - loss: 0.3302 - accuracy: 0.8922 - val_loss: 0.2808 - val_accuracy: 0.9061\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3483 - accuracy: 0.8891 - val_loss: 0.2774 - val_accuracy: 0.9104\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3644 - accuracy: 0.8862 - val_loss: 0.2984 - val_accuracy: 0.9044\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3731 - accuracy: 0.8852 - val_loss: 0.2802 - val_accuracy: 0.9051\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3814 - accuracy: 0.8832 - val_loss: 0.3056 - val_accuracy: 0.9006\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.3949 - accuracy: 0.8773 - val_loss: 0.3068 - val_accuracy: 0.8979\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.4042 - accuracy: 0.8741 - val_loss: 0.3263 - val_accuracy: 0.8981\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.4071 - accuracy: 0.8743 - val_loss: 0.3634 - val_accuracy: 0.8907\n",
      "Duration: 0:07:51.274264\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a3a318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.3203 - accuracy: 0.8912 - val_loss: 0.2659 - val_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3261 - accuracy: 0.8911 - val_loss: 0.2774 - val_accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.3343 - accuracy: 0.8914 - val_loss: 0.3297 - val_accuracy: 0.9109\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 53s 71ms/step - loss: 0.3477 - accuracy: 0.8890 - val_loss: 0.3340 - val_accuracy: 0.9020\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 53s 71ms/step - loss: 0.3574 - accuracy: 0.8864 - val_loss: 0.3078 - val_accuracy: 0.8969\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 54s 72ms/step - loss: 0.3698 - accuracy: 0.8854 - val_loss: 0.3304 - val_accuracy: 0.9019\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.3902 - accuracy: 0.8812 - val_loss: 0.3037 - val_accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 55s 75ms/step - loss: 0.3938 - accuracy: 0.8788 - val_loss: 0.3214 - val_accuracy: 0.8966\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.4045 - accuracy: 0.8755 - val_loss: 0.3197 - val_accuracy: 0.8945\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.4120 - accuracy: 0.8746 - val_loss: 0.3359 - val_accuracy: 0.8887\n",
      "Duration: 0:08:55.752419\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4be2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da804ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3191 - accuracy: 0.8915 - val_loss: 0.2558 - val_accuracy: 0.9124\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3282 - accuracy: 0.8920 - val_loss: 0.2820 - val_accuracy: 0.9118\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3351 - accuracy: 0.8924 - val_loss: 0.2668 - val_accuracy: 0.9102\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3523 - accuracy: 0.8895 - val_loss: 0.3092 - val_accuracy: 0.8974\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3593 - accuracy: 0.8885 - val_loss: 0.3327 - val_accuracy: 0.8924\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 53s 68ms/step - loss: 0.3789 - accuracy: 0.8811 - val_loss: 0.2803 - val_accuracy: 0.9043\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 53s 68ms/step - loss: 0.3948 - accuracy: 0.8767 - val_loss: 0.3101 - val_accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 53s 68ms/step - loss: 0.4097 - accuracy: 0.8735 - val_loss: 0.3106 - val_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4146 - accuracy: 0.8718 - val_loss: 1.2691 - val_accuracy: 0.8071\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4274 - accuracy: 0.8697 - val_loss: 0.3251 - val_accuracy: 0.8916\n",
      "Duration: 0:08:56.592505\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b20bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1adc9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3207 - accuracy: 0.8915 - val_loss: 0.2563 - val_accuracy: 0.9116\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3268 - accuracy: 0.8923 - val_loss: 0.3291 - val_accuracy: 0.8963\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3397 - accuracy: 0.8900 - val_loss: 0.3438 - val_accuracy: 0.8892\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3548 - accuracy: 0.8888 - val_loss: 0.2724 - val_accuracy: 0.9075\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3717 - accuracy: 0.8851 - val_loss: 0.2941 - val_accuracy: 0.9035\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3816 - accuracy: 0.8825 - val_loss: 0.2819 - val_accuracy: 0.9025\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4005 - accuracy: 0.8776 - val_loss: 0.3040 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4156 - accuracy: 0.8738 - val_loss: 0.3152 - val_accuracy: 0.8979\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.4136 - accuracy: 0.8707 - val_loss: 0.6076 - val_accuracy: 0.8526\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.4280 - accuracy: 0.8680 - val_loss: 0.4478 - val_accuracy: 0.8723\n",
      "Duration: 0:09:25.408438\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74b5dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c53a3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3216 - accuracy: 0.8912 - val_loss: 0.2627 - val_accuracy: 0.9099\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3268 - accuracy: 0.8917 - val_loss: 0.2711 - val_accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3367 - accuracy: 0.8911 - val_loss: 0.2644 - val_accuracy: 0.9089\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3547 - accuracy: 0.8895 - val_loss: 0.2734 - val_accuracy: 0.9084\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3708 - accuracy: 0.8847 - val_loss: 0.3060 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3904 - accuracy: 0.8815 - val_loss: 0.2893 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.4069 - accuracy: 0.8759 - val_loss: 0.3231 - val_accuracy: 0.8914\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.4177 - accuracy: 0.8714 - val_loss: 0.3166 - val_accuracy: 0.8945\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.4266 - accuracy: 0.8677 - val_loss: 0.3967 - val_accuracy: 0.8914\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.4288 - accuracy: 0.8687 - val_loss: 0.3248 - val_accuracy: 0.8921\n",
      "Duration: 0:09:53.268683\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5efcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_dsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_dsa_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_dsa:\n",
    "    model.save(new_model_dsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f250fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_dsa = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_dsa_dir = \"D:/models/gtsrb_models/C1/gtsrb_model_c1_sep_dsa_e2_\"+str(i)\n",
    "        print(model_dsa_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_dsa_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_dsa.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77836993",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del dsa_values\n",
    "    del top_images_by_dsa\n",
    "    del top_labels_by_dsa\n",
    "    del image_sets_dsa\n",
    "    del label_sets_dsa\n",
    "    del models_dsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2d78dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327980"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73510f",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ac6d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_direction = \"D:/guided-retraining/data/\"+dataset+\"/deep_gini_values.npy\"\n",
    "\n",
    "deep_gini_values = np.load(dg_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d85ee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by dg values\n",
    "top_images_by_dg  = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),x_train_and_adversary)\n",
    "top_labels_by_dg = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b7636eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dg = []\n",
    "label_sets_dg = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_dg)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dg)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dg)%m))\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m])\n",
    "    image_sets_dg.append(top_images_by_dg_n)\n",
    "    label_sets_dg.append(top_labels_by_dg_n)\n",
    "    print(len(top_images_by_dg_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8235ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "models_dg = []\n",
    "#for i in range(len(label_sets_lsa)):\n",
    "for i in range(len(label_sets_dg)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_dg.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e0ae2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 147ms/step - loss: 1.3012 - accuracy: 0.4596 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 143ms/step - loss: 1.2084 - accuracy: 0.4871 - val_loss: 0.2624 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 1.1430 - accuracy: 0.5243 - val_loss: 0.2633 - val_accuracy: 0.9148\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 1.0973 - accuracy: 0.5536 - val_loss: 0.2621 - val_accuracy: 0.9115\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 145ms/step - loss: 1.0576 - accuracy: 0.5693 - val_loss: 0.2717 - val_accuracy: 0.9061\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 142ms/step - loss: 1.0490 - accuracy: 0.5543 - val_loss: 0.2719 - val_accuracy: 0.9091\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.0448 - accuracy: 0.5754 - val_loss: 0.2714 - val_accuracy: 0.9145\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 7s 152ms/step - loss: 0.9993 - accuracy: 0.6018 - val_loss: 0.2733 - val_accuracy: 0.9122\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 7s 150ms/step - loss: 0.9556 - accuracy: 0.6164 - val_loss: 0.2841 - val_accuracy: 0.9094\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 149ms/step - loss: 0.9267 - accuracy: 0.6271 - val_loss: 0.3019 - val_accuracy: 0.9069\n",
      "Duration: 0:01:04.380784\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9111d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 109ms/step - loss: 1.1174 - accuracy: 0.5186 - val_loss: 0.2536 - val_accuracy: 0.9120\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 10s 110ms/step - loss: 1.0382 - accuracy: 0.5514 - val_loss: 0.2643 - val_accuracy: 0.9046\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 10s 109ms/step - loss: 0.9775 - accuracy: 0.5807 - val_loss: 0.2585 - val_accuracy: 0.9114\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 10s 110ms/step - loss: 0.9795 - accuracy: 0.5788 - val_loss: 0.2595 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 0.9263 - accuracy: 0.6146 - val_loss: 0.2573 - val_accuracy: 0.9126\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 10s 110ms/step - loss: 0.9198 - accuracy: 0.6146 - val_loss: 0.2580 - val_accuracy: 0.9114\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 0.8952 - accuracy: 0.6329 - val_loss: 0.2625 - val_accuracy: 0.9069\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.8630 - accuracy: 0.6375 - val_loss: 0.2695 - val_accuracy: 0.9015\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 0.8674 - accuracy: 0.6405 - val_loss: 0.2548 - val_accuracy: 0.9142\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 0.8289 - accuracy: 0.6643 - val_loss: 0.2676 - val_accuracy: 0.9039\n",
      "Duration: 0:01:37.781220\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57dcb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 14s 98ms/step - loss: 1.0239 - accuracy: 0.5669 - val_loss: 0.2497 - val_accuracy: 0.9176\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 0.9514 - accuracy: 0.5931 - val_loss: 0.2535 - val_accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 0.9127 - accuracy: 0.6106 - val_loss: 0.2609 - val_accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 0.9096 - accuracy: 0.6143 - val_loss: 0.2515 - val_accuracy: 0.9093\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.8678 - accuracy: 0.6336 - val_loss: 0.2553 - val_accuracy: 0.9117\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.8386 - accuracy: 0.6431 - val_loss: 0.2645 - val_accuracy: 0.9101\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.8378 - accuracy: 0.6445 - val_loss: 0.2485 - val_accuracy: 0.9172\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.8082 - accuracy: 0.6757 - val_loss: 0.2525 - val_accuracy: 0.9146\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.7969 - accuracy: 0.6705 - val_loss: 0.2733 - val_accuracy: 0.9100\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.7642 - accuracy: 0.6912 - val_loss: 0.2686 - val_accuracy: 0.9053\n",
      "Duration: 0:02:11.840543\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec6bc487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 17s 92ms/step - loss: 0.9462 - accuracy: 0.6091 - val_loss: 0.2417 - val_accuracy: 0.9126\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 16s 91ms/step - loss: 0.8892 - accuracy: 0.6271 - val_loss: 0.2409 - val_accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 16s 91ms/step - loss: 0.8594 - accuracy: 0.6472 - val_loss: 0.2570 - val_accuracy: 0.9119\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 16s 91ms/step - loss: 0.8402 - accuracy: 0.6571 - val_loss: 0.2564 - val_accuracy: 0.9093\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 16s 91ms/step - loss: 0.8004 - accuracy: 0.6708 - val_loss: 0.2475 - val_accuracy: 0.9144\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 16s 91ms/step - loss: 0.7754 - accuracy: 0.6829 - val_loss: 0.2465 - val_accuracy: 0.9174\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7773 - accuracy: 0.6902 - val_loss: 0.2449 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 16s 92ms/step - loss: 0.7537 - accuracy: 0.7016 - val_loss: 0.2462 - val_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 16s 92ms/step - loss: 0.7447 - accuracy: 0.7087 - val_loss: 0.2488 - val_accuracy: 0.9169\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 16s 92ms/step - loss: 0.7228 - accuracy: 0.7161 - val_loss: 0.2574 - val_accuracy: 0.9168\n",
      "Duration: 0:02:41.025719\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dcbe45fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 20s 88ms/step - loss: 0.8727 - accuracy: 0.6572 - val_loss: 0.2333 - val_accuracy: 0.9191\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.8123 - accuracy: 0.6785 - val_loss: 0.2522 - val_accuracy: 0.9129\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.7851 - accuracy: 0.6859 - val_loss: 0.2518 - val_accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 19s 89ms/step - loss: 0.7603 - accuracy: 0.7014 - val_loss: 0.2521 - val_accuracy: 0.9142\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.7589 - accuracy: 0.7036 - val_loss: 0.2533 - val_accuracy: 0.9140\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.7320 - accuracy: 0.7173 - val_loss: 0.2490 - val_accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.7138 - accuracy: 0.7298 - val_loss: 0.2660 - val_accuracy: 0.9074\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.7078 - accuracy: 0.7299 - val_loss: 0.2453 - val_accuracy: 0.9166\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.6907 - accuracy: 0.7435 - val_loss: 0.2533 - val_accuracy: 0.9181\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 19s 88ms/step - loss: 0.6679 - accuracy: 0.7479 - val_loss: 0.2784 - val_accuracy: 0.9116\n",
      "Duration: 0:03:13.458479\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0107db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 23s 85ms/step - loss: 0.8022 - accuracy: 0.6944 - val_loss: 0.2415 - val_accuracy: 0.9159\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.7525 - accuracy: 0.7113 - val_loss: 0.2432 - val_accuracy: 0.9186\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.7317 - accuracy: 0.7210 - val_loss: 0.2543 - val_accuracy: 0.9121\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.7133 - accuracy: 0.7352 - val_loss: 0.2413 - val_accuracy: 0.9180\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.6945 - accuracy: 0.7395 - val_loss: 0.2485 - val_accuracy: 0.9166\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.6956 - accuracy: 0.7435 - val_loss: 0.2501 - val_accuracy: 0.9186\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.6659 - accuracy: 0.7577 - val_loss: 0.2869 - val_accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.6616 - accuracy: 0.7601 - val_loss: 0.2444 - val_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.6504 - accuracy: 0.7645 - val_loss: 0.2535 - val_accuracy: 0.9173\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.6508 - accuracy: 0.7617 - val_loss: 0.2739 - val_accuracy: 0.9142\n",
      "Duration: 0:03:45.262706\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc5e2f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.7401 - accuracy: 0.7263 - val_loss: 0.2609 - val_accuracy: 0.9024\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6975 - accuracy: 0.7415 - val_loss: 0.2387 - val_accuracy: 0.9171\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6728 - accuracy: 0.7465 - val_loss: 0.2334 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6542 - accuracy: 0.7603 - val_loss: 0.2536 - val_accuracy: 0.9159\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.6495 - accuracy: 0.7632 - val_loss: 0.2467 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.6441 - accuracy: 0.7685 - val_loss: 0.2603 - val_accuracy: 0.9120\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6400 - accuracy: 0.7727 - val_loss: 0.2560 - val_accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6180 - accuracy: 0.7831 - val_loss: 0.2633 - val_accuracy: 0.9076\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 25s 83ms/step - loss: 0.6186 - accuracy: 0.7830 - val_loss: 0.2839 - val_accuracy: 0.9028\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.6266 - accuracy: 0.7825 - val_loss: 0.2646 - val_accuracy: 0.9120\n",
      "Duration: 0:04:15.712997\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f76364c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 29s 80ms/step - loss: 0.6800 - accuracy: 0.7557 - val_loss: 0.2345 - val_accuracy: 0.9150\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6435 - accuracy: 0.7671 - val_loss: 0.2449 - val_accuracy: 0.9150\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6286 - accuracy: 0.7741 - val_loss: 0.2386 - val_accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6161 - accuracy: 0.7798 - val_loss: 0.2472 - val_accuracy: 0.9165\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6100 - accuracy: 0.7869 - val_loss: 0.2530 - val_accuracy: 0.9148\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6050 - accuracy: 0.7887 - val_loss: 0.2551 - val_accuracy: 0.9144\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6014 - accuracy: 0.7918 - val_loss: 0.2606 - val_accuracy: 0.9110\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.5914 - accuracy: 0.7955 - val_loss: 0.2898 - val_accuracy: 0.9047\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6026 - accuracy: 0.7944 - val_loss: 0.2896 - val_accuracy: 0.9066\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6026 - accuracy: 0.7922 - val_loss: 0.2578 - val_accuracy: 0.9166\n",
      "Duration: 0:04:41.972774\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c77cb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.6357 - accuracy: 0.7756 - val_loss: 0.2419 - val_accuracy: 0.9133\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 31s 80ms/step - loss: 0.5979 - accuracy: 0.7866 - val_loss: 0.2439 - val_accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5802 - accuracy: 0.7960 - val_loss: 0.2403 - val_accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5748 - accuracy: 0.8004 - val_loss: 0.2558 - val_accuracy: 0.9155\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5687 - accuracy: 0.8017 - val_loss: 0.2395 - val_accuracy: 0.9179\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.5630 - accuracy: 0.8084 - val_loss: 0.2590 - val_accuracy: 0.9134\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5588 - accuracy: 0.8112 - val_loss: 0.2532 - val_accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5598 - accuracy: 0.8132 - val_loss: 0.2467 - val_accuracy: 0.9174\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5667 - accuracy: 0.8158 - val_loss: 0.2917 - val_accuracy: 0.8985\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.5635 - accuracy: 0.8130 - val_loss: 0.2825 - val_accuracy: 0.9087\n",
      "Duration: 0:05:17.332549\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a4f393d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 36s 79ms/step - loss: 0.5779 - accuracy: 0.7984 - val_loss: 0.2433 - val_accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5606 - accuracy: 0.8036 - val_loss: 0.2564 - val_accuracy: 0.9079\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5410 - accuracy: 0.8137 - val_loss: 0.2471 - val_accuracy: 0.9153\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5403 - accuracy: 0.8177 - val_loss: 0.2597 - val_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5382 - accuracy: 0.8178 - val_loss: 0.2497 - val_accuracy: 0.9157\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5408 - accuracy: 0.8189 - val_loss: 0.2497 - val_accuracy: 0.9141\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5440 - accuracy: 0.8179 - val_loss: 0.2742 - val_accuracy: 0.9091\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5470 - accuracy: 0.8244 - val_loss: 0.2563 - val_accuracy: 0.9154\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5456 - accuracy: 0.8203 - val_loss: 0.2781 - val_accuracy: 0.9064\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5663 - accuracy: 0.8155 - val_loss: 0.2985 - val_accuracy: 0.8995\n",
      "Duration: 0:05:47.455033\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f9b9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 39s 78ms/step - loss: 0.5364 - accuracy: 0.8111 - val_loss: 0.2567 - val_accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5209 - accuracy: 0.8199 - val_loss: 0.2486 - val_accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 37s 78ms/step - loss: 0.5152 - accuracy: 0.8219 - val_loss: 0.2621 - val_accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5074 - accuracy: 0.8302 - val_loss: 0.2565 - val_accuracy: 0.9131\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5147 - accuracy: 0.8298 - val_loss: 0.2937 - val_accuracy: 0.9063\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5145 - accuracy: 0.8314 - val_loss: 0.2535 - val_accuracy: 0.9137\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5186 - accuracy: 0.8301 - val_loss: 0.2942 - val_accuracy: 0.9041\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5193 - accuracy: 0.8308 - val_loss: 0.2820 - val_accuracy: 0.9039\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 37s 78ms/step - loss: 0.5321 - accuracy: 0.8294 - val_loss: 0.2812 - val_accuracy: 0.9081\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 37s 78ms/step - loss: 0.5413 - accuracy: 0.8256 - val_loss: 0.2783 - val_accuracy: 0.9088\n",
      "Duration: 0:06:16.683215\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4849039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 41s 77ms/step - loss: 0.5073 - accuracy: 0.8276 - val_loss: 0.2388 - val_accuracy: 0.9157\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.4793 - accuracy: 0.8367 - val_loss: 0.2528 - val_accuracy: 0.9131\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 41s 77ms/step - loss: 0.4862 - accuracy: 0.8365 - val_loss: 0.2611 - val_accuracy: 0.9081\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.4763 - accuracy: 0.8393 - val_loss: 0.2597 - val_accuracy: 0.9131\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.4860 - accuracy: 0.8411 - val_loss: 0.2533 - val_accuracy: 0.9157\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.4939 - accuracy: 0.8398 - val_loss: 0.2689 - val_accuracy: 0.9121\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5004 - accuracy: 0.8390 - val_loss: 0.2734 - val_accuracy: 0.9089\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5052 - accuracy: 0.8378 - val_loss: 0.2785 - val_accuracy: 0.9049\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5147 - accuracy: 0.8371 - val_loss: 0.2847 - val_accuracy: 0.9059\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5155 - accuracy: 0.8354 - val_loss: 0.2714 - val_accuracy: 0.9100\n",
      "Duration: 0:06:41.547955\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43963e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 45s 77ms/step - loss: 0.4723 - accuracy: 0.8381 - val_loss: 0.2377 - val_accuracy: 0.9173\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.4612 - accuracy: 0.8442 - val_loss: 0.2590 - val_accuracy: 0.9129\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 46s 80ms/step - loss: 0.4549 - accuracy: 0.8471 - val_loss: 0.2503 - val_accuracy: 0.9195\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.4616 - accuracy: 0.8500 - val_loss: 0.2417 - val_accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4706 - accuracy: 0.8489 - val_loss: 0.2546 - val_accuracy: 0.9160\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.4736 - accuracy: 0.8490 - val_loss: 0.2587 - val_accuracy: 0.9110\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.4817 - accuracy: 0.8491 - val_loss: 0.3117 - val_accuracy: 0.9116\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.4923 - accuracy: 0.8438 - val_loss: 0.2664 - val_accuracy: 0.9101\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 46s 81ms/step - loss: 0.4974 - accuracy: 0.8442 - val_loss: 0.2862 - val_accuracy: 0.9030\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 46s 82ms/step - loss: 0.5073 - accuracy: 0.8392 - val_loss: 0.2690 - val_accuracy: 0.9080\n",
      "Duration: 0:07:26.978590\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8ba0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 49s 78ms/step - loss: 0.4403 - accuracy: 0.8489 - val_loss: 0.2415 - val_accuracy: 0.9129\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4267 - accuracy: 0.8558 - val_loss: 0.2493 - val_accuracy: 0.9125\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.4370 - accuracy: 0.8555 - val_loss: 0.2563 - val_accuracy: 0.9109\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4453 - accuracy: 0.8561 - val_loss: 0.2713 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4500 - accuracy: 0.8567 - val_loss: 0.2548 - val_accuracy: 0.9115\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4620 - accuracy: 0.8524 - val_loss: 0.2830 - val_accuracy: 0.9087\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4729 - accuracy: 0.8491 - val_loss: 0.3253 - val_accuracy: 0.9006\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4746 - accuracy: 0.8476 - val_loss: 0.3102 - val_accuracy: 0.9085\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4863 - accuracy: 0.8465 - val_loss: 0.3162 - val_accuracy: 0.8966\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.4931 - accuracy: 0.8450 - val_loss: 0.3081 - val_accuracy: 0.9035\n",
      "Duration: 0:07:51.836890\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c33080eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 51s 76ms/step - loss: 0.4176 - accuracy: 0.8597 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4071 - accuracy: 0.8644 - val_loss: 0.2442 - val_accuracy: 0.9154\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4126 - accuracy: 0.8632 - val_loss: 0.2553 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4239 - accuracy: 0.8644 - val_loss: 0.2699 - val_accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4310 - accuracy: 0.8630 - val_loss: 0.2788 - val_accuracy: 0.9131\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.4353 - accuracy: 0.8613 - val_loss: 0.2924 - val_accuracy: 0.9104\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.4512 - accuracy: 0.8589 - val_loss: 0.2718 - val_accuracy: 0.9078\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 50s 75ms/step - loss: 0.4585 - accuracy: 0.8589 - val_loss: 0.3493 - val_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.4645 - accuracy: 0.8543 - val_loss: 0.2930 - val_accuracy: 0.9016\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.4840 - accuracy: 0.8509 - val_loss: 0.4227 - val_accuracy: 0.8786\n",
      "Duration: 0:08:19.509741\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "935d2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3871 - accuracy: 0.8676 - val_loss: 0.2483 - val_accuracy: 0.9134\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 52s 75ms/step - loss: 0.3890 - accuracy: 0.8701 - val_loss: 0.2523 - val_accuracy: 0.9136\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3917 - accuracy: 0.8717 - val_loss: 0.2559 - val_accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4055 - accuracy: 0.8685 - val_loss: 0.2602 - val_accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4146 - accuracy: 0.8680 - val_loss: 0.2792 - val_accuracy: 0.9093\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4290 - accuracy: 0.8643 - val_loss: 0.2854 - val_accuracy: 0.9044\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4467 - accuracy: 0.8605 - val_loss: 0.2734 - val_accuracy: 0.9086\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4546 - accuracy: 0.8606 - val_loss: 0.3020 - val_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4562 - accuracy: 0.8567 - val_loss: 0.2979 - val_accuracy: 0.8980\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4751 - accuracy: 0.8537 - val_loss: 0.3116 - val_accuracy: 0.8924\n",
      "Duration: 0:08:39.052592\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a242661",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab5a778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.3686 - accuracy: 0.8741 - val_loss: 0.2472 - val_accuracy: 0.9126\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3693 - accuracy: 0.8764 - val_loss: 0.2725 - val_accuracy: 0.9088\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.3765 - accuracy: 0.8757 - val_loss: 0.3058 - val_accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3931 - accuracy: 0.8748 - val_loss: 0.2857 - val_accuracy: 0.9076\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4049 - accuracy: 0.8706 - val_loss: 0.2907 - val_accuracy: 0.9064\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4182 - accuracy: 0.8705 - val_loss: 0.3190 - val_accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4359 - accuracy: 0.8649 - val_loss: 0.3072 - val_accuracy: 0.9044\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4441 - accuracy: 0.8618 - val_loss: 0.3198 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.4511 - accuracy: 0.8578 - val_loss: 0.3266 - val_accuracy: 0.8945\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.4614 - accuracy: 0.8562 - val_loss: 0.3083 - val_accuracy: 0.8929\n",
      "Duration: 0:08:33.909275\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9e8ae173",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b00dcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3539 - accuracy: 0.8808 - val_loss: 0.2456 - val_accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3572 - accuracy: 0.8832 - val_loss: 0.2597 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3684 - accuracy: 0.8796 - val_loss: 0.2974 - val_accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3795 - accuracy: 0.8778 - val_loss: 0.2886 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3934 - accuracy: 0.8772 - val_loss: 0.2777 - val_accuracy: 0.9038\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4022 - accuracy: 0.8747 - val_loss: 0.3410 - val_accuracy: 0.8926\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4246 - accuracy: 0.8709 - val_loss: 0.3028 - val_accuracy: 0.9028\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4305 - accuracy: 0.8658 - val_loss: 0.3384 - val_accuracy: 0.8956\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 55s 70ms/step - loss: 0.4481 - accuracy: 0.8621 - val_loss: 0.3307 - val_accuracy: 0.9022\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 55s 70ms/step - loss: 0.4563 - accuracy: 0.8581 - val_loss: 0.3327 - val_accuracy: 0.8874\n",
      "Duration: 0:09:03.115965\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed4a70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6cccdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 58s 68ms/step - loss: 0.3336 - accuracy: 0.8864 - val_loss: 0.2622 - val_accuracy: 0.9120\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3381 - accuracy: 0.8879 - val_loss: 0.2801 - val_accuracy: 0.9089\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3575 - accuracy: 0.8844 - val_loss: 0.3399 - val_accuracy: 0.9093\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3714 - accuracy: 0.8835 - val_loss: 0.2752 - val_accuracy: 0.9090\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3915 - accuracy: 0.8785 - val_loss: 0.3122 - val_accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4066 - accuracy: 0.8763 - val_loss: 0.2836 - val_accuracy: 0.9031\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.4122 - accuracy: 0.8713 - val_loss: 0.4843 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.4242 - accuracy: 0.8695 - val_loss: 0.3322 - val_accuracy: 0.8928\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.4441 - accuracy: 0.8642 - val_loss: 0.3206 - val_accuracy: 0.8926\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.4463 - accuracy: 0.8635 - val_loss: 0.3087 - val_accuracy: 0.8961\n",
      "Duration: 0:09:28.966394\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83cc5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8140fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 61s 68ms/step - loss: 0.3219 - accuracy: 0.8925 - val_loss: 0.2581 - val_accuracy: 0.9139\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3245 - accuracy: 0.8931 - val_loss: 0.2679 - val_accuracy: 0.9070\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3416 - accuracy: 0.8908 - val_loss: 0.3042 - val_accuracy: 0.9030\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3595 - accuracy: 0.8861 - val_loss: 0.2842 - val_accuracy: 0.9087\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3750 - accuracy: 0.8826 - val_loss: 0.3014 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3830 - accuracy: 0.8793 - val_loss: 0.2919 - val_accuracy: 0.9012\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.4031 - accuracy: 0.8760 - val_loss: 0.3532 - val_accuracy: 0.8944\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.4106 - accuracy: 0.8747 - val_loss: 0.3084 - val_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 61s 70ms/step - loss: 0.4152 - accuracy: 0.8728 - val_loss: 0.3071 - val_accuracy: 0.8914\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 61s 69ms/step - loss: 0.4292 - accuracy: 0.8679 - val_loss: 0.3065 - val_accuracy: 0.8907\n",
      "Duration: 0:10:00.226960\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "822aa540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_dg_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_dg_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_dg_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_dg:\n",
    "    model.save(new_model_dg_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87737d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_dg = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(5):\n",
    "        model_dg_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_gn_e1_\"+str(i)\n",
    "        print(model_dg_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_dg_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_dg.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2139719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del deep_gini_values\n",
    "    del top_images_by_dg\n",
    "    del top_labels_by_dg\n",
    "    del image_sets_dg\n",
    "    del label_sets_dg\n",
    "    del models_dg\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8986882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382925"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bfcff",
   "metadata": {},
   "source": [
    "### Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3b6b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax values\n",
    "se_direction = \"D:/guided-retraining/data/\"+dataset+\"/softmax_values.npy\"\n",
    "se_values = np.load(se_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a389aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by LSA values\n",
    "top_images_by_se  = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),x_train_and_adversary)\n",
    "top_labels_by_se = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74bdb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "\n",
    "n = 0\n",
    "image_sets_se = []\n",
    "label_sets_se = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_se)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_se)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_se)%m))\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m])\n",
    "    image_sets_se.append(top_images_by_se_n)\n",
    "    label_sets_se.append(top_labels_by_se_n)\n",
    "    print(len(top_images_by_se_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14e3cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "models_se = []\n",
    "for i in range(len(label_sets_se)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_se.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f66277ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 150ms/step - loss: 1.3550 - accuracy: 0.4568 - val_loss: 0.2580 - val_accuracy: 0.9104\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.1813 - accuracy: 0.5161 - val_loss: 0.2591 - val_accuracy: 0.9105\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.1379 - accuracy: 0.5314 - val_loss: 0.2599 - val_accuracy: 0.9121\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.0842 - accuracy: 0.5654 - val_loss: 0.2654 - val_accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.0722 - accuracy: 0.5754 - val_loss: 0.2839 - val_accuracy: 0.9074\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.0329 - accuracy: 0.5864 - val_loss: 0.2775 - val_accuracy: 0.9037\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 7s 154ms/step - loss: 0.9824 - accuracy: 0.6068 - val_loss: 0.2730 - val_accuracy: 0.9081\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 7s 153ms/step - loss: 0.9458 - accuracy: 0.6268 - val_loss: 0.3003 - val_accuracy: 0.9075\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 7s 153ms/step - loss: 0.9472 - accuracy: 0.6189 - val_loss: 0.2847 - val_accuracy: 0.9063\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 7s 153ms/step - loss: 0.9078 - accuracy: 0.6468 - val_loss: 0.2935 - val_accuracy: 0.9076\n",
      "Duration: 0:01:05.832014\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bb251b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 11s 110ms/step - loss: 1.1470 - accuracy: 0.5209 - val_loss: 0.2504 - val_accuracy: 0.9154\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 1.0480 - accuracy: 0.5666 - val_loss: 0.2632 - val_accuracy: 0.9076\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 10s 110ms/step - loss: 1.0239 - accuracy: 0.5811 - val_loss: 0.2555 - val_accuracy: 0.9126\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 0.9799 - accuracy: 0.5979 - val_loss: 0.2609 - val_accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 10s 112ms/step - loss: 0.9602 - accuracy: 0.6016 - val_loss: 0.2615 - val_accuracy: 0.9069\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 10s 112ms/step - loss: 0.9360 - accuracy: 0.6204 - val_loss: 0.2625 - val_accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 112ms/step - loss: 0.9149 - accuracy: 0.6343 - val_loss: 0.2824 - val_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.8796 - accuracy: 0.6502 - val_loss: 0.2660 - val_accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.8643 - accuracy: 0.6509 - val_loss: 0.2841 - val_accuracy: 0.9081\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.8297 - accuracy: 0.6639 - val_loss: 0.2897 - val_accuracy: 0.9101\n",
      "Duration: 0:01:39.178437\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b3b84fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 14s 99ms/step - loss: 1.0507 - accuracy: 0.5564 - val_loss: 0.2511 - val_accuracy: 0.9114\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 13s 99ms/step - loss: 0.9693 - accuracy: 0.5946 - val_loss: 0.2685 - val_accuracy: 0.9056\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 13s 100ms/step - loss: 0.9310 - accuracy: 0.6188 - val_loss: 0.2597 - val_accuracy: 0.9046\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.8971 - accuracy: 0.6340 - val_loss: 0.2607 - val_accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.8786 - accuracy: 0.6399 - val_loss: 0.2459 - val_accuracy: 0.9141\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.8517 - accuracy: 0.6498 - val_loss: 0.2610 - val_accuracy: 0.9046\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.8345 - accuracy: 0.6592 - val_loss: 0.2594 - val_accuracy: 0.9075\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 13s 102ms/step - loss: 0.8172 - accuracy: 0.6687 - val_loss: 0.2590 - val_accuracy: 0.9084\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.7869 - accuracy: 0.6815 - val_loss: 0.2719 - val_accuracy: 0.9106\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 13s 101ms/step - loss: 0.7768 - accuracy: 0.6870 - val_loss: 0.2579 - val_accuracy: 0.9091\n",
      "Duration: 0:02:13.601561\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2dd3cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 17s 93ms/step - loss: 0.9577 - accuracy: 0.6013 - val_loss: 0.2484 - val_accuracy: 0.9095\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 17s 95ms/step - loss: 0.8852 - accuracy: 0.6322 - val_loss: 0.2420 - val_accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.8492 - accuracy: 0.6537 - val_loss: 0.2413 - val_accuracy: 0.9191\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.8369 - accuracy: 0.6597 - val_loss: 0.2442 - val_accuracy: 0.9155\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.8165 - accuracy: 0.6729 - val_loss: 0.2485 - val_accuracy: 0.9121\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7885 - accuracy: 0.6863 - val_loss: 0.2509 - val_accuracy: 0.9138\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7689 - accuracy: 0.6986 - val_loss: 0.2547 - val_accuracy: 0.9120\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7536 - accuracy: 0.7012 - val_loss: 0.2640 - val_accuracy: 0.9094\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7442 - accuracy: 0.7060 - val_loss: 0.2551 - val_accuracy: 0.9144\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 16s 93ms/step - loss: 0.7256 - accuracy: 0.7152 - val_loss: 0.2613 - val_accuracy: 0.9126\n",
      "Duration: 0:02:43.910452\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e151e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.8741 - accuracy: 0.6513 - val_loss: 0.2437 - val_accuracy: 0.9125\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.8180 - accuracy: 0.6753 - val_loss: 0.2480 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 0.7971 - accuracy: 0.6825 - val_loss: 0.2394 - val_accuracy: 0.9152\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.7685 - accuracy: 0.6990 - val_loss: 0.2424 - val_accuracy: 0.9151\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 0.7528 - accuracy: 0.7098 - val_loss: 0.2401 - val_accuracy: 0.9176\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 0.7315 - accuracy: 0.7178 - val_loss: 0.2537 - val_accuracy: 0.9138\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.7229 - accuracy: 0.7235 - val_loss: 0.2718 - val_accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.6967 - accuracy: 0.7344 - val_loss: 0.2546 - val_accuracy: 0.9162\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.6916 - accuracy: 0.7403 - val_loss: 0.2559 - val_accuracy: 0.9141\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 20s 89ms/step - loss: 0.6748 - accuracy: 0.7500 - val_loss: 0.2839 - val_accuracy: 0.9131\n",
      "Duration: 0:03:16.774162\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "976d21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 24s 87ms/step - loss: 0.8079 - accuracy: 0.6894 - val_loss: 0.2335 - val_accuracy: 0.9170\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.7553 - accuracy: 0.7092 - val_loss: 0.2446 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.7265 - accuracy: 0.7244 - val_loss: 0.2364 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.7142 - accuracy: 0.7321 - val_loss: 0.2606 - val_accuracy: 0.9079\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.6933 - accuracy: 0.7418 - val_loss: 0.2423 - val_accuracy: 0.9151\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.6745 - accuracy: 0.7482 - val_loss: 0.2439 - val_accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.6543 - accuracy: 0.7565 - val_loss: 0.2583 - val_accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.6554 - accuracy: 0.7601 - val_loss: 0.2516 - val_accuracy: 0.9164\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.6481 - accuracy: 0.7645 - val_loss: 0.2763 - val_accuracy: 0.9164\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.6436 - accuracy: 0.7675 - val_loss: 0.2697 - val_accuracy: 0.9146\n",
      "Duration: 0:03:48.763286\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "86546a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 27s 84ms/step - loss: 0.7403 - accuracy: 0.7213 - val_loss: 0.2466 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6848 - accuracy: 0.7475 - val_loss: 0.2450 - val_accuracy: 0.9143\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6810 - accuracy: 0.7494 - val_loss: 0.2438 - val_accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 26s 85ms/step - loss: 0.6651 - accuracy: 0.7549 - val_loss: 0.2442 - val_accuracy: 0.9165\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6464 - accuracy: 0.7632 - val_loss: 0.2483 - val_accuracy: 0.9171\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6287 - accuracy: 0.7726 - val_loss: 0.2693 - val_accuracy: 0.9039\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 26s 85ms/step - loss: 0.6334 - accuracy: 0.7733 - val_loss: 0.2924 - val_accuracy: 0.9051\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6240 - accuracy: 0.7790 - val_loss: 0.2759 - val_accuracy: 0.9052\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6364 - accuracy: 0.7788 - val_loss: 0.2967 - val_accuracy: 0.9091\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.6147 - accuracy: 0.7868 - val_loss: 0.2640 - val_accuracy: 0.9129\n",
      "Duration: 0:04:19.834303\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "01855707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.6865 - accuracy: 0.7515 - val_loss: 0.2408 - val_accuracy: 0.9146\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6432 - accuracy: 0.7675 - val_loss: 0.2384 - val_accuracy: 0.9169\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.6268 - accuracy: 0.7758 - val_loss: 0.2509 - val_accuracy: 0.9152\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.6049 - accuracy: 0.7839 - val_loss: 0.2504 - val_accuracy: 0.9124\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.6026 - accuracy: 0.7882 - val_loss: 0.2520 - val_accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.5985 - accuracy: 0.7910 - val_loss: 0.2515 - val_accuracy: 0.9169\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 29s 83ms/step - loss: 0.5901 - accuracy: 0.7964 - val_loss: 0.2446 - val_accuracy: 0.9200\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.5955 - accuracy: 0.7989 - val_loss: 0.2470 - val_accuracy: 0.9173\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.5902 - accuracy: 0.7995 - val_loss: 0.2932 - val_accuracy: 0.9106\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.5968 - accuracy: 0.7966 - val_loss: 0.2582 - val_accuracy: 0.9141\n",
      "Duration: 0:04:48.003138\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e8db845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 33s 82ms/step - loss: 0.6181 - accuracy: 0.7796 - val_loss: 0.2373 - val_accuracy: 0.9166\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.6026 - accuracy: 0.7883 - val_loss: 0.2342 - val_accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 34s 87ms/step - loss: 0.5855 - accuracy: 0.7962 - val_loss: 0.2471 - val_accuracy: 0.9177\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5778 - accuracy: 0.7991 - val_loss: 0.2477 - val_accuracy: 0.9115\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 33s 84ms/step - loss: 0.5628 - accuracy: 0.8046 - val_loss: 0.2373 - val_accuracy: 0.9201\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5644 - accuracy: 0.8061 - val_loss: 0.2497 - val_accuracy: 0.9154\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5684 - accuracy: 0.8115 - val_loss: 0.2458 - val_accuracy: 0.9157\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5662 - accuracy: 0.8135 - val_loss: 0.2646 - val_accuracy: 0.9139\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5652 - accuracy: 0.8089 - val_loss: 0.2564 - val_accuracy: 0.9131\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.5754 - accuracy: 0.8081 - val_loss: 0.2566 - val_accuracy: 0.9131\n",
      "Duration: 0:05:27.288614\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e26b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 36s 81ms/step - loss: 0.5796 - accuracy: 0.7974 - val_loss: 0.2494 - val_accuracy: 0.9111\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 36s 81ms/step - loss: 0.5592 - accuracy: 0.8053 - val_loss: 0.2570 - val_accuracy: 0.9094\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.5366 - accuracy: 0.8139 - val_loss: 0.2475 - val_accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 36s 82ms/step - loss: 0.5391 - accuracy: 0.8182 - val_loss: 0.2445 - val_accuracy: 0.9160\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 36s 82ms/step - loss: 0.5480 - accuracy: 0.8154 - val_loss: 0.2828 - val_accuracy: 0.9089\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 36s 82ms/step - loss: 0.5438 - accuracy: 0.8202 - val_loss: 0.2619 - val_accuracy: 0.9153\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 36s 82ms/step - loss: 0.5432 - accuracy: 0.8228 - val_loss: 0.2880 - val_accuracy: 0.9088\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.5445 - accuracy: 0.8231 - val_loss: 0.2776 - val_accuracy: 0.9097\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.5495 - accuracy: 0.8228 - val_loss: 0.2627 - val_accuracy: 0.9093\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.5569 - accuracy: 0.8209 - val_loss: 0.2712 - val_accuracy: 0.9052\n",
      "Duration: 0:06:01.448783\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "20c681f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 42s 85ms/step - loss: 0.5304 - accuracy: 0.8152 - val_loss: 0.2383 - val_accuracy: 0.9147\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5171 - accuracy: 0.8215 - val_loss: 0.2721 - val_accuracy: 0.9090\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5107 - accuracy: 0.8258 - val_loss: 0.3002 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 40s 83ms/step - loss: 0.5092 - accuracy: 0.8283 - val_loss: 0.2534 - val_accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5151 - accuracy: 0.8265 - val_loss: 0.2434 - val_accuracy: 0.9153\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 40s 83ms/step - loss: 0.5157 - accuracy: 0.8309 - val_loss: 0.2723 - val_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5198 - accuracy: 0.8313 - val_loss: 0.2713 - val_accuracy: 0.9096\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5239 - accuracy: 0.8302 - val_loss: 0.2796 - val_accuracy: 0.9074\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 40s 84ms/step - loss: 0.5455 - accuracy: 0.8233 - val_loss: 0.3116 - val_accuracy: 0.8939\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 40s 83ms/step - loss: 0.5469 - accuracy: 0.8253 - val_loss: 0.2854 - val_accuracy: 0.9089\n",
      "Duration: 0:06:44.110303\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "363f1a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 44s 82ms/step - loss: 0.4964 - accuracy: 0.8279 - val_loss: 0.2420 - val_accuracy: 0.9126\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 43s 83ms/step - loss: 0.4836 - accuracy: 0.8344 - val_loss: 0.2467 - val_accuracy: 0.9136\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 42s 81ms/step - loss: 0.4846 - accuracy: 0.8364 - val_loss: 0.2413 - val_accuracy: 0.9143\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.4822 - accuracy: 0.8398 - val_loss: 0.2432 - val_accuracy: 0.9163\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.4840 - accuracy: 0.8417 - val_loss: 0.2680 - val_accuracy: 0.9070\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.4945 - accuracy: 0.8399 - val_loss: 0.2473 - val_accuracy: 0.9165\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 43s 81ms/step - loss: 0.5003 - accuracy: 0.8411 - val_loss: 0.2735 - val_accuracy: 0.9072\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 44s 83ms/step - loss: 0.5057 - accuracy: 0.8383 - val_loss: 0.3095 - val_accuracy: 0.9061\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5143 - accuracy: 0.8347 - val_loss: 0.2717 - val_accuracy: 0.9110\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5144 - accuracy: 0.8347 - val_loss: 0.3217 - val_accuracy: 0.8931\n",
      "Duration: 0:07:03.826607\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49e2515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.4650 - accuracy: 0.8388 - val_loss: 0.2390 - val_accuracy: 0.9173\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4474 - accuracy: 0.8448 - val_loss: 0.2483 - val_accuracy: 0.9164\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.4593 - accuracy: 0.8474 - val_loss: 0.2450 - val_accuracy: 0.9150\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4588 - accuracy: 0.8497 - val_loss: 0.2578 - val_accuracy: 0.9136\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4660 - accuracy: 0.8490 - val_loss: 0.3039 - val_accuracy: 0.9119\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4725 - accuracy: 0.8486 - val_loss: 0.2630 - val_accuracy: 0.9120\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4808 - accuracy: 0.8470 - val_loss: 0.2679 - val_accuracy: 0.9103\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4938 - accuracy: 0.8424 - val_loss: 0.2778 - val_accuracy: 0.9072\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.5060 - accuracy: 0.8416 - val_loss: 0.2689 - val_accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.5123 - accuracy: 0.8375 - val_loss: 0.2741 - val_accuracy: 0.9076\n",
      "Duration: 0:07:24.535200\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8144888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 48s 77ms/step - loss: 0.4342 - accuracy: 0.8507 - val_loss: 0.2584 - val_accuracy: 0.9079\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.4317 - accuracy: 0.8560 - val_loss: 0.2492 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4365 - accuracy: 0.8570 - val_loss: 0.2531 - val_accuracy: 0.9116\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4407 - accuracy: 0.8558 - val_loss: 0.2493 - val_accuracy: 0.9127\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4476 - accuracy: 0.8540 - val_loss: 0.2752 - val_accuracy: 0.9079\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4631 - accuracy: 0.8532 - val_loss: 0.2799 - val_accuracy: 0.9112\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4743 - accuracy: 0.8481 - val_loss: 0.2967 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4859 - accuracy: 0.8466 - val_loss: 0.2742 - val_accuracy: 0.9076\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4954 - accuracy: 0.8438 - val_loss: 0.2998 - val_accuracy: 0.9058\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.5079 - accuracy: 0.8420 - val_loss: 0.3549 - val_accuracy: 0.9041\n",
      "Duration: 0:07:55.192981\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c9ba5f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 52s 77ms/step - loss: 0.4104 - accuracy: 0.8603 - val_loss: 0.2466 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4061 - accuracy: 0.8642 - val_loss: 0.2537 - val_accuracy: 0.9132\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4115 - accuracy: 0.8640 - val_loss: 0.2595 - val_accuracy: 0.9121\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4212 - accuracy: 0.8635 - val_loss: 0.2601 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4333 - accuracy: 0.8612 - val_loss: 0.3240 - val_accuracy: 0.9091\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4451 - accuracy: 0.8614 - val_loss: 0.4137 - val_accuracy: 0.9065\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4513 - accuracy: 0.8583 - val_loss: 0.2813 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4637 - accuracy: 0.8562 - val_loss: 0.2906 - val_accuracy: 0.9014\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4714 - accuracy: 0.8529 - val_loss: 0.3518 - val_accuracy: 0.8995\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4877 - accuracy: 0.8496 - val_loss: 0.2953 - val_accuracy: 0.9006\n",
      "Duration: 0:08:25.310170\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "147a3a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 54s 75ms/step - loss: 0.3899 - accuracy: 0.8662 - val_loss: 0.2587 - val_accuracy: 0.9076\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.3816 - accuracy: 0.8721 - val_loss: 0.2598 - val_accuracy: 0.9164\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.3879 - accuracy: 0.8709 - val_loss: 0.2603 - val_accuracy: 0.9122\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4086 - accuracy: 0.8695 - val_loss: 0.2643 - val_accuracy: 0.9098\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4195 - accuracy: 0.8677 - val_loss: 0.2586 - val_accuracy: 0.9104\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4352 - accuracy: 0.8630 - val_loss: 0.2875 - val_accuracy: 0.9041\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4377 - accuracy: 0.8634 - val_loss: 0.2855 - val_accuracy: 0.9049\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4510 - accuracy: 0.8593 - val_loss: 0.3144 - val_accuracy: 0.8940\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4669 - accuracy: 0.8573 - val_loss: 0.3244 - val_accuracy: 0.9001\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4734 - accuracy: 0.8532 - val_loss: 0.2986 - val_accuracy: 0.8986\n",
      "Duration: 0:08:48.126245\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2153455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 58s 76ms/step - loss: 0.3695 - accuracy: 0.8745 - val_loss: 0.2403 - val_accuracy: 0.9186\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 57s 76ms/step - loss: 0.3672 - accuracy: 0.8771 - val_loss: 0.2498 - val_accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 57s 76ms/step - loss: 0.3774 - accuracy: 0.8757 - val_loss: 0.2614 - val_accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 58s 79ms/step - loss: 0.3925 - accuracy: 0.8733 - val_loss: 0.2687 - val_accuracy: 0.9112\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 57s 77ms/step - loss: 0.4003 - accuracy: 0.8744 - val_loss: 0.2642 - val_accuracy: 0.9094\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 58s 78ms/step - loss: 0.4252 - accuracy: 0.8684 - val_loss: 0.3205 - val_accuracy: 0.8981\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 57s 77ms/step - loss: 0.4357 - accuracy: 0.8658 - val_loss: 0.3026 - val_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 57s 76ms/step - loss: 0.4459 - accuracy: 0.8643 - val_loss: 0.2930 - val_accuracy: 0.8989\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 57s 76ms/step - loss: 0.4571 - accuracy: 0.8582 - val_loss: 0.2865 - val_accuracy: 0.9008\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 57s 76ms/step - loss: 0.4675 - accuracy: 0.8564 - val_loss: 0.3091 - val_accuracy: 0.8968\n",
      "Duration: 0:09:32.889114\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1670fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8763f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 55s 69ms/step - loss: 0.3546 - accuracy: 0.8799 - val_loss: 0.2481 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3605 - accuracy: 0.8811 - val_loss: 0.2612 - val_accuracy: 0.9122\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 55s 69ms/step - loss: 0.3672 - accuracy: 0.8819 - val_loss: 0.3065 - val_accuracy: 0.9099\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3762 - accuracy: 0.8806 - val_loss: 0.2848 - val_accuracy: 0.9074\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3969 - accuracy: 0.8759 - val_loss: 0.2700 - val_accuracy: 0.9116\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4041 - accuracy: 0.8757 - val_loss: 0.3307 - val_accuracy: 0.9066\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4229 - accuracy: 0.8698 - val_loss: 0.3182 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4253 - accuracy: 0.8692 - val_loss: 0.3453 - val_accuracy: 0.8918\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 55s 69ms/step - loss: 0.4390 - accuracy: 0.8676 - val_loss: 0.4953 - val_accuracy: 0.8592\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 55s 70ms/step - loss: 0.4536 - accuracy: 0.8599 - val_loss: 0.3262 - val_accuracy: 0.8886\n",
      "Duration: 0:09:06.728894\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b91ad678",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f6c0a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.3329 - accuracy: 0.8877 - val_loss: 0.2499 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.3421 - accuracy: 0.8882 - val_loss: 0.2738 - val_accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.3537 - accuracy: 0.8868 - val_loss: 0.2879 - val_accuracy: 0.9080\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.3661 - accuracy: 0.8823 - val_loss: 0.2969 - val_accuracy: 0.9074\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.3871 - accuracy: 0.8795 - val_loss: 0.2792 - val_accuracy: 0.9061\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.3971 - accuracy: 0.8761 - val_loss: 0.3187 - val_accuracy: 0.9006\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.4104 - accuracy: 0.8742 - val_loss: 0.3294 - val_accuracy: 0.8968\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.4332 - accuracy: 0.8670 - val_loss: 0.3409 - val_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.4444 - accuracy: 0.8639 - val_loss: 0.4029 - val_accuracy: 0.8905\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 59s 71ms/step - loss: 0.4423 - accuracy: 0.8609 - val_loss: 0.3259 - val_accuracy: 0.8915\n",
      "Duration: 0:09:39.404926\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "39f645c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee3c5163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 62s 70ms/step - loss: 0.3266 - accuracy: 0.8907 - val_loss: 0.2558 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 61s 69ms/step - loss: 0.3250 - accuracy: 0.8941 - val_loss: 0.2625 - val_accuracy: 0.9076\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3422 - accuracy: 0.8913 - val_loss: 0.2634 - val_accuracy: 0.9118\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 53s 61ms/step - loss: 0.3569 - accuracy: 0.8867 - val_loss: 0.2929 - val_accuracy: 0.9074\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 54s 61ms/step - loss: 0.3675 - accuracy: 0.8847 - val_loss: 0.3252 - val_accuracy: 0.8921\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 54s 61ms/step - loss: 0.3846 - accuracy: 0.8813 - val_loss: 0.2993 - val_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 53s 61ms/step - loss: 0.3948 - accuracy: 0.8778 - val_loss: 0.3210 - val_accuracy: 0.8943\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 53s 61ms/step - loss: 0.4146 - accuracy: 0.8745 - val_loss: 0.3167 - val_accuracy: 0.8952\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 55s 63ms/step - loss: 0.4195 - accuracy: 0.8711 - val_loss: 0.3547 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 54s 62ms/step - loss: 0.4365 - accuracy: 0.8658 - val_loss: 0.3212 - val_accuracy: 0.8904\n",
      "Duration: 0:09:19.536866\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "61d40f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "825c1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_se_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_se_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_se_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_se:\n",
    "    model.save(new_model_se_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95d86000",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del se_values\n",
    "    del top_images_by_se\n",
    "    del top_labels_by_se\n",
    "    del image_sets_se\n",
    "    del label_sets_se\n",
    "    del models_se\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fcf7c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349489"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11198aa3",
   "metadata": {},
   "source": [
    "## Training guided by Random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3581436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44452, 19510, 17221, 10503, 39361, 13991, 33222, 18588, 30257, 15715]\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_indexes =list(range(len(x_train_and_adversary)))\n",
    "random.shuffle(random_indexes)\n",
    "print(random_indexes[:10])\n",
    "print(len(random_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0eca574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"D:/guided-retraining/data/\"+dataset+\"/random_values.npy\"\n",
    "random_indexes = np.load(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5a735c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55998"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d13ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by random values\n",
    "top_images_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),x_train_and_adversary)\n",
    "top_labels_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1209ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_random = []\n",
    "label_sets_random = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_random)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_random)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_random)%m))\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m])\n",
    "    image_sets_random.append(top_images_by_random_n)\n",
    "    label_sets_random.append(top_labels_by_random_n)\n",
    "    print(len(top_images_by_random_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ed47a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3f03e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_random = []\n",
    "for i in range(len(label_sets_random)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_random.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "14912c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.3010 - accuracy: 0.8946 - val_loss: 0.2403 - val_accuracy: 0.9171\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 127ms/step - loss: 0.2678 - accuracy: 0.9093 - val_loss: 0.2423 - val_accuracy: 0.9150\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.2683 - accuracy: 0.9025 - val_loss: 0.2458 - val_accuracy: 0.9174\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 128ms/step - loss: 0.2358 - accuracy: 0.9179 - val_loss: 0.2643 - val_accuracy: 0.9131\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.2280 - accuracy: 0.9186 - val_loss: 0.2739 - val_accuracy: 0.9100\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.2181 - accuracy: 0.9218 - val_loss: 0.2800 - val_accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 135ms/step - loss: 0.2043 - accuracy: 0.9250 - val_loss: 0.2901 - val_accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 136ms/step - loss: 0.1900 - accuracy: 0.9321 - val_loss: 0.2839 - val_accuracy: 0.9106\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 7s 172ms/step - loss: 0.1920 - accuracy: 0.9296 - val_loss: 0.3001 - val_accuracy: 0.9101\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 0.1835 - accuracy: 0.9329 - val_loss: 0.2998 - val_accuracy: 0.9117\n",
      "Duration: 0:00:59.918792\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f28e27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 105ms/step - loss: 0.3309 - accuracy: 0.8852 - val_loss: 0.2488 - val_accuracy: 0.9102\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 0.3052 - accuracy: 0.8948 - val_loss: 0.2397 - val_accuracy: 0.9181\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 0.2876 - accuracy: 0.9018 - val_loss: 0.2488 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.2771 - accuracy: 0.9011 - val_loss: 0.2505 - val_accuracy: 0.9146\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 0.2549 - accuracy: 0.9102 - val_loss: 0.2741 - val_accuracy: 0.9096\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.2446 - accuracy: 0.9125 - val_loss: 0.2748 - val_accuracy: 0.9134\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 9s 100ms/step - loss: 0.2442 - accuracy: 0.9089 - val_loss: 0.2783 - val_accuracy: 0.9099\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 9s 101ms/step - loss: 0.2468 - accuracy: 0.9130 - val_loss: 0.2988 - val_accuracy: 0.9046\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 9s 101ms/step - loss: 0.2358 - accuracy: 0.9177 - val_loss: 0.3056 - val_accuracy: 0.9124\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.2241 - accuracy: 0.9229 - val_loss: 0.3078 - val_accuracy: 0.9063\n",
      "Duration: 0:01:29.174574\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a212da14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 0.3198 - accuracy: 0.8912 - val_loss: 0.2439 - val_accuracy: 0.9135\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.3023 - accuracy: 0.8994 - val_loss: 0.2446 - val_accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.2960 - accuracy: 0.8962 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.2956 - accuracy: 0.8993 - val_loss: 0.3503 - val_accuracy: 0.8849\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.2722 - accuracy: 0.9071 - val_loss: 0.2595 - val_accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.2745 - accuracy: 0.9050 - val_loss: 0.2733 - val_accuracy: 0.9115\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.2642 - accuracy: 0.9110 - val_loss: 0.2733 - val_accuracy: 0.9098\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.2612 - accuracy: 0.9094 - val_loss: 0.2812 - val_accuracy: 0.9079\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.2494 - accuracy: 0.9180 - val_loss: 0.2850 - val_accuracy: 0.9146\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.2568 - accuracy: 0.9121 - val_loss: 0.3080 - val_accuracy: 0.9109\n",
      "Duration: 0:01:59.815956\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "825cb011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3241 - accuracy: 0.8923 - val_loss: 0.2440 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3042 - accuracy: 0.8977 - val_loss: 0.2404 - val_accuracy: 0.9176\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.2948 - accuracy: 0.9010 - val_loss: 0.2590 - val_accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.2895 - accuracy: 0.9034 - val_loss: 0.2587 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.2846 - accuracy: 0.9058 - val_loss: 0.2487 - val_accuracy: 0.9151\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.2781 - accuracy: 0.9062 - val_loss: 0.2856 - val_accuracy: 0.9099\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.2727 - accuracy: 0.9093 - val_loss: 0.3021 - val_accuracy: 0.9104\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.2694 - accuracy: 0.9095 - val_loss: 0.2859 - val_accuracy: 0.9144\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.2674 - accuracy: 0.9121 - val_loss: 0.2717 - val_accuracy: 0.9128\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.2631 - accuracy: 0.9126 - val_loss: 0.2835 - val_accuracy: 0.9101\n",
      "Duration: 0:02:26.552940\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b6988483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 19s 80ms/step - loss: 0.3139 - accuracy: 0.8930 - val_loss: 0.2513 - val_accuracy: 0.9108\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2950 - accuracy: 0.8980 - val_loss: 0.2654 - val_accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.2948 - accuracy: 0.9001 - val_loss: 0.2693 - val_accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2838 - accuracy: 0.9056 - val_loss: 0.2594 - val_accuracy: 0.9166\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2866 - accuracy: 0.9027 - val_loss: 0.2878 - val_accuracy: 0.9121\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2911 - accuracy: 0.9059 - val_loss: 0.2728 - val_accuracy: 0.9136\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.2872 - accuracy: 0.9045 - val_loss: 0.2694 - val_accuracy: 0.9104\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2780 - accuracy: 0.9069 - val_loss: 0.2854 - val_accuracy: 0.9055\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2941 - accuracy: 0.9030 - val_loss: 0.2790 - val_accuracy: 0.9094\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 18s 81ms/step - loss: 0.2892 - accuracy: 0.9057 - val_loss: 0.3191 - val_accuracy: 0.9124\n",
      "Duration: 0:02:58.594434\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b5013c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.3154 - accuracy: 0.8905 - val_loss: 0.2468 - val_accuracy: 0.9115\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 0.3062 - accuracy: 0.8971 - val_loss: 0.2581 - val_accuracy: 0.9114\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 0.2958 - accuracy: 0.9008 - val_loss: 0.2798 - val_accuracy: 0.9089\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 0.2963 - accuracy: 0.9001 - val_loss: 0.2585 - val_accuracy: 0.9162\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 0.2980 - accuracy: 0.9019 - val_loss: 0.2758 - val_accuracy: 0.9099\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.2952 - accuracy: 0.9007 - val_loss: 0.2633 - val_accuracy: 0.9101\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 0.3024 - accuracy: 0.9010 - val_loss: 0.2637 - val_accuracy: 0.9081\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 21s 78ms/step - loss: 0.3020 - accuracy: 0.9020 - val_loss: 0.2960 - val_accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 20s 78ms/step - loss: 0.2943 - accuracy: 0.9049 - val_loss: 0.2906 - val_accuracy: 0.9088\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 0.3048 - accuracy: 0.9026 - val_loss: 0.2876 - val_accuracy: 0.9087\n",
      "Duration: 0:03:25.191492\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6af282f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 24s 75ms/step - loss: 0.3181 - accuracy: 0.8935 - val_loss: 0.2612 - val_accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.3086 - accuracy: 0.8948 - val_loss: 0.2497 - val_accuracy: 0.9154\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.3084 - accuracy: 0.8968 - val_loss: 0.2577 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.3044 - accuracy: 0.8986 - val_loss: 0.2666 - val_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.2958 - accuracy: 0.8990 - val_loss: 0.2868 - val_accuracy: 0.9076\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.2944 - accuracy: 0.9010 - val_loss: 0.2715 - val_accuracy: 0.9136\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.3003 - accuracy: 0.9019 - val_loss: 0.3260 - val_accuracy: 0.9056\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.3071 - accuracy: 0.9028 - val_loss: 0.2937 - val_accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.3131 - accuracy: 0.9007 - val_loss: 0.2840 - val_accuracy: 0.9039\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.3156 - accuracy: 0.8984 - val_loss: 0.3600 - val_accuracy: 0.9010\n",
      "Duration: 0:03:52.422791\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d29def12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.3133 - accuracy: 0.8940 - val_loss: 0.2433 - val_accuracy: 0.9161\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.3039 - accuracy: 0.8956 - val_loss: 0.2530 - val_accuracy: 0.9141\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 30s 87ms/step - loss: 0.3000 - accuracy: 0.9001 - val_loss: 0.2574 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 29s 83ms/step - loss: 0.3044 - accuracy: 0.9010 - val_loss: 0.2775 - val_accuracy: 0.9071\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 27s 77ms/step - loss: 0.2991 - accuracy: 0.9024 - val_loss: 0.2782 - val_accuracy: 0.9097\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 27s 77ms/step - loss: 0.3002 - accuracy: 0.9010 - val_loss: 0.2900 - val_accuracy: 0.9089\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 25s 73ms/step - loss: 0.3134 - accuracy: 0.9008 - val_loss: 0.2953 - val_accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.3108 - accuracy: 0.9004 - val_loss: 0.3415 - val_accuracy: 0.9035\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.3161 - accuracy: 0.8978 - val_loss: 0.2925 - val_accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.3244 - accuracy: 0.8971 - val_loss: 0.2950 - val_accuracy: 0.9016\n",
      "Duration: 0:04:28.500522\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "279e2866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 29s 71ms/step - loss: 0.3210 - accuracy: 0.8942 - val_loss: 0.2557 - val_accuracy: 0.9118\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 28s 72ms/step - loss: 0.3079 - accuracy: 0.8958 - val_loss: 0.2610 - val_accuracy: 0.9097\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 29s 73ms/step - loss: 0.3086 - accuracy: 0.8971 - val_loss: 0.2626 - val_accuracy: 0.9113\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 31s 79ms/step - loss: 0.3068 - accuracy: 0.8987 - val_loss: 0.2909 - val_accuracy: 0.9132\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.3149 - accuracy: 0.8995 - val_loss: 0.2822 - val_accuracy: 0.9105\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 33s 83ms/step - loss: 0.3164 - accuracy: 0.8976 - val_loss: 0.2765 - val_accuracy: 0.9069\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.3268 - accuracy: 0.8942 - val_loss: 0.2758 - val_accuracy: 0.9041\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 33s 83ms/step - loss: 0.3285 - accuracy: 0.8950 - val_loss: 0.2901 - val_accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.3374 - accuracy: 0.8954 - val_loss: 0.2871 - val_accuracy: 0.9088\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 33s 83ms/step - loss: 0.3455 - accuracy: 0.8915 - val_loss: 0.3623 - val_accuracy: 0.9004\n",
      "Duration: 0:05:11.892567\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1aec7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 5s 10ms/step - loss: 0.5032 - accuracy: 0.8342\n",
      "[0.5032416582107544, 0.8342142701148987]\n",
      "438/438 [==============================] - 5s 10ms/step - loss: 0.5032 - accuracy: 0.8342\n",
      "[0.5032416582107544, 0.8342142701148987]\n"
     ]
    }
   ],
   "source": [
    "print(models_random[8].evaluate(x_test_and_adversary,y_test_and_adversary))\n",
    "print(models_random[9].evaluate(x_test_and_adversary,y_test_and_adversary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4767ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 36s 80ms/step - loss: 0.3228 - accuracy: 0.8929 - val_loss: 0.2447 - val_accuracy: 0.9129\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 40s 92ms/step - loss: 0.3096 - accuracy: 0.8940 - val_loss: 0.2623 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 38s 86ms/step - loss: 0.3155 - accuracy: 0.8957 - val_loss: 0.2646 - val_accuracy: 0.9073\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3120 - accuracy: 0.8980 - val_loss: 0.2599 - val_accuracy: 0.9074\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 34s 79ms/step - loss: 0.3224 - accuracy: 0.8949 - val_loss: 0.2623 - val_accuracy: 0.9100\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 34s 78ms/step - loss: 0.3258 - accuracy: 0.8956 - val_loss: 0.2954 - val_accuracy: 0.8979\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.3319 - accuracy: 0.8970 - val_loss: 0.2829 - val_accuracy: 0.9067\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.3468 - accuracy: 0.8940 - val_loss: 0.3306 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 33s 75ms/step - loss: 0.3537 - accuracy: 0.8894 - val_loss: 0.4301 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.3523 - accuracy: 0.8929 - val_loss: 0.3705 - val_accuracy: 0.8991\n",
      "Duration: 0:05:52.953663\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n= 9\n",
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fb28909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 38s 77ms/step - loss: 0.3202 - accuracy: 0.8938 - val_loss: 0.2509 - val_accuracy: 0.9128\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 39s 82ms/step - loss: 0.3079 - accuracy: 0.8969 - val_loss: 0.2539 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 37s 78ms/step - loss: 0.3152 - accuracy: 0.8981 - val_loss: 0.2671 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.3192 - accuracy: 0.8965 - val_loss: 0.2653 - val_accuracy: 0.9078\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 41s 85ms/step - loss: 0.3229 - accuracy: 0.8973 - val_loss: 0.2655 - val_accuracy: 0.9038\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 39s 82ms/step - loss: 0.3287 - accuracy: 0.8937 - val_loss: 0.2725 - val_accuracy: 0.9105\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 42s 86ms/step - loss: 0.3332 - accuracy: 0.8941 - val_loss: 0.3185 - val_accuracy: 0.9087\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 46s 95ms/step - loss: 0.3431 - accuracy: 0.8915 - val_loss: 0.4229 - val_accuracy: 0.8896\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 42s 87ms/step - loss: 0.3495 - accuracy: 0.8896 - val_loss: 0.2927 - val_accuracy: 0.9037\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 42s 88ms/step - loss: 0.3590 - accuracy: 0.8880 - val_loss: 0.3357 - val_accuracy: 0.8999\n",
      "Duration: 0:06:44.942643\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0e5cdaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 38s 71ms/step - loss: 0.3203 - accuracy: 0.8917 - val_loss: 0.2651 - val_accuracy: 0.9124\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 44s 83ms/step - loss: 0.3148 - accuracy: 0.8964 - val_loss: 0.2668 - val_accuracy: 0.9063\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 43s 82ms/step - loss: 0.3189 - accuracy: 0.8960 - val_loss: 0.2534 - val_accuracy: 0.9142\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3251 - accuracy: 0.8960 - val_loss: 0.2534 - val_accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 45s 85ms/step - loss: 0.3262 - accuracy: 0.8955 - val_loss: 0.3231 - val_accuracy: 0.8940\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 41s 79ms/step - loss: 0.3441 - accuracy: 0.8913 - val_loss: 0.2912 - val_accuracy: 0.9013\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 39s 75ms/step - loss: 0.3456 - accuracy: 0.8915 - val_loss: 0.3084 - val_accuracy: 0.9016\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.3518 - accuracy: 0.8902 - val_loss: 0.2863 - val_accuracy: 0.9025\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.3647 - accuracy: 0.8911 - val_loss: 0.2873 - val_accuracy: 0.9011\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 45s 85ms/step - loss: 0.3723 - accuracy: 0.8878 - val_loss: 0.3478 - val_accuracy: 0.9005\n",
      "Duration: 0:06:56.713972\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a093e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 44s 76ms/step - loss: 0.3189 - accuracy: 0.8936 - val_loss: 0.2450 - val_accuracy: 0.9124\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 43s 76ms/step - loss: 0.3185 - accuracy: 0.8958 - val_loss: 0.2481 - val_accuracy: 0.9133\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 43s 75ms/step - loss: 0.3149 - accuracy: 0.8969 - val_loss: 0.2871 - val_accuracy: 0.9069\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.3336 - accuracy: 0.8926 - val_loss: 0.2711 - val_accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 46s 80ms/step - loss: 0.3374 - accuracy: 0.8930 - val_loss: 0.2779 - val_accuracy: 0.9104\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 46s 80ms/step - loss: 0.3492 - accuracy: 0.8880 - val_loss: 0.2885 - val_accuracy: 0.9069\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.3529 - accuracy: 0.8896 - val_loss: 0.2769 - val_accuracy: 0.9049\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 46s 81ms/step - loss: 0.3602 - accuracy: 0.8894 - val_loss: 0.2866 - val_accuracy: 0.9036\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 46s 81ms/step - loss: 0.3758 - accuracy: 0.8851 - val_loss: 0.2860 - val_accuracy: 0.9015\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 47s 82ms/step - loss: 0.3823 - accuracy: 0.8839 - val_loss: 0.3065 - val_accuracy: 0.8949\n",
      "Duration: 0:07:28.190014\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d59f257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 52s 83ms/step - loss: 0.3156 - accuracy: 0.8943 - val_loss: 0.2586 - val_accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 54s 88ms/step - loss: 0.3199 - accuracy: 0.8957 - val_loss: 0.2469 - val_accuracy: 0.9164\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 55s 90ms/step - loss: 0.3243 - accuracy: 0.8940 - val_loss: 0.3015 - val_accuracy: 0.9079\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 50s 82ms/step - loss: 0.3339 - accuracy: 0.8928 - val_loss: 0.2756 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 50s 81ms/step - loss: 0.3401 - accuracy: 0.8923 - val_loss: 0.2860 - val_accuracy: 0.9049\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 50s 81ms/step - loss: 0.3523 - accuracy: 0.8871 - val_loss: 0.2916 - val_accuracy: 0.9011\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 50s 81ms/step - loss: 0.3663 - accuracy: 0.8861 - val_loss: 0.2858 - val_accuracy: 0.9026\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 55s 90ms/step - loss: 0.3748 - accuracy: 0.8847 - val_loss: 0.3048 - val_accuracy: 0.8982\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 58s 94ms/step - loss: 0.3779 - accuracy: 0.8840 - val_loss: 0.3967 - val_accuracy: 0.8981\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 53s 86ms/step - loss: 0.3943 - accuracy: 0.8794 - val_loss: 0.3445 - val_accuracy: 0.8854\n",
      "Duration: 0:08:44.972615\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4b04c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 59s 88ms/step - loss: 0.3202 - accuracy: 0.8927 - val_loss: 0.2551 - val_accuracy: 0.9109\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 54s 83ms/step - loss: 0.3164 - accuracy: 0.8952 - val_loss: 0.2537 - val_accuracy: 0.9134\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 56s 85ms/step - loss: 0.3279 - accuracy: 0.8943 - val_loss: 0.3021 - val_accuracy: 0.9113\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.3351 - accuracy: 0.8931 - val_loss: 0.3220 - val_accuracy: 0.9021\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 56s 85ms/step - loss: 0.3531 - accuracy: 0.8893 - val_loss: 0.3248 - val_accuracy: 0.8970\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 0.3571 - accuracy: 0.8872 - val_loss: 0.3865 - val_accuracy: 0.8859\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 54s 82ms/step - loss: 0.3679 - accuracy: 0.8869 - val_loss: 0.2994 - val_accuracy: 0.8990\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 60s 91ms/step - loss: 0.3866 - accuracy: 0.8814 - val_loss: 0.3426 - val_accuracy: 0.8969\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 54s 83ms/step - loss: 0.3972 - accuracy: 0.8787 - val_loss: 0.2975 - val_accuracy: 0.8909\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 55s 83ms/step - loss: 0.4052 - accuracy: 0.8775 - val_loss: 0.3500 - val_accuracy: 0.8904\n",
      "Duration: 0:09:11.684091\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "230fb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 58s 82ms/step - loss: 0.3207 - accuracy: 0.8913 - val_loss: 0.2553 - val_accuracy: 0.9143\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 57s 81ms/step - loss: 0.3173 - accuracy: 0.8944 - val_loss: 0.2580 - val_accuracy: 0.9110\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 64s 91ms/step - loss: 0.3280 - accuracy: 0.8941 - val_loss: 0.2608 - val_accuracy: 0.9082\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 57s 81ms/step - loss: 0.3442 - accuracy: 0.8897 - val_loss: 0.2627 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 57s 82ms/step - loss: 0.3556 - accuracy: 0.8896 - val_loss: 0.3186 - val_accuracy: 0.9012\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 58s 83ms/step - loss: 0.3633 - accuracy: 0.8855 - val_loss: 0.2805 - val_accuracy: 0.9061\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 55s 78ms/step - loss: 0.3757 - accuracy: 0.8854 - val_loss: 0.3982 - val_accuracy: 0.8912\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 56s 79ms/step - loss: 0.3842 - accuracy: 0.8805 - val_loss: 0.3091 - val_accuracy: 0.8959\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 56s 80ms/step - loss: 0.3912 - accuracy: 0.8795 - val_loss: 0.3064 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 57s 82ms/step - loss: 0.4023 - accuracy: 0.8775 - val_loss: 0.3202 - val_accuracy: 0.8890\n",
      "Duration: 0:09:33.750143\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c52ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 66s 87ms/step - loss: 0.3239 - accuracy: 0.8918 - val_loss: 0.2519 - val_accuracy: 0.9117\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3247 - accuracy: 0.8941 - val_loss: 0.2764 - val_accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 63s 84ms/step - loss: 0.3374 - accuracy: 0.8916 - val_loss: 0.2833 - val_accuracy: 0.9126\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 62s 83ms/step - loss: 0.3580 - accuracy: 0.8878 - val_loss: 0.2736 - val_accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 61s 82ms/step - loss: 0.3644 - accuracy: 0.8843 - val_loss: 0.2977 - val_accuracy: 0.9032\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 60s 80ms/step - loss: 0.3755 - accuracy: 0.8828 - val_loss: 0.4185 - val_accuracy: 0.8840\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 58s 78ms/step - loss: 0.3841 - accuracy: 0.8814 - val_loss: 0.3150 - val_accuracy: 0.8942\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 57s 77ms/step - loss: 0.3996 - accuracy: 0.8769 - val_loss: 0.3082 - val_accuracy: 0.8957\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 58s 78ms/step - loss: 0.4067 - accuracy: 0.8758 - val_loss: 0.2964 - val_accuracy: 0.8952\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 59s 79ms/step - loss: 0.4160 - accuracy: 0.8711 - val_loss: 0.3192 - val_accuracy: 0.8897\n",
      "Duration: 0:10:10.133704\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9f44f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 66s 83ms/step - loss: 0.3180 - accuracy: 0.8930 - val_loss: 0.2506 - val_accuracy: 0.9108\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 63s 80ms/step - loss: 0.3150 - accuracy: 0.8949 - val_loss: 0.2651 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 63s 81ms/step - loss: 0.3297 - accuracy: 0.8933 - val_loss: 0.3274 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 63s 80ms/step - loss: 0.3495 - accuracy: 0.8903 - val_loss: 0.2832 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 63s 80ms/step - loss: 0.3596 - accuracy: 0.8870 - val_loss: 0.3139 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 63s 80ms/step - loss: 0.3772 - accuracy: 0.8832 - val_loss: 0.3476 - val_accuracy: 0.8951\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 65s 83ms/step - loss: 0.3928 - accuracy: 0.8788 - val_loss: 0.4219 - val_accuracy: 0.8785\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 74s 94ms/step - loss: 0.4009 - accuracy: 0.8757 - val_loss: 0.3259 - val_accuracy: 0.8897\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 70s 88ms/step - loss: 0.4077 - accuracy: 0.8757 - val_loss: 0.3304 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 73s 92ms/step - loss: 0.4197 - accuracy: 0.8715 - val_loss: 0.3313 - val_accuracy: 0.8866\n",
      "Duration: 0:11:03.346746\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66419a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d61ae9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 74s 88ms/step - loss: 0.3209 - accuracy: 0.8919 - val_loss: 0.2616 - val_accuracy: 0.9117\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 73s 87ms/step - loss: 0.3261 - accuracy: 0.8924 - val_loss: 0.2888 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 71s 85ms/step - loss: 0.3413 - accuracy: 0.8919 - val_loss: 0.2856 - val_accuracy: 0.9079\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 76s 92ms/step - loss: 0.3585 - accuracy: 0.8861 - val_loss: 0.2799 - val_accuracy: 0.9044\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 67s 80ms/step - loss: 0.3737 - accuracy: 0.8839 - val_loss: 0.3153 - val_accuracy: 0.9021\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 68s 82ms/step - loss: 0.3865 - accuracy: 0.8828 - val_loss: 0.3248 - val_accuracy: 0.8991\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 66s 79ms/step - loss: 0.3894 - accuracy: 0.8811 - val_loss: 0.3002 - val_accuracy: 0.8943\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 66s 79ms/step - loss: 0.4026 - accuracy: 0.8747 - val_loss: 0.4577 - val_accuracy: 0.8959\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 67s 80ms/step - loss: 0.4232 - accuracy: 0.8719 - val_loss: 0.3921 - val_accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 64s 77ms/step - loss: 0.4318 - accuracy: 0.8661 - val_loss: 0.4539 - val_accuracy: 0.8913\n",
      "Duration: 0:11:31.404265\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d844da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "486d063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 66s 74ms/step - loss: 0.3190 - accuracy: 0.8912 - val_loss: 0.2520 - val_accuracy: 0.9142\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 66s 75ms/step - loss: 0.3315 - accuracy: 0.8920 - val_loss: 0.2555 - val_accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 66s 75ms/step - loss: 0.3492 - accuracy: 0.8890 - val_loss: 0.2761 - val_accuracy: 0.9023\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 67s 76ms/step - loss: 0.3679 - accuracy: 0.8842 - val_loss: 0.2843 - val_accuracy: 0.9046\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 69s 78ms/step - loss: 0.3776 - accuracy: 0.8812 - val_loss: 0.3042 - val_accuracy: 0.8953\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 68s 78ms/step - loss: 0.3971 - accuracy: 0.8781 - val_loss: 0.2942 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 66s 76ms/step - loss: 0.4087 - accuracy: 0.8750 - val_loss: 0.3514 - val_accuracy: 0.8725\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 67s 77ms/step - loss: 0.4184 - accuracy: 0.8701 - val_loss: 0.3167 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 67s 77ms/step - loss: 0.4303 - accuracy: 0.8681 - val_loss: 0.3344 - val_accuracy: 0.8909\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 67s 77ms/step - loss: 0.4430 - accuracy: 0.8637 - val_loss: 0.3292 - val_accuracy: 0.8872\n",
      "Duration: 0:11:08.611294\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "24dc2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_random_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_random_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_random_e1\"\n",
    "\n",
    "i=9\n",
    "\n",
    "for model in models_random[i:]:\n",
    "    model.save(new_model_random_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d243087",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_random = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_random_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_random_e1_\"+str(i)\n",
    "        print(model_random_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_random_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_random.append(model)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "85078e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del random_indexes\n",
    "    del top_images_by_random\n",
    "    del top_labels_by_random\n",
    "    del image_sets_random\n",
    "    del label_sets_random\n",
    "    del models_random\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5a4c9d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391929"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a54b05",
   "metadata": {},
   "source": [
    "## Training guided by NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e53f2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC\n",
    "nc_values = []\n",
    "for i in range(1,17):\n",
    "    #save_dir = \"C:/Users/fjdur/Desktop/upc/project_notebooks/github_project/DL_notebooks/NC_values/nc_values_\"+str(i)+\".npy\"\n",
    "    save_dir = \"D:/guided-retraining/data/\"+dataset+\"/\"+dataset+\"_nc_values_\"+str(i)+\".npy\"\n",
    "\n",
    "    #print(save_dir_rand)\n",
    "    tmp_values = np.load(save_dir)\n",
    "    #print(tmp_values.shape)\n",
    "    nc_values = np.append(nc_values,tmp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637de522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55998,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "024f3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_images_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),x_train_and_adversary)\n",
    "top_labels_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),y_train_and_adversary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7490c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_nc = []\n",
    "label_sets_nc = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_nc)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_nc)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_nc)%m))\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m])\n",
    "    image_sets_nc.append(top_images_by_nc_n)\n",
    "    label_sets_nc.append(top_labels_by_nc_n)\n",
    "    print(len(top_images_by_nc_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a65e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_nc = []\n",
    "for i in range(len(label_sets_nc)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_nc.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0b6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 0.3872 - accuracy: 0.8886 - val_loss: 0.3002 - val_accuracy: 0.8904\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.3243 - accuracy: 0.9061 - val_loss: 0.2902 - val_accuracy: 0.8955\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.3043 - accuracy: 0.9071 - val_loss: 0.2837 - val_accuracy: 0.8971\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.2802 - accuracy: 0.9154 - val_loss: 0.3441 - val_accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 5s 126ms/step - loss: 0.2750 - accuracy: 0.9118 - val_loss: 0.3213 - val_accuracy: 0.8914\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 118ms/step - loss: 0.2492 - accuracy: 0.9250 - val_loss: 0.3245 - val_accuracy: 0.8937\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.2461 - accuracy: 0.9225 - val_loss: 0.3359 - val_accuracy: 0.8923\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.2378 - accuracy: 0.9207 - val_loss: 0.3496 - val_accuracy: 0.8902\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 116ms/step - loss: 0.2351 - accuracy: 0.9264 - val_loss: 0.3252 - val_accuracy: 0.8884\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.2185 - accuracy: 0.9286 - val_loss: 0.3861 - val_accuracy: 0.8886\n",
      "Duration: 0:00:52.319866\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4f3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 0.3348 - accuracy: 0.9120 - val_loss: 0.2864 - val_accuracy: 0.8974\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 0.2816 - accuracy: 0.9186 - val_loss: 0.2990 - val_accuracy: 0.8955\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.2660 - accuracy: 0.9229 - val_loss: 0.3424 - val_accuracy: 0.8890\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.2508 - accuracy: 0.9237 - val_loss: 0.3335 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.2378 - accuracy: 0.9325 - val_loss: 0.3845 - val_accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 9s 102ms/step - loss: 0.2360 - accuracy: 0.9314 - val_loss: 0.3877 - val_accuracy: 0.8884\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.2197 - accuracy: 0.9325 - val_loss: 0.4198 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.2107 - accuracy: 0.9389 - val_loss: 0.4285 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 0.2074 - accuracy: 0.9371 - val_loss: 0.4186 - val_accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 0.2162 - accuracy: 0.9366 - val_loss: 0.5124 - val_accuracy: 0.8784\n",
      "Duration: 0:01:24.629409\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f72b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.2471 - accuracy: 0.9336 - val_loss: 0.3089 - val_accuracy: 0.8984\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.2327 - accuracy: 0.9386 - val_loss: 0.4270 - val_accuracy: 0.8822\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.2255 - accuracy: 0.9388 - val_loss: 0.3819 - val_accuracy: 0.8901\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.2061 - accuracy: 0.9433 - val_loss: 0.3392 - val_accuracy: 0.8937\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.2079 - accuracy: 0.9402 - val_loss: 0.4260 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.1929 - accuracy: 0.9469 - val_loss: 0.4710 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 10s 72ms/step - loss: 0.1902 - accuracy: 0.9482 - val_loss: 0.5135 - val_accuracy: 0.8702\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.1903 - accuracy: 0.9445 - val_loss: 0.5308 - val_accuracy: 0.8634\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.1881 - accuracy: 0.9461 - val_loss: 0.7509 - val_accuracy: 0.8158\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.1800 - accuracy: 0.9501 - val_loss: 0.6765 - val_accuracy: 0.8524\n",
      "Duration: 0:01:40.233630\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08f19179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 13s 69ms/step - loss: 0.2461 - accuracy: 0.9334 - val_loss: 0.3136 - val_accuracy: 0.8971\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.2160 - accuracy: 0.9399 - val_loss: 0.3211 - val_accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.2024 - accuracy: 0.9425 - val_loss: 0.3448 - val_accuracy: 0.8996\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.2000 - accuracy: 0.9444 - val_loss: 0.4421 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.1981 - accuracy: 0.9451 - val_loss: 0.4775 - val_accuracy: 0.8812\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.1904 - accuracy: 0.9438 - val_loss: 0.5032 - val_accuracy: 0.8777\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.1888 - accuracy: 0.9461 - val_loss: 0.5660 - val_accuracy: 0.8503\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.1959 - accuracy: 0.9476 - val_loss: 0.7206 - val_accuracy: 0.8188\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.2027 - accuracy: 0.9484 - val_loss: 0.8802 - val_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.1954 - accuracy: 0.9470 - val_loss: 1.0011 - val_accuracy: 0.7806\n",
      "Duration: 0:01:59.507803\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf71df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2345 - accuracy: 0.9378 - val_loss: 0.2932 - val_accuracy: 0.9001\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.2043 - accuracy: 0.9436 - val_loss: 0.3473 - val_accuracy: 0.8963\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 16s 75ms/step - loss: 0.2045 - accuracy: 0.9451 - val_loss: 0.4696 - val_accuracy: 0.8845\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.1941 - accuracy: 0.9462 - val_loss: 0.4672 - val_accuracy: 0.8746\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.1941 - accuracy: 0.9466 - val_loss: 0.5975 - val_accuracy: 0.8489\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.1945 - accuracy: 0.9461 - val_loss: 0.6841 - val_accuracy: 0.8239\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.1914 - accuracy: 0.9491 - val_loss: 0.8476 - val_accuracy: 0.7818\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.1882 - accuracy: 0.9491 - val_loss: 0.8187 - val_accuracy: 0.7836\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.1908 - accuracy: 0.9483 - val_loss: 1.3117 - val_accuracy: 0.7819\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 15s 71ms/step - loss: 0.1935 - accuracy: 0.9494 - val_loss: 1.1926 - val_accuracy: 0.7773\n",
      "Duration: 0:02:30.323229\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72c612a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 21s 76ms/step - loss: 0.2237 - accuracy: 0.9424 - val_loss: 0.3290 - val_accuracy: 0.9003\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 24s 91ms/step - loss: 0.2034 - accuracy: 0.9458 - val_loss: 0.3362 - val_accuracy: 0.8928\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 0.1956 - accuracy: 0.9449 - val_loss: 0.4391 - val_accuracy: 0.8682\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 21s 79ms/step - loss: 0.1970 - accuracy: 0.9471 - val_loss: 0.8643 - val_accuracy: 0.7854\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 19s 72ms/step - loss: 0.1961 - accuracy: 0.9470 - val_loss: 0.8440 - val_accuracy: 0.7850\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.1886 - accuracy: 0.9496 - val_loss: 0.9370 - val_accuracy: 0.7832\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 19s 71ms/step - loss: 0.1898 - accuracy: 0.9505 - val_loss: 1.5838 - val_accuracy: 0.7863\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 19s 74ms/step - loss: 0.1894 - accuracy: 0.9490 - val_loss: 0.9739 - val_accuracy: 0.7751\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 20s 74ms/step - loss: 0.1838 - accuracy: 0.9504 - val_loss: 1.4532 - val_accuracy: 0.7825\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 18s 70ms/step - loss: 0.1938 - accuracy: 0.9522 - val_loss: 1.9227 - val_accuracy: 0.7779\n",
      "Duration: 0:03:17.995947\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "534d3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 24s 77ms/step - loss: 0.2024 - accuracy: 0.9476 - val_loss: 0.3649 - val_accuracy: 0.8851\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 22s 73ms/step - loss: 0.1944 - accuracy: 0.9491 - val_loss: 0.4432 - val_accuracy: 0.8697\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 21s 70ms/step - loss: 0.1946 - accuracy: 0.9494 - val_loss: 0.5508 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 22s 71ms/step - loss: 0.1941 - accuracy: 0.9504 - val_loss: 0.9640 - val_accuracy: 0.7954\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 22s 71ms/step - loss: 0.1944 - accuracy: 0.9512 - val_loss: 1.0716 - val_accuracy: 0.7836\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 22s 72ms/step - loss: 0.1982 - accuracy: 0.9501 - val_loss: 1.4798 - val_accuracy: 0.7723\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 22s 73ms/step - loss: 0.1935 - accuracy: 0.9519 - val_loss: 1.7683 - val_accuracy: 0.7754\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.1925 - accuracy: 0.9505 - val_loss: 1.6610 - val_accuracy: 0.7712\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 24s 77ms/step - loss: 0.2008 - accuracy: 0.9507 - val_loss: 1.6035 - val_accuracy: 0.7803\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.2154 - accuracy: 0.9458 - val_loss: 1.5337 - val_accuracy: 0.7725\n",
      "Duration: 0:03:45.621399\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1266750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.1948 - accuracy: 0.9482 - val_loss: 0.3444 - val_accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.1877 - accuracy: 0.9523 - val_loss: 0.4269 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.1840 - accuracy: 0.9509 - val_loss: 0.4689 - val_accuracy: 0.8416\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.1802 - accuracy: 0.9521 - val_loss: 0.8158 - val_accuracy: 0.7910\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.1886 - accuracy: 0.9498 - val_loss: 1.2974 - val_accuracy: 0.7884\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.1857 - accuracy: 0.9524 - val_loss: 1.2054 - val_accuracy: 0.7895\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 27s 78ms/step - loss: 0.1908 - accuracy: 0.9529 - val_loss: 0.9889 - val_accuracy: 0.7764\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.1970 - accuracy: 0.9501 - val_loss: 1.8209 - val_accuracy: 0.7796\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 32s 92ms/step - loss: 0.2113 - accuracy: 0.9486 - val_loss: 3.3527 - val_accuracy: 0.7784\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.2117 - accuracy: 0.9473 - val_loss: 2.3597 - val_accuracy: 0.7748\n",
      "Duration: 0:04:18.451158\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f83db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 34s 86ms/step - loss: 0.1956 - accuracy: 0.9494 - val_loss: 0.3461 - val_accuracy: 0.8969\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.1838 - accuracy: 0.9511 - val_loss: 0.4200 - val_accuracy: 0.8918\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 30s 77ms/step - loss: 0.1879 - accuracy: 0.9509 - val_loss: 0.4354 - val_accuracy: 0.8872\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 29s 75ms/step - loss: 0.1809 - accuracy: 0.9519 - val_loss: 0.5839 - val_accuracy: 0.8603\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 29s 73ms/step - loss: 0.1823 - accuracy: 0.9517 - val_loss: 1.1329 - val_accuracy: 0.7897\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 28s 72ms/step - loss: 0.1916 - accuracy: 0.9513 - val_loss: 1.0067 - val_accuracy: 0.7863\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 29s 73ms/step - loss: 0.1976 - accuracy: 0.9511 - val_loss: 1.0952 - val_accuracy: 0.7862\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 29s 73ms/step - loss: 0.1973 - accuracy: 0.9508 - val_loss: 1.9469 - val_accuracy: 0.7801\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 29s 74ms/step - loss: 0.2056 - accuracy: 0.9485 - val_loss: 1.5266 - val_accuracy: 0.7751\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 31s 78ms/step - loss: 0.2138 - accuracy: 0.9469 - val_loss: 2.2711 - val_accuracy: 0.7701\n",
      "Duration: 0:04:59.666576\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b788eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 35s 77ms/step - loss: 0.1912 - accuracy: 0.9494 - val_loss: 0.3156 - val_accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 33s 74ms/step - loss: 0.1838 - accuracy: 0.9515 - val_loss: 0.4424 - val_accuracy: 0.8874\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.1887 - accuracy: 0.9503 - val_loss: 0.3999 - val_accuracy: 0.8929\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 34s 77ms/step - loss: 0.1824 - accuracy: 0.9492 - val_loss: 0.4081 - val_accuracy: 0.8879\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 33s 75ms/step - loss: 0.1950 - accuracy: 0.9484 - val_loss: 0.4385 - val_accuracy: 0.8798\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 30s 69ms/step - loss: 0.1992 - accuracy: 0.9505 - val_loss: 0.4851 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 31s 72ms/step - loss: 0.2090 - accuracy: 0.9473 - val_loss: 0.5091 - val_accuracy: 0.8738\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 31s 70ms/step - loss: 0.2096 - accuracy: 0.9474 - val_loss: 0.7464 - val_accuracy: 0.8470\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 32s 73ms/step - loss: 0.2175 - accuracy: 0.9469 - val_loss: 0.8594 - val_accuracy: 0.8496\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.2264 - accuracy: 0.9459 - val_loss: 0.7944 - val_accuracy: 0.8359\n",
      "Duration: 0:05:23.613022\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b73a982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 36s 73ms/step - loss: 0.2028 - accuracy: 0.9471 - val_loss: 0.3475 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 34s 70ms/step - loss: 0.1933 - accuracy: 0.9498 - val_loss: 0.4069 - val_accuracy: 0.8899\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 32s 67ms/step - loss: 0.1873 - accuracy: 0.9494 - val_loss: 0.3845 - val_accuracy: 0.8954\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 33s 68ms/step - loss: 0.1940 - accuracy: 0.9497 - val_loss: 0.3908 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 33s 68ms/step - loss: 0.1966 - accuracy: 0.9498 - val_loss: 0.4248 - val_accuracy: 0.8804\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 33s 68ms/step - loss: 0.2074 - accuracy: 0.9463 - val_loss: 0.4409 - val_accuracy: 0.8814\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 39s 82ms/step - loss: 0.2045 - accuracy: 0.9475 - val_loss: 0.4053 - val_accuracy: 0.8753\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 36s 76ms/step - loss: 0.2171 - accuracy: 0.9445 - val_loss: 0.5276 - val_accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 33s 69ms/step - loss: 0.2281 - accuracy: 0.9420 - val_loss: 0.6112 - val_accuracy: 0.8801\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 35s 73ms/step - loss: 0.2343 - accuracy: 0.9432 - val_loss: 0.8192 - val_accuracy: 0.8779\n",
      "Duration: 0:05:44.077091\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9367822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 36s 68ms/step - loss: 0.2016 - accuracy: 0.9461 - val_loss: 0.3267 - val_accuracy: 0.8986\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.1955 - accuracy: 0.9482 - val_loss: 0.3703 - val_accuracy: 0.8973\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2032 - accuracy: 0.9471 - val_loss: 0.4613 - val_accuracy: 0.8890\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2104 - accuracy: 0.9448 - val_loss: 0.3873 - val_accuracy: 0.8859\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2135 - accuracy: 0.9452 - val_loss: 0.3926 - val_accuracy: 0.8897\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.2220 - accuracy: 0.9439 - val_loss: 0.6071 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2291 - accuracy: 0.9421 - val_loss: 0.4300 - val_accuracy: 0.8827\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.2332 - accuracy: 0.9434 - val_loss: 0.4202 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.2463 - accuracy: 0.9399 - val_loss: 0.6025 - val_accuracy: 0.8726\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.2485 - accuracy: 0.9391 - val_loss: 0.4307 - val_accuracy: 0.8773\n",
      "Duration: 0:05:50.342916\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7fcec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 38s 66ms/step - loss: 0.2041 - accuracy: 0.9452 - val_loss: 0.3403 - val_accuracy: 0.9009\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 38s 66ms/step - loss: 0.1971 - accuracy: 0.9467 - val_loss: 0.3918 - val_accuracy: 0.8946\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 37s 65ms/step - loss: 0.1983 - accuracy: 0.9468 - val_loss: 0.5298 - val_accuracy: 0.8855\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 37s 66ms/step - loss: 0.2064 - accuracy: 0.9456 - val_loss: 0.3998 - val_accuracy: 0.8974\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 37s 65ms/step - loss: 0.2111 - accuracy: 0.9460 - val_loss: 0.4708 - val_accuracy: 0.8920\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 37s 65ms/step - loss: 0.2241 - accuracy: 0.9434 - val_loss: 0.4739 - val_accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 38s 67ms/step - loss: 0.2306 - accuracy: 0.9420 - val_loss: 0.4328 - val_accuracy: 0.8883\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 38s 67ms/step - loss: 0.2309 - accuracy: 0.9426 - val_loss: 0.4406 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 38s 66ms/step - loss: 0.2510 - accuracy: 0.9380 - val_loss: 0.4239 - val_accuracy: 0.8685\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 38s 66ms/step - loss: 0.2532 - accuracy: 0.9370 - val_loss: 0.4109 - val_accuracy: 0.8751\n",
      "Duration: 0:06:16.097132\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e832bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 42s 67ms/step - loss: 0.2007 - accuracy: 0.9447 - val_loss: 0.3259 - val_accuracy: 0.9007\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 40s 66ms/step - loss: 0.1995 - accuracy: 0.9456 - val_loss: 0.3592 - val_accuracy: 0.8944\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 41s 67ms/step - loss: 0.2047 - accuracy: 0.9459 - val_loss: 0.3175 - val_accuracy: 0.8936\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 41s 66ms/step - loss: 0.2095 - accuracy: 0.9456 - val_loss: 0.3492 - val_accuracy: 0.8949\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2194 - accuracy: 0.9435 - val_loss: 0.4462 - val_accuracy: 0.8911\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2240 - accuracy: 0.9429 - val_loss: 0.3945 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2340 - accuracy: 0.9420 - val_loss: 0.6076 - val_accuracy: 0.8827\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 39s 64ms/step - loss: 0.2448 - accuracy: 0.9383 - val_loss: 0.5381 - val_accuracy: 0.8783\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2517 - accuracy: 0.9369 - val_loss: 0.6055 - val_accuracy: 0.8828\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2560 - accuracy: 0.9352 - val_loss: 0.4760 - val_accuracy: 0.8808\n",
      "Duration: 0:06:42.340575\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95525d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 45s 67ms/step - loss: 0.2079 - accuracy: 0.9439 - val_loss: 0.3486 - val_accuracy: 0.8963\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 43s 66ms/step - loss: 0.2050 - accuracy: 0.9443 - val_loss: 0.3894 - val_accuracy: 0.9019\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 44s 66ms/step - loss: 0.2124 - accuracy: 0.9430 - val_loss: 0.3212 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 42s 64ms/step - loss: 0.2210 - accuracy: 0.9414 - val_loss: 0.3539 - val_accuracy: 0.8927\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 42s 64ms/step - loss: 0.2282 - accuracy: 0.9399 - val_loss: 0.4186 - val_accuracy: 0.8941\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 0.2412 - accuracy: 0.9390 - val_loss: 0.5003 - val_accuracy: 0.8879\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.2548 - accuracy: 0.9370 - val_loss: 0.3856 - val_accuracy: 0.8804\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 0.2638 - accuracy: 0.9339 - val_loss: 0.4517 - val_accuracy: 0.8815\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.2669 - accuracy: 0.9321 - val_loss: 0.5148 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 46s 70ms/step - loss: 0.2791 - accuracy: 0.9295 - val_loss: 0.5535 - val_accuracy: 0.8833\n",
      "Duration: 0:07:12.354277\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c55183",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c41a1606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.2135 - accuracy: 0.9395 - val_loss: 0.3043 - val_accuracy: 0.9041\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.2211 - accuracy: 0.9392 - val_loss: 0.3092 - val_accuracy: 0.8999\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.2239 - accuracy: 0.9390 - val_loss: 0.3560 - val_accuracy: 0.9016\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.2435 - accuracy: 0.9353 - val_loss: 0.3361 - val_accuracy: 0.8991\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.2449 - accuracy: 0.9358 - val_loss: 0.4002 - val_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.2572 - accuracy: 0.9326 - val_loss: 0.4113 - val_accuracy: 0.8938\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.2695 - accuracy: 0.9303 - val_loss: 0.3788 - val_accuracy: 0.8872\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.2755 - accuracy: 0.9280 - val_loss: 0.4222 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.2796 - accuracy: 0.9268 - val_loss: 0.4382 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.2810 - accuracy: 0.9258 - val_loss: 0.4345 - val_accuracy: 0.8817\n",
      "Duration: 0:08:54.467199\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c801b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 60s 80ms/step - loss: 0.2406 - accuracy: 0.9297 - val_loss: 0.2706 - val_accuracy: 0.9081\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 56s 76ms/step - loss: 0.2397 - accuracy: 0.9302 - val_loss: 0.2980 - val_accuracy: 0.9051\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 56s 75ms/step - loss: 0.2516 - accuracy: 0.9287 - val_loss: 0.3219 - val_accuracy: 0.9057\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 56s 75ms/step - loss: 0.2661 - accuracy: 0.9256 - val_loss: 0.3506 - val_accuracy: 0.8926\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 55s 75ms/step - loss: 0.2779 - accuracy: 0.9247 - val_loss: 0.3700 - val_accuracy: 0.8946\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 53s 71ms/step - loss: 0.2893 - accuracy: 0.9204 - val_loss: 0.4768 - val_accuracy: 0.8887\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 55s 74ms/step - loss: 0.2966 - accuracy: 0.9186 - val_loss: 0.4524 - val_accuracy: 0.8888\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 50s 67ms/step - loss: 0.3086 - accuracy: 0.9161 - val_loss: 0.3464 - val_accuracy: 0.8881\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.3221 - accuracy: 0.9124 - val_loss: 0.3520 - val_accuracy: 0.8901\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.3321 - accuracy: 0.9099 - val_loss: 0.4629 - val_accuracy: 0.8830\n",
      "Duration: 0:08:59.093664\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ab4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a689e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 54s 67ms/step - loss: 0.2649 - accuracy: 0.9191 - val_loss: 0.2758 - val_accuracy: 0.9109\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.2659 - accuracy: 0.9191 - val_loss: 0.3057 - val_accuracy: 0.9057\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 51s 64ms/step - loss: 0.2820 - accuracy: 0.9161 - val_loss: 0.2963 - val_accuracy: 0.9026\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 51s 64ms/step - loss: 0.2886 - accuracy: 0.9172 - val_loss: 0.4186 - val_accuracy: 0.8848\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 51s 64ms/step - loss: 0.3067 - accuracy: 0.9121 - val_loss: 0.3289 - val_accuracy: 0.8965\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.3149 - accuracy: 0.9093 - val_loss: 0.3795 - val_accuracy: 0.8993\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.3286 - accuracy: 0.9075 - val_loss: 0.3160 - val_accuracy: 0.8975\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 50s 63ms/step - loss: 0.3481 - accuracy: 0.9021 - val_loss: 0.3529 - val_accuracy: 0.8860\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.3541 - accuracy: 0.9015 - val_loss: 0.3889 - val_accuracy: 0.8724\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 50s 63ms/step - loss: 0.3608 - accuracy: 0.9004 - val_loss: 0.3731 - val_accuracy: 0.8826\n",
      "Duration: 0:08:32.518862\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a79f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 53s 63ms/step - loss: 0.2896 - accuracy: 0.9075 - val_loss: 0.2721 - val_accuracy: 0.9086\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 53s 64ms/step - loss: 0.2917 - accuracy: 0.9074 - val_loss: 0.2696 - val_accuracy: 0.9113\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 54s 65ms/step - loss: 0.3065 - accuracy: 0.9051 - val_loss: 0.3024 - val_accuracy: 0.9052\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 55s 66ms/step - loss: 0.3159 - accuracy: 0.9064 - val_loss: 0.3101 - val_accuracy: 0.9024\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 54s 65ms/step - loss: 0.3319 - accuracy: 0.8998 - val_loss: 0.2988 - val_accuracy: 0.9041\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.3486 - accuracy: 0.8976 - val_loss: 0.3421 - val_accuracy: 0.8984\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.3606 - accuracy: 0.8942 - val_loss: 0.3386 - val_accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 54s 65ms/step - loss: 0.3728 - accuracy: 0.8920 - val_loss: 0.3393 - val_accuracy: 0.8965\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 55s 66ms/step - loss: 0.3738 - accuracy: 0.8899 - val_loss: 0.3970 - val_accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 53s 64ms/step - loss: 0.3870 - accuracy: 0.8852 - val_loss: 0.3433 - val_accuracy: 0.8906\n",
      "Duration: 0:09:06.680781\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a19fc597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 57s 64ms/step - loss: 0.3194 - accuracy: 0.8930 - val_loss: 0.2420 - val_accuracy: 0.9142\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 56s 63ms/step - loss: 0.3253 - accuracy: 0.8933 - val_loss: 0.2598 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 56s 64ms/step - loss: 0.3366 - accuracy: 0.8913 - val_loss: 0.2692 - val_accuracy: 0.9079\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 57s 65ms/step - loss: 0.3523 - accuracy: 0.8887 - val_loss: 0.2901 - val_accuracy: 0.9027\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 57s 65ms/step - loss: 0.3694 - accuracy: 0.8848 - val_loss: 0.2828 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 56s 63ms/step - loss: 0.3894 - accuracy: 0.8812 - val_loss: 0.3162 - val_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 56s 64ms/step - loss: 0.3971 - accuracy: 0.8769 - val_loss: 0.3746 - val_accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 56s 64ms/step - loss: 0.4084 - accuracy: 0.8760 - val_loss: 0.3213 - val_accuracy: 0.8946\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 56s 64ms/step - loss: 0.4200 - accuracy: 0.8730 - val_loss: 0.3233 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 56s 64ms/step - loss: 0.4270 - accuracy: 0.8692 - val_loss: 0.3125 - val_accuracy: 0.8900\n",
      "Duration: 0:09:20.800272\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b86726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43bd398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C2/fashion_model_c2_may_nc_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_nc_dir  = \"D:/models/aug_22/\"+dataset+\"/C2/\"+dataset+\"_model_c2_may_nc_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_nc:\n",
    "    model.save(new_model_nc_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_nc = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_nc_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_nc_e1\"+str(i)\n",
    "        print(model_nc_dir)\n",
    "        model =utils.My_model(dataset,True,model_nc_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_nc.append(model)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47e2faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del nc_values\n",
    "    del top_images_by_nc\n",
    "    del top_labels_by_nc\n",
    "    del image_sets_nc\n",
    "    del label_sets_nc\n",
    "    del models_nc\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98f93725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327980"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73f695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
