{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f216e2a2",
   "metadata": {},
   "source": [
    "# Ordering by metrics and retraining phase\n",
    "\n",
    "## Dataset: CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790af13b",
   "metadata": {},
   "source": [
    "## Experiment configuration 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a98552",
   "metadata": {},
   "source": [
    "## Configuration 1\n",
    "\t1. Incremental guided retraining starting from scratch using the new adversarial inputs and original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90383afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --user tensorflow==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1386e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tf.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0aa2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ == '2.5.0' # Version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa923a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\guided-retraining\\utils\n"
     ]
    }
   ],
   "source": [
    "cd ../utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723735cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "keras\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# utils for project\n",
    "import utils_guided_retraining2 as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6a307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd '../notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1bd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fashion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2b3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/fashion/x_train.npy\n",
      "x_set len:  48999\n",
      "D:/guided-retraining/data/fashion/y_train.npy\n",
      "y_set len:  48999\n",
      "D:/guided-retraining/data/fashion/x_val.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/fashion/y_val.npy\n",
      "y_set len:  14000\n",
      "D:/guided-retraining/data/fashion/x_test.npy\n",
      "x_set len:  7001\n",
      "D:/guided-retraining/data/fashion/y_test.npy\n",
      "y_set len:  7001\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = utils.get_data(dataset,\"Train\",True)\n",
    "x_val,y_val = utils.get_data(dataset,\"Val\",True)\n",
    "x_test,y_test = utils.get_data(dataset,\"Test\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f6f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary.npy\n",
      "x_set len:  55998\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary_labels.npy\n",
      "y_set len:  55998\n"
     ]
    }
   ],
   "source": [
    "x_train_and_adversary,y_train_and_adversary = utils.get_data(dataset,\"Train_and_adversary\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dcdf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_training = x_train_and_adversary[len(x_train):]\n",
    "print(len(x_adversary_training))\n",
    "y_adversary_training = y_train_and_adversary[len(y_train):]\n",
    "\n",
    "print(len(y_adversary_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8fd2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "y_set len:  14000\n"
     ]
    }
   ],
   "source": [
    "# Obtaining adversarial examples for testing \n",
    "x_test_and_adversary,y_test_and_adversary = utils.get_adversarial_data(dataset,'Test_adversarial',True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27698e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_test = x_test_and_adversary[len(x_test):]\n",
    "print(len(x_adversary_test))\n",
    "y_adversary_test = y_test_and_adversary[len(y_test):]\n",
    "\n",
    "print(len(y_adversary_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb4e3b",
   "metadata": {},
   "source": [
    "## ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2fa13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fashion'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1560941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model \n",
    "\n",
    "model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06/\"\n",
    "if(dataset == 'gtsrb'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06\"\n",
    "elif(dataset == 'intel'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/intel_model_21_10\"\n",
    "elif(dataset == 'mnist'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/models2\"\n",
    "elif(dataset == 'cifar'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/model_02\"\n",
    "elif(dataset == 'fashion'):\n",
    "    model_dir = \"D:/guided-retraining/models/model_fashion_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5478616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "Model loaded correctly\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "model_original = utils.My_model(dataset,True, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f5589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea0bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55998, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_and_adversary.shape)\n",
    "len(x_train_and_adversary)//20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983373d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = 2800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edd1c7",
   "metadata": {},
   "source": [
    "## Loading LSA and DSA values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd62896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/lsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62da548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe684c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_values = np.load(lsa_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e725932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0ec186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtaining top n images by LSA values\n",
    "top_images_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),x_train_and_adversary)\n",
    "top_labels_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),y_train_and_adversary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f9ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "262a4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_lsa = []\n",
    "label_sets_lsa = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_lsa)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_lsa)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_lsa)%m))\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m])\n",
    "    image_sets_lsa.append(top_images_by_lsa_n)\n",
    "    label_sets_lsa.append(top_labels_by_lsa_n)\n",
    "    print(len(top_images_by_lsa_n))\n",
    "    n += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16d9a882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55998"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_lsa[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55e3a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a68e",
   "metadata": {},
   "source": [
    "## Training guided by LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa4de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_sets_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daef1b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_lsa = []\n",
    "for i in range(len(label_sets_lsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False,None)\n",
    "    model.compile_model()\n",
    "    models_lsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3665e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 6s 121ms/step - loss: 1.1453 - accuracy: 0.6325 - val_loss: 1.8995 - val_accuracy: 0.2497\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.6790 - accuracy: 0.7607 - val_loss: 1.5452 - val_accuracy: 0.4357\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 5s 117ms/step - loss: 0.5767 - accuracy: 0.8093 - val_loss: 1.4715 - val_accuracy: 0.3969\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.5099 - accuracy: 0.8325 - val_loss: 1.2761 - val_accuracy: 0.4926\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 5s 119ms/step - loss: 0.4569 - accuracy: 0.8507 - val_loss: 1.2127 - val_accuracy: 0.5292\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 121ms/step - loss: 0.4175 - accuracy: 0.8686 - val_loss: 1.2049 - val_accuracy: 0.5411\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 131ms/step - loss: 0.3992 - accuracy: 0.8732 - val_loss: 1.0491 - val_accuracy: 0.5804\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 128ms/step - loss: 0.3584 - accuracy: 0.8875 - val_loss: 1.1034 - val_accuracy: 0.5306\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 126ms/step - loss: 0.3519 - accuracy: 0.8907 - val_loss: 1.0033 - val_accuracy: 0.6113\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 7s 159ms/step - loss: 0.3206 - accuracy: 0.8939 - val_loss: 0.9482 - val_accuracy: 0.6651\n",
      "Duration: 0:00:55.589501\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2f79099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 102ms/step - loss: 0.6502 - accuracy: 0.8209 - val_loss: 2.2610 - val_accuracy: 0.1167\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 8s 97ms/step - loss: 0.3499 - accuracy: 0.8914 - val_loss: 2.0406 - val_accuracy: 0.3086\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 8s 93ms/step - loss: 0.2875 - accuracy: 0.9182 - val_loss: 1.7993 - val_accuracy: 0.3264\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 8s 94ms/step - loss: 0.2419 - accuracy: 0.9268 - val_loss: 1.5435 - val_accuracy: 0.3779\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 0.2319 - accuracy: 0.9334 - val_loss: 1.4411 - val_accuracy: 0.4149\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 8s 95ms/step - loss: 0.2071 - accuracy: 0.9379 - val_loss: 1.4150 - val_accuracy: 0.4315\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 8s 96ms/step - loss: 0.1891 - accuracy: 0.9443 - val_loss: 1.2942 - val_accuracy: 0.4514\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 9s 101ms/step - loss: 0.1809 - accuracy: 0.9468 - val_loss: 1.2778 - val_accuracy: 0.4578\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 0.1669 - accuracy: 0.9500 - val_loss: 1.3444 - val_accuracy: 0.4800\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 0.1576 - accuracy: 0.9520 - val_loss: 1.0877 - val_accuracy: 0.5552\n",
      "Duration: 0:01:26.334854\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9f7fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.5751 - accuracy: 0.8293 - val_loss: 1.9227 - val_accuracy: 0.3011\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.3214 - accuracy: 0.9004 - val_loss: 2.0457 - val_accuracy: 0.3510\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.2559 - accuracy: 0.9251 - val_loss: 1.7393 - val_accuracy: 0.3885\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 11s 87ms/step - loss: 0.2214 - accuracy: 0.9335 - val_loss: 1.4281 - val_accuracy: 0.4799\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.1961 - accuracy: 0.9421 - val_loss: 1.3229 - val_accuracy: 0.4995\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.1793 - accuracy: 0.9473 - val_loss: 1.2338 - val_accuracy: 0.5113\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 93ms/step - loss: 0.1628 - accuracy: 0.9532 - val_loss: 1.4290 - val_accuracy: 0.4832\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.1555 - accuracy: 0.9532 - val_loss: 1.1760 - val_accuracy: 0.5158\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 11s 86ms/step - loss: 0.1411 - accuracy: 0.9557 - val_loss: 1.0911 - val_accuracy: 0.5331\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 88ms/step - loss: 0.1308 - accuracy: 0.9579 - val_loss: 1.1000 - val_accuracy: 0.5211\n",
      "Duration: 0:01:57.397998\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f1f84df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 15s 79ms/step - loss: 0.4625 - accuracy: 0.8601 - val_loss: 1.8190 - val_accuracy: 0.3098\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 14s 80ms/step - loss: 0.2423 - accuracy: 0.9309 - val_loss: 1.5366 - val_accuracy: 0.4510\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1961 - accuracy: 0.9470 - val_loss: 1.6069 - val_accuracy: 0.4362\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1715 - accuracy: 0.9511 - val_loss: 1.5012 - val_accuracy: 0.4571\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.1511 - accuracy: 0.9595 - val_loss: 1.3051 - val_accuracy: 0.5050\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1391 - accuracy: 0.9602 - val_loss: 1.2415 - val_accuracy: 0.5133\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1296 - accuracy: 0.9638 - val_loss: 1.3769 - val_accuracy: 0.4783\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1251 - accuracy: 0.9640 - val_loss: 1.2142 - val_accuracy: 0.5080\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1146 - accuracy: 0.9661 - val_loss: 1.1292 - val_accuracy: 0.5321\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.1081 - accuracy: 0.9680 - val_loss: 1.2358 - val_accuracy: 0.4921\n",
      "Duration: 0:02:22.205870\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23e0459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 18s 77ms/step - loss: 0.5881 - accuracy: 0.8365 - val_loss: 1.6930 - val_accuracy: 0.3957\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.3484 - accuracy: 0.9054 - val_loss: 1.6368 - val_accuracy: 0.4396\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 18s 80ms/step - loss: 0.2985 - accuracy: 0.9174 - val_loss: 1.3664 - val_accuracy: 0.4990\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.2599 - accuracy: 0.9254 - val_loss: 1.2926 - val_accuracy: 0.5331\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 0.2453 - accuracy: 0.9296 - val_loss: 1.2990 - val_accuracy: 0.5061\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.2345 - accuracy: 0.9313 - val_loss: 1.1300 - val_accuracy: 0.5672\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.2198 - accuracy: 0.9361 - val_loss: 1.1572 - val_accuracy: 0.5833\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.2100 - accuracy: 0.9384 - val_loss: 1.0192 - val_accuracy: 0.5796\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.1987 - accuracy: 0.9401 - val_loss: 0.9346 - val_accuracy: 0.6157\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 17s 78ms/step - loss: 0.1957 - accuracy: 0.9430 - val_loss: 1.3338 - val_accuracy: 0.5735\n",
      "Duration: 0:02:59.783310\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eccb083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 21s 76ms/step - loss: 0.5555 - accuracy: 0.8623 - val_loss: 1.9241 - val_accuracy: 0.3872\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.3357 - accuracy: 0.9137 - val_loss: 1.5666 - val_accuracy: 0.4426\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 20s 77ms/step - loss: 0.2825 - accuracy: 0.9264 - val_loss: 1.4229 - val_accuracy: 0.5259\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.2632 - accuracy: 0.9305 - val_loss: 1.2935 - val_accuracy: 0.5459\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.2437 - accuracy: 0.9353 - val_loss: 1.1506 - val_accuracy: 0.5473\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.2380 - accuracy: 0.9371 - val_loss: 1.4674 - val_accuracy: 0.5284\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.2281 - accuracy: 0.9382 - val_loss: 1.1205 - val_accuracy: 0.5763\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.2220 - accuracy: 0.9400 - val_loss: 1.3428 - val_accuracy: 0.5676\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.2178 - accuracy: 0.9418 - val_loss: 1.1464 - val_accuracy: 0.5852\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 20s 76ms/step - loss: 0.2153 - accuracy: 0.9410 - val_loss: 1.1857 - val_accuracy: 0.5804\n",
      "Duration: 0:03:30.417828\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c148cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.6067 - accuracy: 0.8281 - val_loss: 1.7611 - val_accuracy: 0.4636\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.3456 - accuracy: 0.9068 - val_loss: 1.2362 - val_accuracy: 0.5479\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.2957 - accuracy: 0.9202 - val_loss: 1.1722 - val_accuracy: 0.5665\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.2688 - accuracy: 0.9251 - val_loss: 1.5242 - val_accuracy: 0.5582\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 23s 76ms/step - loss: 0.2588 - accuracy: 0.9281 - val_loss: 1.1525 - val_accuracy: 0.5871\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 23s 73ms/step - loss: 0.2406 - accuracy: 0.9324 - val_loss: 1.3167 - val_accuracy: 0.5799\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 23s 73ms/step - loss: 0.2330 - accuracy: 0.9352 - val_loss: 1.2196 - val_accuracy: 0.5893\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 23s 75ms/step - loss: 0.2277 - accuracy: 0.9354 - val_loss: 1.1052 - val_accuracy: 0.5929\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 23s 74ms/step - loss: 0.2234 - accuracy: 0.9379 - val_loss: 1.0255 - val_accuracy: 0.6076\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 22s 73ms/step - loss: 0.2249 - accuracy: 0.9378 - val_loss: 1.3728 - val_accuracy: 0.5791\n",
      "Duration: 0:03:47.607478\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e472398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 26s 72ms/step - loss: 0.5927 - accuracy: 0.8271 - val_loss: 1.9035 - val_accuracy: 0.4774\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.3371 - accuracy: 0.9107 - val_loss: 1.3978 - val_accuracy: 0.5378\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.2818 - accuracy: 0.9255 - val_loss: 1.3106 - val_accuracy: 0.5570\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2573 - accuracy: 0.9297 - val_loss: 1.4116 - val_accuracy: 0.5795\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2478 - accuracy: 0.9321 - val_loss: 1.0586 - val_accuracy: 0.6021\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2354 - accuracy: 0.9346 - val_loss: 1.0367 - val_accuracy: 0.6069\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2331 - accuracy: 0.9362 - val_loss: 1.0105 - val_accuracy: 0.6104\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.2248 - accuracy: 0.9383 - val_loss: 1.1177 - val_accuracy: 0.5988\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 27s 76ms/step - loss: 0.2276 - accuracy: 0.9373 - val_loss: 0.9779 - val_accuracy: 0.6093\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 26s 74ms/step - loss: 0.2200 - accuracy: 0.9400 - val_loss: 1.0524 - val_accuracy: 0.6085\n",
      "Duration: 0:04:13.312821\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5cdc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 29s 71ms/step - loss: 0.5571 - accuracy: 0.8387 - val_loss: 1.5977 - val_accuracy: 0.4784\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.3021 - accuracy: 0.9218 - val_loss: 1.4667 - val_accuracy: 0.5331\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2506 - accuracy: 0.9339 - val_loss: 1.2457 - val_accuracy: 0.5576\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2357 - accuracy: 0.9378 - val_loss: 1.1268 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 28s 72ms/step - loss: 0.2244 - accuracy: 0.9394 - val_loss: 1.2313 - val_accuracy: 0.5611\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2206 - accuracy: 0.9417 - val_loss: 1.1001 - val_accuracy: 0.5797\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2097 - accuracy: 0.9429 - val_loss: 1.0530 - val_accuracy: 0.5909\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2074 - accuracy: 0.9431 - val_loss: 1.1478 - val_accuracy: 0.5846\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 28s 70ms/step - loss: 0.2086 - accuracy: 0.9440 - val_loss: 1.3820 - val_accuracy: 0.5618\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 28s 71ms/step - loss: 0.2107 - accuracy: 0.9440 - val_loss: 1.5057 - val_accuracy: 0.5833\n",
      "Duration: 0:04:40.398144\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6edd628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 32s 70ms/step - loss: 0.5255 - accuracy: 0.8521 - val_loss: 1.4894 - val_accuracy: 0.4832\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 31s 70ms/step - loss: 0.2798 - accuracy: 0.9292 - val_loss: 1.3062 - val_accuracy: 0.5343\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 261s 596ms/step - loss: 0.2398 - accuracy: 0.9375 - val_loss: 1.3707 - val_accuracy: 0.5762\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 31s 72ms/step - loss: 0.2257 - accuracy: 0.9428 - val_loss: 1.1767 - val_accuracy: 0.5815\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 27s 61ms/step - loss: 0.2146 - accuracy: 0.9446 - val_loss: 1.0815 - val_accuracy: 0.5932\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 27s 61ms/step - loss: 0.2083 - accuracy: 0.9454 - val_loss: 1.1912 - val_accuracy: 0.5951\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 28s 63ms/step - loss: 0.2083 - accuracy: 0.9453 - val_loss: 1.2714 - val_accuracy: 0.5826\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 27s 62ms/step - loss: 0.2058 - accuracy: 0.9439 - val_loss: 1.6097 - val_accuracy: 0.5838\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 27s 62ms/step - loss: 0.2072 - accuracy: 0.9460 - val_loss: 1.4018 - val_accuracy: 0.5802\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 27s 62ms/step - loss: 0.2024 - accuracy: 0.9459 - val_loss: 0.9580 - val_accuracy: 0.5958\n",
      "Duration: 0:08:36.910574\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b03a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 31s 63ms/step - loss: 0.5651 - accuracy: 0.8395 - val_loss: 1.3847 - val_accuracy: 0.5624\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 30s 62ms/step - loss: 0.3192 - accuracy: 0.9126 - val_loss: 0.9948 - val_accuracy: 0.5707\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 30s 62ms/step - loss: 0.2813 - accuracy: 0.9204 - val_loss: 1.2220 - val_accuracy: 0.5737\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 30s 62ms/step - loss: 0.2568 - accuracy: 0.9254 - val_loss: 1.1455 - val_accuracy: 0.5776\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.2447 - accuracy: 0.9283 - val_loss: 0.9489 - val_accuracy: 0.6184\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.2386 - accuracy: 0.9317 - val_loss: 0.9590 - val_accuracy: 0.5856\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.2405 - accuracy: 0.9331 - val_loss: 1.1464 - val_accuracy: 0.6347\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.2299 - accuracy: 0.9362 - val_loss: 0.9778 - val_accuracy: 0.6174\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.2361 - accuracy: 0.9354 - val_loss: 1.9907 - val_accuracy: 0.5854\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 30s 62ms/step - loss: 0.2376 - accuracy: 0.9364 - val_loss: 1.7099 - val_accuracy: 0.6008\n",
      "Duration: 0:04:58.087808\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a437cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 33s 62ms/step - loss: 0.5886 - accuracy: 0.8311 - val_loss: 1.3274 - val_accuracy: 0.5676\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 33s 62ms/step - loss: 0.3339 - accuracy: 0.9111 - val_loss: 1.2207 - val_accuracy: 0.5720\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 33s 64ms/step - loss: 0.2930 - accuracy: 0.9197 - val_loss: 1.1146 - val_accuracy: 0.5746\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 34s 64ms/step - loss: 0.2757 - accuracy: 0.9232 - val_loss: 1.1016 - val_accuracy: 0.5768\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 34s 65ms/step - loss: 0.2686 - accuracy: 0.9261 - val_loss: 1.2227 - val_accuracy: 0.5777\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2580 - accuracy: 0.9277 - val_loss: 1.3556 - val_accuracy: 0.6002\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 35s 66ms/step - loss: 0.2578 - accuracy: 0.9307 - val_loss: 1.0696 - val_accuracy: 0.6076\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.2587 - accuracy: 0.9306 - val_loss: 1.1387 - val_accuracy: 0.5991\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 36s 68ms/step - loss: 0.2556 - accuracy: 0.9316 - val_loss: 0.9098 - val_accuracy: 0.6570\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 36s 69ms/step - loss: 0.2499 - accuracy: 0.9330 - val_loss: 1.2338 - val_accuracy: 0.5954\n",
      "Duration: 0:05:44.030325\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f350a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 41s 71ms/step - loss: 0.6537 - accuracy: 0.7980 - val_loss: 1.3016 - val_accuracy: 0.5955\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 40s 70ms/step - loss: 0.4036 - accuracy: 0.8818 - val_loss: 0.9973 - val_accuracy: 0.6078\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 39s 69ms/step - loss: 0.3548 - accuracy: 0.8923 - val_loss: 0.8514 - val_accuracy: 0.6344\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 39s 69ms/step - loss: 0.3304 - accuracy: 0.8984 - val_loss: 0.9412 - val_accuracy: 0.6440\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 39s 69ms/step - loss: 0.3184 - accuracy: 0.9027 - val_loss: 0.9720 - val_accuracy: 0.6458\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 39s 69ms/step - loss: 0.3111 - accuracy: 0.9045 - val_loss: 1.0099 - val_accuracy: 0.6274\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 40s 70ms/step - loss: 0.3115 - accuracy: 0.9061 - val_loss: 0.8648 - val_accuracy: 0.6384\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 39s 68ms/step - loss: 0.3041 - accuracy: 0.9083 - val_loss: 1.0169 - val_accuracy: 0.6449\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 39s 68ms/step - loss: 0.3098 - accuracy: 0.9069 - val_loss: 0.8481 - val_accuracy: 0.6550\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 39s 69ms/step - loss: 0.3061 - accuracy: 0.9090 - val_loss: 1.0152 - val_accuracy: 0.6497\n",
      "Duration: 0:06:33.148015\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e44708f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 42s 68ms/step - loss: 0.6760 - accuracy: 0.7864 - val_loss: 1.0099 - val_accuracy: 0.6289\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 42s 68ms/step - loss: 0.4192 - accuracy: 0.8743 - val_loss: 0.8760 - val_accuracy: 0.6421\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 41s 68ms/step - loss: 0.3625 - accuracy: 0.8896 - val_loss: 0.8179 - val_accuracy: 0.6530\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 41s 67ms/step - loss: 0.3435 - accuracy: 0.8965 - val_loss: 0.9336 - val_accuracy: 0.6529\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 42s 68ms/step - loss: 0.3307 - accuracy: 0.9010 - val_loss: 0.7191 - val_accuracy: 0.6551\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 41s 67ms/step - loss: 0.3210 - accuracy: 0.9050 - val_loss: 0.7941 - val_accuracy: 0.6596\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 42s 69ms/step - loss: 0.3163 - accuracy: 0.9058 - val_loss: 1.1358 - val_accuracy: 0.6588\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 46s 75ms/step - loss: 0.3123 - accuracy: 0.9085 - val_loss: 0.7796 - val_accuracy: 0.6662\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.3157 - accuracy: 0.9100 - val_loss: 0.7091 - val_accuracy: 0.6674\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.3108 - accuracy: 0.9119 - val_loss: 1.1834 - val_accuracy: 0.6653\n",
      "Duration: 0:07:11.966340\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eedcb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.7616 - accuracy: 0.7421 - val_loss: 0.9044 - val_accuracy: 0.6905\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4756 - accuracy: 0.8432 - val_loss: 0.8097 - val_accuracy: 0.7167\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.4168 - accuracy: 0.8659 - val_loss: 0.7265 - val_accuracy: 0.7201\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3885 - accuracy: 0.8740 - val_loss: 0.7810 - val_accuracy: 0.7312\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3648 - accuracy: 0.8822 - val_loss: 0.6732 - val_accuracy: 0.7276\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.3598 - accuracy: 0.8841 - val_loss: 0.6091 - val_accuracy: 0.7439\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3551 - accuracy: 0.8885 - val_loss: 0.8819 - val_accuracy: 0.7354\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3547 - accuracy: 0.8907 - val_loss: 0.6783 - val_accuracy: 0.7276\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 50s 75ms/step - loss: 0.3616 - accuracy: 0.8905 - val_loss: 0.7250 - val_accuracy: 0.6984\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3571 - accuracy: 0.8889 - val_loss: 0.6365 - val_accuracy: 0.7419\n",
      "Duration: 0:08:22.023051\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7137d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.7527 - accuracy: 0.7439 - val_loss: 0.7593 - val_accuracy: 0.6878\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.4589 - accuracy: 0.8522 - val_loss: 0.5288 - val_accuracy: 0.7837\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 52s 75ms/step - loss: 0.4042 - accuracy: 0.8707 - val_loss: 0.4997 - val_accuracy: 0.8065\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3797 - accuracy: 0.8808 - val_loss: 0.4528 - val_accuracy: 0.8127\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3645 - accuracy: 0.8853 - val_loss: 0.4799 - val_accuracy: 0.8372\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 52s 75ms/step - loss: 0.3578 - accuracy: 0.8907 - val_loss: 0.5499 - val_accuracy: 0.7995\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 52s 75ms/step - loss: 0.3577 - accuracy: 0.8919 - val_loss: 0.4129 - val_accuracy: 0.8577\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3541 - accuracy: 0.8915 - val_loss: 0.3914 - val_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3522 - accuracy: 0.8932 - val_loss: 0.5748 - val_accuracy: 0.8105\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 52s 74ms/step - loss: 0.3587 - accuracy: 0.8917 - val_loss: 0.5025 - val_accuracy: 0.8221\n",
      "Duration: 0:08:43.221037\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad003a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb8f82be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 47s 62ms/step - loss: 0.7702 - accuracy: 0.7280 - val_loss: 0.5123 - val_accuracy: 0.8216\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 45s 61ms/step - loss: 0.4866 - accuracy: 0.8348 - val_loss: 0.4223 - val_accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 45s 61ms/step - loss: 0.4153 - accuracy: 0.8582 - val_loss: 0.3770 - val_accuracy: 0.8774\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 45s 61ms/step - loss: 0.3979 - accuracy: 0.8689 - val_loss: 0.3510 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 45s 61ms/step - loss: 0.3859 - accuracy: 0.8723 - val_loss: 0.3252 - val_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 46s 61ms/step - loss: 0.3736 - accuracy: 0.8785 - val_loss: 0.3319 - val_accuracy: 0.8896\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 45s 61ms/step - loss: 0.3728 - accuracy: 0.8800 - val_loss: 0.3951 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 46s 62ms/step - loss: 0.3717 - accuracy: 0.8796 - val_loss: 0.3721 - val_accuracy: 0.8831\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 46s 61ms/step - loss: 0.3763 - accuracy: 0.8805 - val_loss: 0.4397 - val_accuracy: 0.8789\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 46s 62ms/step - loss: 0.3799 - accuracy: 0.8804 - val_loss: 0.3840 - val_accuracy: 0.8859\n",
      "Duration: 0:07:37.327033\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e104a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff11737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 48s 59ms/step - loss: 0.7781 - accuracy: 0.7306 - val_loss: 0.6109 - val_accuracy: 0.7729\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.4847 - accuracy: 0.8376 - val_loss: 0.4372 - val_accuracy: 0.8623\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.4238 - accuracy: 0.8599 - val_loss: 0.3844 - val_accuracy: 0.8722\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.4052 - accuracy: 0.8687 - val_loss: 0.4283 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.3989 - accuracy: 0.8696 - val_loss: 0.3270 - val_accuracy: 0.8882\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.3949 - accuracy: 0.8730 - val_loss: 0.4917 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 47s 59ms/step - loss: 0.3940 - accuracy: 0.8726 - val_loss: 0.4197 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.4038 - accuracy: 0.8713 - val_loss: 0.4071 - val_accuracy: 0.8633\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 50s 64ms/step - loss: 0.4011 - accuracy: 0.8721 - val_loss: 0.4088 - val_accuracy: 0.8586\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.4060 - accuracy: 0.8709 - val_loss: 0.3715 - val_accuracy: 0.8750\n",
      "Duration: 0:07:52.283108\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17c860ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8737c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 57s 67ms/step - loss: 0.7907 - accuracy: 0.7208 - val_loss: 0.3970 - val_accuracy: 0.8577\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.4837 - accuracy: 0.8355 - val_loss: 0.3350 - val_accuracy: 0.8779\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4242 - accuracy: 0.8609 - val_loss: 0.3354 - val_accuracy: 0.8791\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.3995 - accuracy: 0.8689 - val_loss: 0.2987 - val_accuracy: 0.8920\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.3830 - accuracy: 0.8762 - val_loss: 0.3267 - val_accuracy: 0.8946\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.3799 - accuracy: 0.8788 - val_loss: 0.2848 - val_accuracy: 0.8995\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3764 - accuracy: 0.8788 - val_loss: 0.2925 - val_accuracy: 0.8957\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3784 - accuracy: 0.8799 - val_loss: 0.3683 - val_accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3822 - accuracy: 0.8798 - val_loss: 0.2874 - val_accuracy: 0.8959\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.3817 - accuracy: 0.8791 - val_loss: 0.3240 - val_accuracy: 0.8897\n",
      "Duration: 0:09:24.957202\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c79e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "787a45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 60s 67ms/step - loss: 0.7241 - accuracy: 0.7477 - val_loss: 0.3741 - val_accuracy: 0.8689\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.4549 - accuracy: 0.8468 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3978 - accuracy: 0.8691 - val_loss: 0.2876 - val_accuracy: 0.8959\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3767 - accuracy: 0.8772 - val_loss: 0.2917 - val_accuracy: 0.8973\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3695 - accuracy: 0.8803 - val_loss: 0.2799 - val_accuracy: 0.9026\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3642 - accuracy: 0.8848 - val_loss: 0.2872 - val_accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3608 - accuracy: 0.8858 - val_loss: 0.2884 - val_accuracy: 0.8983\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3581 - accuracy: 0.8869 - val_loss: 0.2981 - val_accuracy: 0.8959\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3705 - accuracy: 0.8814 - val_loss: 0.2887 - val_accuracy: 0.8957\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3696 - accuracy: 0.8848 - val_loss: 0.3017 - val_accuracy: 0.9011\n",
      "Duration: 0:09:53.525242\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fe2527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb139a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cf4ae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_lsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_lsa_dir  = \"D:/models/gtsrb_models/C1/gtsrb_model_c1_sep_lsa_e2\"\n",
    "new_model_lsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_lsa_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_lsa:\n",
    "    model.save(new_model_lsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52746ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "759bc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del lsa_values\n",
    "    del top_images_by_lsa\n",
    "    del top_labels_by_lsa\n",
    "    del image_sets_lsa\n",
    "    del label_sets_lsa\n",
    "    del models_lsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9b28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "402aa433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45211"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c44d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_lsa = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(10,20):\n",
    "        #model_lsa_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_lsa_e1_\"+str(i)\n",
    "        print(model_lsa_dir)\n",
    "        model =utils.My_model(dataset,True,model_lsa_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_lsa.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ef06e",
   "metadata": {},
   "source": [
    "## Training guided by DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14fc6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/dsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "585cd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_values = np.load(dsa_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5944946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_images_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),x_train_and_adversary)\n",
    "top_labels_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "099c7fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dsa = []\n",
    "label_sets_dsa = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_dsa)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dsa)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dsa)%m))\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m])\n",
    "    image_sets_dsa.append(top_images_by_dsa_n)\n",
    "    label_sets_dsa.append(top_labels_by_dsa_n)\n",
    "    print(len(top_images_by_dsa_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8713d09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_dsa = []\n",
    "for i in range(len(label_sets_dsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False,None)\n",
    "    model.compile_model()\n",
    "    models_dsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9990e037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 150ms/step - loss: 1.8784 - accuracy: 0.3300 - val_loss: 1.4872 - val_accuracy: 0.4785\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 148ms/step - loss: 1.4385 - accuracy: 0.4832 - val_loss: 1.3142 - val_accuracy: 0.5044\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.2605 - accuracy: 0.5493 - val_loss: 1.0855 - val_accuracy: 0.5669\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 149ms/step - loss: 1.1339 - accuracy: 0.5868 - val_loss: 0.9088 - val_accuracy: 0.6212\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.0536 - accuracy: 0.6125 - val_loss: 0.7704 - val_accuracy: 0.6588\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 148ms/step - loss: 0.9753 - accuracy: 0.6300 - val_loss: 0.7518 - val_accuracy: 0.6514\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 0.9434 - accuracy: 0.6464 - val_loss: 0.7016 - val_accuracy: 0.6783\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 0.8801 - accuracy: 0.6729 - val_loss: 0.6238 - val_accuracy: 0.7844\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 6s 148ms/step - loss: 0.8466 - accuracy: 0.6921 - val_loss: 0.5400 - val_accuracy: 0.8118\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 149ms/step - loss: 0.7853 - accuracy: 0.7050 - val_loss: 0.5397 - val_accuracy: 0.8079\n",
      "Duration: 0:01:05.270165\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c24fa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 109ms/step - loss: 1.5299 - accuracy: 0.4404 - val_loss: 0.7328 - val_accuracy: 0.7407\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.9777 - accuracy: 0.6459 - val_loss: 0.5871 - val_accuracy: 0.7754\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.8387 - accuracy: 0.6961 - val_loss: 0.5521 - val_accuracy: 0.8063\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7550 - accuracy: 0.7307 - val_loss: 0.4770 - val_accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7114 - accuracy: 0.7411 - val_loss: 0.4691 - val_accuracy: 0.8244\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.6583 - accuracy: 0.7650 - val_loss: 0.4464 - val_accuracy: 0.8340\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 0.6052 - accuracy: 0.7807 - val_loss: 0.4361 - val_accuracy: 0.8388\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.5877 - accuracy: 0.7884 - val_loss: 0.4373 - val_accuracy: 0.8345\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.5450 - accuracy: 0.8025 - val_loss: 0.4127 - val_accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.5361 - accuracy: 0.8084 - val_loss: 0.4073 - val_accuracy: 0.8539\n",
      "Duration: 0:01:34.194723\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2582ba35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 93ms/step - loss: 1.3076 - accuracy: 0.5254 - val_loss: 0.6146 - val_accuracy: 0.7606\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.8000 - accuracy: 0.7092 - val_loss: 0.5389 - val_accuracy: 0.7938\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.6708 - accuracy: 0.7568 - val_loss: 0.4914 - val_accuracy: 0.8076\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.6016 - accuracy: 0.7876 - val_loss: 0.4566 - val_accuracy: 0.8243\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.5573 - accuracy: 0.8002 - val_loss: 0.4228 - val_accuracy: 0.8421\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.5221 - accuracy: 0.8171 - val_loss: 0.4103 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.4880 - accuracy: 0.8304 - val_loss: 0.3970 - val_accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 92ms/step - loss: 0.4567 - accuracy: 0.8401 - val_loss: 0.3937 - val_accuracy: 0.8588\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 13s 96ms/step - loss: 0.4364 - accuracy: 0.8482 - val_loss: 0.3980 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.4108 - accuracy: 0.8635 - val_loss: 0.3974 - val_accuracy: 0.8639\n",
      "Duration: 0:02:02.438877\n"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62d686d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 16s 84ms/step - loss: 1.1731 - accuracy: 0.5765 - val_loss: 0.5805 - val_accuracy: 0.7980\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.7243 - accuracy: 0.7433 - val_loss: 0.4886 - val_accuracy: 0.8231\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.6038 - accuracy: 0.7826 - val_loss: 0.4284 - val_accuracy: 0.8441\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.5355 - accuracy: 0.8112 - val_loss: 0.4008 - val_accuracy: 0.8511\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.4971 - accuracy: 0.8294 - val_loss: 0.3752 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.4583 - accuracy: 0.8413 - val_loss: 0.3711 - val_accuracy: 0.8658\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.4258 - accuracy: 0.8479 - val_loss: 0.3634 - val_accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.3988 - accuracy: 0.8629 - val_loss: 0.3410 - val_accuracy: 0.8758\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.3797 - accuracy: 0.8723 - val_loss: 0.3447 - val_accuracy: 0.8771\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.3584 - accuracy: 0.8790 - val_loss: 0.3604 - val_accuracy: 0.8729\n",
      "Duration: 0:02:27.544949\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4cbf21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 19s 82ms/step - loss: 1.0917 - accuracy: 0.6026 - val_loss: 0.5447 - val_accuracy: 0.7907\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.6685 - accuracy: 0.7623 - val_loss: 0.4575 - val_accuracy: 0.8361\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.5697 - accuracy: 0.8002 - val_loss: 0.4029 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.5076 - accuracy: 0.8239 - val_loss: 0.3893 - val_accuracy: 0.8517\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.4704 - accuracy: 0.8401 - val_loss: 0.3552 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.4316 - accuracy: 0.8494 - val_loss: 0.3583 - val_accuracy: 0.8711\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 0.4124 - accuracy: 0.8601 - val_loss: 0.3403 - val_accuracy: 0.8765\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.3850 - accuracy: 0.8706 - val_loss: 0.3392 - val_accuracy: 0.8774\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 18s 84ms/step - loss: 0.3676 - accuracy: 0.8769 - val_loss: 0.3282 - val_accuracy: 0.8856\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.3511 - accuracy: 0.8846 - val_loss: 0.3344 - val_accuracy: 0.8829\n",
      "Duration: 0:03:01.263218\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abf7808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 22s 81ms/step - loss: 1.0501 - accuracy: 0.6218 - val_loss: 0.5188 - val_accuracy: 0.8066\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 0.6317 - accuracy: 0.7814 - val_loss: 0.4387 - val_accuracy: 0.8424\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 21s 82ms/step - loss: 0.5399 - accuracy: 0.8171 - val_loss: 0.3804 - val_accuracy: 0.8628\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 0.4786 - accuracy: 0.8381 - val_loss: 0.3866 - val_accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 0.4401 - accuracy: 0.8529 - val_loss: 0.3573 - val_accuracy: 0.8739\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.4127 - accuracy: 0.8620 - val_loss: 0.3375 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.3898 - accuracy: 0.8714 - val_loss: 0.3150 - val_accuracy: 0.8870\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.3659 - accuracy: 0.8800 - val_loss: 0.3348 - val_accuracy: 0.8829\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.3475 - accuracy: 0.8857 - val_loss: 0.3161 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 22s 85ms/step - loss: 0.3349 - accuracy: 0.8939 - val_loss: 0.3173 - val_accuracy: 0.8885\n",
      "Duration: 0:03:39.019809\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0e62cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 27s 84ms/step - loss: 1.0179 - accuracy: 0.6356 - val_loss: 0.5479 - val_accuracy: 0.7861\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 26s 85ms/step - loss: 0.6187 - accuracy: 0.7869 - val_loss: 0.4399 - val_accuracy: 0.8376\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.5243 - accuracy: 0.8214 - val_loss: 0.3839 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.4713 - accuracy: 0.8423 - val_loss: 0.3730 - val_accuracy: 0.8677\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.4242 - accuracy: 0.8574 - val_loss: 0.3329 - val_accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.4073 - accuracy: 0.8615 - val_loss: 0.3369 - val_accuracy: 0.8796\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.3855 - accuracy: 0.8712 - val_loss: 0.3559 - val_accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.3624 - accuracy: 0.8803 - val_loss: 0.3249 - val_accuracy: 0.8851\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.3448 - accuracy: 0.8854 - val_loss: 0.3160 - val_accuracy: 0.8872\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.3305 - accuracy: 0.8914 - val_loss: 0.3292 - val_accuracy: 0.8865\n",
      "Duration: 0:04:18.920067\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27986901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 30s 82ms/step - loss: 0.9336 - accuracy: 0.6625 - val_loss: 0.4840 - val_accuracy: 0.8157\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.5690 - accuracy: 0.8040 - val_loss: 0.4137 - val_accuracy: 0.8471\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.4900 - accuracy: 0.8339 - val_loss: 0.3559 - val_accuracy: 0.8691\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 29s 83ms/step - loss: 0.4469 - accuracy: 0.8506 - val_loss: 0.3458 - val_accuracy: 0.8731\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.4114 - accuracy: 0.8607 - val_loss: 0.3219 - val_accuracy: 0.8887\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.3745 - accuracy: 0.8741 - val_loss: 0.3226 - val_accuracy: 0.8832\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.3665 - accuracy: 0.8785 - val_loss: 0.3171 - val_accuracy: 0.8904\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.3498 - accuracy: 0.8848 - val_loss: 0.3371 - val_accuracy: 0.8791\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.3380 - accuracy: 0.8910 - val_loss: 0.3056 - val_accuracy: 0.8977\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.3286 - accuracy: 0.8923 - val_loss: 0.3243 - val_accuracy: 0.8901\n",
      "Duration: 0:04:46.408492\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56bd3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 33s 81ms/step - loss: 0.9485 - accuracy: 0.6623 - val_loss: 0.4757 - val_accuracy: 0.8261\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.5494 - accuracy: 0.8068 - val_loss: 0.3898 - val_accuracy: 0.8573\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.4677 - accuracy: 0.8424 - val_loss: 0.3588 - val_accuracy: 0.8695\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.4304 - accuracy: 0.8563 - val_loss: 0.3453 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3989 - accuracy: 0.8676 - val_loss: 0.3172 - val_accuracy: 0.8834\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3779 - accuracy: 0.8720 - val_loss: 0.3187 - val_accuracy: 0.8879\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.3581 - accuracy: 0.8799 - val_loss: 0.3264 - val_accuracy: 0.8908\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3505 - accuracy: 0.8823 - val_loss: 0.3223 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3346 - accuracy: 0.8890 - val_loss: 0.2929 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.3312 - accuracy: 0.8907 - val_loss: 0.3079 - val_accuracy: 0.8969\n",
      "Duration: 0:05:21.233516\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c7f8d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 36s 81ms/step - loss: 0.8969 - accuracy: 0.6824 - val_loss: 0.4460 - val_accuracy: 0.8390\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.5238 - accuracy: 0.8177 - val_loss: 0.3729 - val_accuracy: 0.8632\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.4586 - accuracy: 0.8468 - val_loss: 0.3449 - val_accuracy: 0.8731\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 36s 82ms/step - loss: 0.4167 - accuracy: 0.8592 - val_loss: 0.3213 - val_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.3854 - accuracy: 0.8691 - val_loss: 0.3068 - val_accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.3665 - accuracy: 0.8776 - val_loss: 0.3085 - val_accuracy: 0.8869\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.3534 - accuracy: 0.8833 - val_loss: 0.2966 - val_accuracy: 0.8948\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.3355 - accuracy: 0.8878 - val_loss: 0.3511 - val_accuracy: 0.8931\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.3292 - accuracy: 0.8925 - val_loss: 0.3491 - val_accuracy: 0.8876\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 36s 81ms/step - loss: 0.3273 - accuracy: 0.8933 - val_loss: 0.2886 - val_accuracy: 0.8979\n",
      "Duration: 0:05:54.864479\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25bc6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 40s 81ms/step - loss: 0.8814 - accuracy: 0.6814 - val_loss: 0.4550 - val_accuracy: 0.8274\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.5298 - accuracy: 0.8186 - val_loss: 0.3823 - val_accuracy: 0.8616\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.4570 - accuracy: 0.8451 - val_loss: 0.3662 - val_accuracy: 0.8695\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.4105 - accuracy: 0.8626 - val_loss: 0.3310 - val_accuracy: 0.8817\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.3868 - accuracy: 0.8716 - val_loss: 0.2987 - val_accuracy: 0.8920\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.3703 - accuracy: 0.8787 - val_loss: 0.3238 - val_accuracy: 0.8874\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.3547 - accuracy: 0.8820 - val_loss: 0.2940 - val_accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.3487 - accuracy: 0.8842 - val_loss: 0.2953 - val_accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 38s 80ms/step - loss: 0.3403 - accuracy: 0.8890 - val_loss: 0.3523 - val_accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.3343 - accuracy: 0.8912 - val_loss: 0.3018 - val_accuracy: 0.8966\n",
      "Duration: 0:06:28.508184\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16b89575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 42s 78ms/step - loss: 0.8411 - accuracy: 0.6963 - val_loss: 0.4385 - val_accuracy: 0.8453\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5161 - accuracy: 0.8221 - val_loss: 0.3582 - val_accuracy: 0.8709\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.4439 - accuracy: 0.8514 - val_loss: 0.3404 - val_accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.4061 - accuracy: 0.8666 - val_loss: 0.3172 - val_accuracy: 0.8840\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.3776 - accuracy: 0.8757 - val_loss: 0.2971 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.3642 - accuracy: 0.8791 - val_loss: 0.3083 - val_accuracy: 0.8919\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.3479 - accuracy: 0.8847 - val_loss: 0.3080 - val_accuracy: 0.8931\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.3416 - accuracy: 0.8892 - val_loss: 0.2979 - val_accuracy: 0.8968\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.3422 - accuracy: 0.8898 - val_loss: 0.2983 - val_accuracy: 0.8948\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.3347 - accuracy: 0.8917 - val_loss: 0.3515 - val_accuracy: 0.8996\n",
      "Duration: 0:06:51.742596\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b446c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 46s 80ms/step - loss: 0.8073 - accuracy: 0.7131 - val_loss: 0.4310 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.4905 - accuracy: 0.8350 - val_loss: 0.3443 - val_accuracy: 0.8779\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.4253 - accuracy: 0.8587 - val_loss: 0.3218 - val_accuracy: 0.8829\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 45s 80ms/step - loss: 0.3867 - accuracy: 0.8728 - val_loss: 0.3068 - val_accuracy: 0.8869\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.3650 - accuracy: 0.8794 - val_loss: 0.2999 - val_accuracy: 0.8928\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.3564 - accuracy: 0.8821 - val_loss: 0.3038 - val_accuracy: 0.8991\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.3476 - accuracy: 0.8873 - val_loss: 0.2909 - val_accuracy: 0.8998\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.3419 - accuracy: 0.8898 - val_loss: 0.2816 - val_accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.3425 - accuracy: 0.8908 - val_loss: 0.2989 - val_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 46s 81ms/step - loss: 0.3453 - accuracy: 0.8912 - val_loss: 0.2919 - val_accuracy: 0.8994\n",
      "Duration: 0:07:31.942157\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dcc047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 50s 80ms/step - loss: 0.8027 - accuracy: 0.7158 - val_loss: 0.4279 - val_accuracy: 0.8479\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 48s 79ms/step - loss: 0.4914 - accuracy: 0.8321 - val_loss: 0.3725 - val_accuracy: 0.8651\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 48s 79ms/step - loss: 0.4258 - accuracy: 0.8579 - val_loss: 0.3155 - val_accuracy: 0.8832\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.3858 - accuracy: 0.8692 - val_loss: 0.2963 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.3665 - accuracy: 0.8791 - val_loss: 0.2948 - val_accuracy: 0.8934\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.3505 - accuracy: 0.8838 - val_loss: 0.3319 - val_accuracy: 0.9012\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.3442 - accuracy: 0.8888 - val_loss: 0.3079 - val_accuracy: 0.8944\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 48s 79ms/step - loss: 0.3446 - accuracy: 0.8880 - val_loss: 0.3604 - val_accuracy: 0.8875\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.3386 - accuracy: 0.8927 - val_loss: 0.4256 - val_accuracy: 0.8827\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.3422 - accuracy: 0.8906 - val_loss: 0.3074 - val_accuracy: 0.8993\n",
      "Duration: 0:08:00.828695\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f65979e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.8041 - accuracy: 0.7220 - val_loss: 0.4016 - val_accuracy: 0.8553\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4774 - accuracy: 0.8402 - val_loss: 0.3345 - val_accuracy: 0.8768\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4151 - accuracy: 0.8630 - val_loss: 0.3094 - val_accuracy: 0.8885\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.3844 - accuracy: 0.8712 - val_loss: 0.3158 - val_accuracy: 0.8835\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.3694 - accuracy: 0.8779 - val_loss: 0.3366 - val_accuracy: 0.8890\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3567 - accuracy: 0.8825 - val_loss: 0.3486 - val_accuracy: 0.8914\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3566 - accuracy: 0.8853 - val_loss: 0.3724 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3484 - accuracy: 0.8871 - val_loss: 0.3175 - val_accuracy: 0.8920\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3510 - accuracy: 0.8882 - val_loss: 0.3000 - val_accuracy: 0.8986\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.3468 - accuracy: 0.8890 - val_loss: 0.3101 - val_accuracy: 0.9006\n",
      "Duration: 0:08:29.004553\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1aa246b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 54s 76ms/step - loss: 0.7705 - accuracy: 0.7295 - val_loss: 0.4028 - val_accuracy: 0.8534\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4725 - accuracy: 0.8393 - val_loss: 0.3188 - val_accuracy: 0.8872\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4120 - accuracy: 0.8614 - val_loss: 0.2968 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3813 - accuracy: 0.8719 - val_loss: 0.3006 - val_accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3756 - accuracy: 0.8776 - val_loss: 0.2935 - val_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3700 - accuracy: 0.8797 - val_loss: 0.2862 - val_accuracy: 0.9001\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.3625 - accuracy: 0.8821 - val_loss: 0.3146 - val_accuracy: 0.8883\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3561 - accuracy: 0.8851 - val_loss: 0.3006 - val_accuracy: 0.8989\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.3641 - accuracy: 0.8828 - val_loss: 0.3051 - val_accuracy: 0.8944\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.3604 - accuracy: 0.8856 - val_loss: 0.2903 - val_accuracy: 0.8987\n",
      "Duration: 0:08:52.557009\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a8e3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cd6f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.7781 - accuracy: 0.7224 - val_loss: 0.4053 - val_accuracy: 0.8581\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4763 - accuracy: 0.8392 - val_loss: 0.3386 - val_accuracy: 0.8744\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4158 - accuracy: 0.8629 - val_loss: 0.3293 - val_accuracy: 0.8801\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3857 - accuracy: 0.8723 - val_loss: 0.3044 - val_accuracy: 0.8890\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3688 - accuracy: 0.8809 - val_loss: 0.3035 - val_accuracy: 0.8937\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.3607 - accuracy: 0.8812 - val_loss: 0.2812 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.3629 - accuracy: 0.8842 - val_loss: 0.3071 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.3638 - accuracy: 0.8822 - val_loss: 0.3070 - val_accuracy: 0.8985\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.3580 - accuracy: 0.8859 - val_loss: 0.2939 - val_accuracy: 0.8999\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 53s 71ms/step - loss: 0.3570 - accuracy: 0.8871 - val_loss: 0.2906 - val_accuracy: 0.9005\n",
      "Duration: 0:08:37.668233\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c0a7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b22e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.7343 - accuracy: 0.7431 - val_loss: 0.3818 - val_accuracy: 0.8589\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4478 - accuracy: 0.8483 - val_loss: 0.3385 - val_accuracy: 0.8784\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3944 - accuracy: 0.8688 - val_loss: 0.2869 - val_accuracy: 0.8955\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3723 - accuracy: 0.8765 - val_loss: 0.3240 - val_accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3603 - accuracy: 0.8841 - val_loss: 0.3148 - val_accuracy: 0.8866\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3626 - accuracy: 0.8826 - val_loss: 0.3364 - val_accuracy: 0.8928\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3633 - accuracy: 0.8837 - val_loss: 0.2835 - val_accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3608 - accuracy: 0.8848 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 55s 69ms/step - loss: 0.3688 - accuracy: 0.8831 - val_loss: 0.3421 - val_accuracy: 0.8959\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 55s 70ms/step - loss: 0.3689 - accuracy: 0.8842 - val_loss: 0.2971 - val_accuracy: 0.8973\n",
      "Duration: 0:09:01.784369\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71382b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9d0e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 58s 69ms/step - loss: 0.7237 - accuracy: 0.7463 - val_loss: 0.3949 - val_accuracy: 0.8562\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4501 - accuracy: 0.8495 - val_loss: 0.3163 - val_accuracy: 0.8833\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3967 - accuracy: 0.8685 - val_loss: 0.3085 - val_accuracy: 0.8859\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3743 - accuracy: 0.8767 - val_loss: 0.3165 - val_accuracy: 0.8891\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3701 - accuracy: 0.8788 - val_loss: 0.3183 - val_accuracy: 0.8892\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3612 - accuracy: 0.8843 - val_loss: 0.3481 - val_accuracy: 0.8773\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.3665 - accuracy: 0.8847 - val_loss: 0.3129 - val_accuracy: 0.8953\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.3605 - accuracy: 0.8854 - val_loss: 0.3025 - val_accuracy: 0.8937\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 59s 71ms/step - loss: 0.3612 - accuracy: 0.8861 - val_loss: 0.3066 - val_accuracy: 0.8948\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.3575 - accuracy: 0.8873 - val_loss: 0.3095 - val_accuracy: 0.8966\n",
      "Duration: 0:09:32.493257\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "427901cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a9d9f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.7129 - accuracy: 0.7500 - val_loss: 0.3847 - val_accuracy: 0.8600\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.4444 - accuracy: 0.8520 - val_loss: 0.3049 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3913 - accuracy: 0.8715 - val_loss: 0.2854 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3707 - accuracy: 0.8782 - val_loss: 0.3077 - val_accuracy: 0.8943\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3655 - accuracy: 0.8812 - val_loss: 0.3071 - val_accuracy: 0.8977\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3606 - accuracy: 0.8840 - val_loss: 0.2781 - val_accuracy: 0.9015\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 60s 68ms/step - loss: 0.3596 - accuracy: 0.8852 - val_loss: 0.2865 - val_accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3628 - accuracy: 0.8851 - val_loss: 0.2954 - val_accuracy: 0.8949\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3640 - accuracy: 0.8861 - val_loss: 0.2930 - val_accuracy: 0.8983\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 61s 69ms/step - loss: 0.3666 - accuracy: 0.8842 - val_loss: 0.3172 - val_accuracy: 0.8894\n",
      "Duration: 0:09:57.753826\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e683b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5efcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_dsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_dsa_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_dsa:\n",
    "    model.save(new_model_dsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f250fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_dsa = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_dsa_dir = \"D:/models/gtsrb_models/C1/gtsrb_model_c1_sep_dsa_e2_\"+str(i)\n",
    "        print(model_dsa_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_dsa_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_dsa.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77836993",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del dsa_values\n",
    "    del top_images_by_dsa\n",
    "    del top_labels_by_dsa\n",
    "    del image_sets_dsa\n",
    "    del label_sets_dsa\n",
    "    del models_dsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2d78dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89881"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73510f",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ac6d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_direction = \"D:/guided-retraining/data/\"+dataset+\"/deep_gini_values.npy\"\n",
    "\n",
    "deep_gini_values = np.load(dg_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d85ee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by dg values\n",
    "top_images_by_dg  = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),x_train_and_adversary)\n",
    "top_labels_by_dg = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7636eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dg = []\n",
    "label_sets_dg = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_dg)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dg)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dg)%m))\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m])\n",
    "    image_sets_dg.append(top_images_by_dg_n)\n",
    "    label_sets_dg.append(top_labels_by_dg_n)\n",
    "    print(len(top_images_by_dg_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8235ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "models_dg = []\n",
    "#for i in range(len(label_sets_lsa)):\n",
    "for i in range(len(label_sets_dg)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False)\n",
    "    model.compile_model()\n",
    "    models_dg.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e0ae2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 150ms/step - loss: 1.9706 - accuracy: 0.2679 - val_loss: 2.1915 - val_accuracy: 0.1504\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 6s 145ms/step - loss: 1.7569 - accuracy: 0.2979 - val_loss: 2.1105 - val_accuracy: 0.2756\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 143ms/step - loss: 1.6679 - accuracy: 0.3146 - val_loss: 1.9619 - val_accuracy: 0.3084\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 1.5877 - accuracy: 0.3593 - val_loss: 1.8529 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 144ms/step - loss: 1.5394 - accuracy: 0.3507 - val_loss: 1.8332 - val_accuracy: 0.4354\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 6s 149ms/step - loss: 1.4941 - accuracy: 0.3661 - val_loss: 1.7351 - val_accuracy: 0.4235\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 145ms/step - loss: 1.4524 - accuracy: 0.3839 - val_loss: 1.6727 - val_accuracy: 0.4900\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.4093 - accuracy: 0.3943 - val_loss: 1.5867 - val_accuracy: 0.5269\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.3758 - accuracy: 0.4114 - val_loss: 1.6452 - val_accuracy: 0.4997\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.3638 - accuracy: 0.4161 - val_loss: 1.5171 - val_accuracy: 0.5039\n",
      "Duration: 0:01:04.267964\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9111d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 10s 108ms/step - loss: 1.8208 - accuracy: 0.2868 - val_loss: 2.0210 - val_accuracy: 0.2436\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 9s 104ms/step - loss: 1.4968 - accuracy: 0.3866 - val_loss: 1.7558 - val_accuracy: 0.3798\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 9s 104ms/step - loss: 1.3720 - accuracy: 0.4239 - val_loss: 1.8373 - val_accuracy: 0.3737\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.3123 - accuracy: 0.4275 - val_loss: 1.5807 - val_accuracy: 0.3987\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 9s 104ms/step - loss: 1.2804 - accuracy: 0.4457 - val_loss: 1.5997 - val_accuracy: 0.4126\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 9s 104ms/step - loss: 1.2194 - accuracy: 0.4643 - val_loss: 1.6400 - val_accuracy: 0.4572\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 1.1860 - accuracy: 0.4796 - val_loss: 1.6231 - val_accuracy: 0.4226\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 1.1619 - accuracy: 0.4854 - val_loss: 1.3457 - val_accuracy: 0.4925\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 1.1338 - accuracy: 0.5004 - val_loss: 1.3955 - val_accuracy: 0.4714\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 9s 102ms/step - loss: 1.1116 - accuracy: 0.5139 - val_loss: 1.3925 - val_accuracy: 0.4881\n",
      "Duration: 0:01:32.808665\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f271a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 13s 92ms/step - loss: 1.6286 - accuracy: 0.3500 - val_loss: 1.7689 - val_accuracy: 0.4355\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 1.3361 - accuracy: 0.4386 - val_loss: 1.6020 - val_accuracy: 0.4177\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 1.2458 - accuracy: 0.4626 - val_loss: 1.6521 - val_accuracy: 0.4664\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 1.1885 - accuracy: 0.4888 - val_loss: 1.5523 - val_accuracy: 0.4948\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 89ms/step - loss: 1.1500 - accuracy: 0.4910 - val_loss: 1.4033 - val_accuracy: 0.4458\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 1.1206 - accuracy: 0.5095 - val_loss: 1.4932 - val_accuracy: 0.4194\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 1.0913 - accuracy: 0.5126 - val_loss: 1.3034 - val_accuracy: 0.4709\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 1.0538 - accuracy: 0.5345 - val_loss: 1.3417 - val_accuracy: 0.5082\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 1.0314 - accuracy: 0.5492 - val_loss: 1.2960 - val_accuracy: 0.5217\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 1.0036 - accuracy: 0.5567 - val_loss: 1.2348 - val_accuracy: 0.5011\n",
      "Duration: 0:02:00.371237\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "808aef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 16s 86ms/step - loss: 1.5738 - accuracy: 0.3736 - val_loss: 1.6834 - val_accuracy: 0.4335\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 1.2711 - accuracy: 0.4589 - val_loss: 1.5633 - val_accuracy: 0.4270\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 1.1797 - accuracy: 0.4877 - val_loss: 1.5308 - val_accuracy: 0.4256\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 1.1230 - accuracy: 0.5067 - val_loss: 1.3280 - val_accuracy: 0.5111\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 1.0748 - accuracy: 0.5318 - val_loss: 1.4011 - val_accuracy: 0.5112\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 1.0460 - accuracy: 0.5440 - val_loss: 1.3409 - val_accuracy: 0.5158\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 1.0156 - accuracy: 0.5641 - val_loss: 1.2526 - val_accuracy: 0.5436\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.9822 - accuracy: 0.5768 - val_loss: 1.1320 - val_accuracy: 0.5536\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.9515 - accuracy: 0.5905 - val_loss: 1.0529 - val_accuracy: 0.6184\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.9277 - accuracy: 0.6071 - val_loss: 1.1413 - val_accuracy: 0.6051\n",
      "Duration: 0:02:29.425209\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a41229bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 19s 82ms/step - loss: 1.4622 - accuracy: 0.4009 - val_loss: 1.6924 - val_accuracy: 0.4534\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 1.1870 - accuracy: 0.4891 - val_loss: 1.5882 - val_accuracy: 0.5002\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 1.1049 - accuracy: 0.5191 - val_loss: 1.4046 - val_accuracy: 0.4841\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 1.0487 - accuracy: 0.5454 - val_loss: 1.2870 - val_accuracy: 0.5281\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 18s 82ms/step - loss: 1.0095 - accuracy: 0.5711 - val_loss: 1.2257 - val_accuracy: 0.5581\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.9650 - accuracy: 0.5839 - val_loss: 1.2661 - val_accuracy: 0.5586\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.9351 - accuracy: 0.6047 - val_loss: 1.2092 - val_accuracy: 0.5825\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.9089 - accuracy: 0.6243 - val_loss: 1.0555 - val_accuracy: 0.6207\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 18s 84ms/step - loss: 0.8735 - accuracy: 0.6422 - val_loss: 1.0272 - val_accuracy: 0.6246\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 18s 83ms/step - loss: 0.8532 - accuracy: 0.6462 - val_loss: 1.0584 - val_accuracy: 0.6466\n",
      "Duration: 0:03:01.554648\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ff46b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 1.4424 - accuracy: 0.4168 - val_loss: 1.5112 - val_accuracy: 0.5139\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 1.1397 - accuracy: 0.5140 - val_loss: 1.4163 - val_accuracy: 0.5580\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 21s 81ms/step - loss: 1.0337 - accuracy: 0.5724 - val_loss: 1.3383 - val_accuracy: 0.5651\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 0.9717 - accuracy: 0.6034 - val_loss: 1.1922 - val_accuracy: 0.5906\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 22s 83ms/step - loss: 0.9251 - accuracy: 0.6267 - val_loss: 1.1639 - val_accuracy: 0.5942\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 22s 82ms/step - loss: 0.8852 - accuracy: 0.6451 - val_loss: 1.2197 - val_accuracy: 0.5951\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.8512 - accuracy: 0.6676 - val_loss: 1.1035 - val_accuracy: 0.6015\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.8154 - accuracy: 0.6842 - val_loss: 1.0893 - val_accuracy: 0.6189\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.7940 - accuracy: 0.6987 - val_loss: 1.2473 - val_accuracy: 0.6013\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 22s 84ms/step - loss: 0.7700 - accuracy: 0.7061 - val_loss: 1.1081 - val_accuracy: 0.6751\n",
      "Duration: 0:03:38.719602\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68940f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 27s 84ms/step - loss: 1.3613 - accuracy: 0.4577 - val_loss: 1.5744 - val_accuracy: 0.5191\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 1.0577 - accuracy: 0.5741 - val_loss: 1.2175 - val_accuracy: 0.5693\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.9522 - accuracy: 0.6235 - val_loss: 1.1525 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 27s 87ms/step - loss: 0.8925 - accuracy: 0.6563 - val_loss: 1.1410 - val_accuracy: 0.6041\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.8336 - accuracy: 0.6860 - val_loss: 1.0595 - val_accuracy: 0.6250\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.7869 - accuracy: 0.7056 - val_loss: 1.0331 - val_accuracy: 0.6081\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.7544 - accuracy: 0.7198 - val_loss: 0.8972 - val_accuracy: 0.6775\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.7317 - accuracy: 0.7280 - val_loss: 0.8804 - val_accuracy: 0.6571\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.7001 - accuracy: 0.7458 - val_loss: 0.8925 - val_accuracy: 0.7139\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.6863 - accuracy: 0.7531 - val_loss: 0.9892 - val_accuracy: 0.6990\n",
      "Duration: 0:04:18.825908\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8a2858ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 30s 82ms/step - loss: 1.3163 - accuracy: 0.4874 - val_loss: 1.3506 - val_accuracy: 0.5594\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.9971 - accuracy: 0.6144 - val_loss: 1.1735 - val_accuracy: 0.5792\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.8829 - accuracy: 0.6684 - val_loss: 1.0759 - val_accuracy: 0.5982\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.8121 - accuracy: 0.7027 - val_loss: 1.0312 - val_accuracy: 0.6126\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.7610 - accuracy: 0.7272 - val_loss: 0.9823 - val_accuracy: 0.6144\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 29s 82ms/step - loss: 0.7249 - accuracy: 0.7425 - val_loss: 0.9185 - val_accuracy: 0.6567\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 29s 83ms/step - loss: 0.7036 - accuracy: 0.7496 - val_loss: 0.9548 - val_accuracy: 0.6562\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6757 - accuracy: 0.7620 - val_loss: 0.8756 - val_accuracy: 0.6905\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6598 - accuracy: 0.7667 - val_loss: 0.9155 - val_accuracy: 0.7110\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6438 - accuracy: 0.7732 - val_loss: 0.8193 - val_accuracy: 0.7455\n",
      "Duration: 0:04:45.774243\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8d03b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 33s 82ms/step - loss: 1.2402 - accuracy: 0.5244 - val_loss: 1.2932 - val_accuracy: 0.5609\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 33s 84ms/step - loss: 0.9122 - accuracy: 0.6605 - val_loss: 1.1653 - val_accuracy: 0.5983\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.8054 - accuracy: 0.7104 - val_loss: 0.9820 - val_accuracy: 0.6171\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.7448 - accuracy: 0.7349 - val_loss: 0.9542 - val_accuracy: 0.6371\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.6966 - accuracy: 0.7538 - val_loss: 0.7515 - val_accuracy: 0.6844\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.6662 - accuracy: 0.7680 - val_loss: 0.8501 - val_accuracy: 0.7130\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.6445 - accuracy: 0.7762 - val_loss: 0.7804 - val_accuracy: 0.7410\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.6368 - accuracy: 0.7799 - val_loss: 0.7270 - val_accuracy: 0.7578\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 80ms/step - loss: 0.6143 - accuracy: 0.7871 - val_loss: 0.8643 - val_accuracy: 0.7516\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.6107 - accuracy: 0.7902 - val_loss: 0.7050 - val_accuracy: 0.7770\n",
      "Duration: 0:05:20.396085\n"
     ]
    }
   ],
   "source": [
    "n=8\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "272ddf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 36s 81ms/step - loss: 1.1873 - accuracy: 0.5509 - val_loss: 1.2345 - val_accuracy: 0.5701\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.8459 - accuracy: 0.6983 - val_loss: 1.0784 - val_accuracy: 0.5856\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.7447 - accuracy: 0.7393 - val_loss: 0.8290 - val_accuracy: 0.6472\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.6889 - accuracy: 0.7621 - val_loss: 0.9023 - val_accuracy: 0.6556\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.6489 - accuracy: 0.7782 - val_loss: 0.7282 - val_accuracy: 0.6981\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.6212 - accuracy: 0.7878 - val_loss: 0.7462 - val_accuracy: 0.7206\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.6030 - accuracy: 0.7947 - val_loss: 0.7318 - val_accuracy: 0.7374\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5873 - accuracy: 0.8000 - val_loss: 0.5903 - val_accuracy: 0.7848\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.5814 - accuracy: 0.8060 - val_loss: 0.5761 - val_accuracy: 0.7976\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5733 - accuracy: 0.8074 - val_loss: 0.8774 - val_accuracy: 0.7621\n",
      "Duration: 0:05:50.453157\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "63a15493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 1.1244 - accuracy: 0.5914 - val_loss: 1.1982 - val_accuracy: 0.5572\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 38s 80ms/step - loss: 0.7879 - accuracy: 0.7275 - val_loss: 1.0164 - val_accuracy: 0.6079\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.6933 - accuracy: 0.7620 - val_loss: 0.8735 - val_accuracy: 0.6436\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.6444 - accuracy: 0.7795 - val_loss: 0.9730 - val_accuracy: 0.6121\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 38s 80ms/step - loss: 0.6121 - accuracy: 0.7915 - val_loss: 0.8089 - val_accuracy: 0.6770\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5839 - accuracy: 0.8020 - val_loss: 0.8048 - val_accuracy: 0.6800\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 38s 80ms/step - loss: 0.5719 - accuracy: 0.8086 - val_loss: 0.7359 - val_accuracy: 0.7170\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5630 - accuracy: 0.8083 - val_loss: 0.6312 - val_accuracy: 0.7951\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5559 - accuracy: 0.8122 - val_loss: 0.7660 - val_accuracy: 0.7501\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 38s 78ms/step - loss: 0.5535 - accuracy: 0.8156 - val_loss: 0.8172 - val_accuracy: 0.7693\n",
      "Duration: 0:06:23.678011\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61fe761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 42s 78ms/step - loss: 1.0458 - accuracy: 0.6304 - val_loss: 0.9834 - val_accuracy: 0.5939\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.7175 - accuracy: 0.7546 - val_loss: 0.7498 - val_accuracy: 0.6982\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.6420 - accuracy: 0.7818 - val_loss: 0.6447 - val_accuracy: 0.7551\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5979 - accuracy: 0.7958 - val_loss: 0.6078 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5721 - accuracy: 0.8075 - val_loss: 0.5025 - val_accuracy: 0.8086\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5533 - accuracy: 0.8143 - val_loss: 0.4940 - val_accuracy: 0.8194\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 40s 76ms/step - loss: 0.5353 - accuracy: 0.8211 - val_loss: 0.4325 - val_accuracy: 0.8504\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5298 - accuracy: 0.8239 - val_loss: 0.4158 - val_accuracy: 0.8531\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5284 - accuracy: 0.8275 - val_loss: 0.4394 - val_accuracy: 0.8424\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5240 - accuracy: 0.8283 - val_loss: 0.4268 - val_accuracy: 0.8574\n",
      "Duration: 0:06:44.091291\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c825f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 1.0097 - accuracy: 0.6418 - val_loss: 0.8294 - val_accuracy: 0.6342\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.6834 - accuracy: 0.7630 - val_loss: 0.5801 - val_accuracy: 0.7850\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 46s 81ms/step - loss: 0.6001 - accuracy: 0.7925 - val_loss: 0.4348 - val_accuracy: 0.8534\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.5530 - accuracy: 0.8122 - val_loss: 0.3669 - val_accuracy: 0.8736\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.5353 - accuracy: 0.8226 - val_loss: 0.3388 - val_accuracy: 0.8842\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.5119 - accuracy: 0.8307 - val_loss: 0.3174 - val_accuracy: 0.8880\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.4974 - accuracy: 0.8368 - val_loss: 0.2927 - val_accuracy: 0.8987\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4933 - accuracy: 0.8381 - val_loss: 0.3260 - val_accuracy: 0.8922\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.4888 - accuracy: 0.8394 - val_loss: 0.2951 - val_accuracy: 0.8996\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.4904 - accuracy: 0.8411 - val_loss: 0.3099 - val_accuracy: 0.9035\n",
      "Duration: 0:07:27.352837\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae294d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 48s 77ms/step - loss: 0.9662 - accuracy: 0.6566 - val_loss: 0.5486 - val_accuracy: 0.8099\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.6499 - accuracy: 0.7777 - val_loss: 0.4094 - val_accuracy: 0.8526\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.5625 - accuracy: 0.8091 - val_loss: 0.3977 - val_accuracy: 0.8679\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.5163 - accuracy: 0.8263 - val_loss: 0.3030 - val_accuracy: 0.8924\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4983 - accuracy: 0.8328 - val_loss: 0.2921 - val_accuracy: 0.8982\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4819 - accuracy: 0.8392 - val_loss: 0.2839 - val_accuracy: 0.8993\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4684 - accuracy: 0.8458 - val_loss: 0.3335 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4705 - accuracy: 0.8478 - val_loss: 0.3002 - val_accuracy: 0.8951\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4686 - accuracy: 0.8464 - val_loss: 0.3426 - val_accuracy: 0.8961\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4754 - accuracy: 0.8470 - val_loss: 0.2791 - val_accuracy: 0.9021\n",
      "Duration: 0:07:50.282171\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4ed2760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 53s 79ms/step - loss: 0.9419 - accuracy: 0.6701 - val_loss: 0.4533 - val_accuracy: 0.8419\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.6099 - accuracy: 0.7926 - val_loss: 0.3695 - val_accuracy: 0.8711\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.5253 - accuracy: 0.8231 - val_loss: 0.3124 - val_accuracy: 0.8931\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.4848 - accuracy: 0.8401 - val_loss: 0.2910 - val_accuracy: 0.8962\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4616 - accuracy: 0.8483 - val_loss: 0.2698 - val_accuracy: 0.9036\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.4503 - accuracy: 0.8541 - val_loss: 0.2916 - val_accuracy: 0.8940\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4339 - accuracy: 0.8574 - val_loss: 0.2848 - val_accuracy: 0.9005\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4327 - accuracy: 0.8597 - val_loss: 0.3123 - val_accuracy: 0.8992\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4388 - accuracy: 0.8600 - val_loss: 0.2804 - val_accuracy: 0.9017\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4359 - accuracy: 0.8611 - val_loss: 0.3543 - val_accuracy: 0.8966\n",
      "Duration: 0:08:31.978808\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "51c8d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 54s 76ms/step - loss: 0.9052 - accuracy: 0.6821 - val_loss: 0.3903 - val_accuracy: 0.8586\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.5677 - accuracy: 0.8098 - val_loss: 0.3159 - val_accuracy: 0.8801\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4923 - accuracy: 0.8365 - val_loss: 0.2897 - val_accuracy: 0.8965\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4550 - accuracy: 0.8499 - val_loss: 0.2727 - val_accuracy: 0.9035\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4418 - accuracy: 0.8562 - val_loss: 0.3015 - val_accuracy: 0.8935\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4328 - accuracy: 0.8610 - val_loss: 0.2696 - val_accuracy: 0.9050\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 54s 77ms/step - loss: 0.4296 - accuracy: 0.8624 - val_loss: 0.2830 - val_accuracy: 0.9008\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 55s 78ms/step - loss: 0.4269 - accuracy: 0.8639 - val_loss: 0.3121 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 55s 78ms/step - loss: 0.4259 - accuracy: 0.8632 - val_loss: 0.2741 - val_accuracy: 0.9060\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4325 - accuracy: 0.8647 - val_loss: 0.2875 - val_accuracy: 0.8968\n",
      "Duration: 0:08:56.366214\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a242661",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6bed38dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 54s 71ms/step - loss: 0.8451 - accuracy: 0.7022 - val_loss: 0.3904 - val_accuracy: 0.8549\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.5282 - accuracy: 0.8211 - val_loss: 0.3281 - val_accuracy: 0.8852\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 54s 72ms/step - loss: 0.4626 - accuracy: 0.8464 - val_loss: 0.2918 - val_accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 51s 68ms/step - loss: 0.4280 - accuracy: 0.8589 - val_loss: 0.2751 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.4091 - accuracy: 0.8643 - val_loss: 0.3112 - val_accuracy: 0.8919\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.4037 - accuracy: 0.8689 - val_loss: 0.2685 - val_accuracy: 0.9057\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 51s 68ms/step - loss: 0.4100 - accuracy: 0.8688 - val_loss: 0.2815 - val_accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4038 - accuracy: 0.8708 - val_loss: 0.3056 - val_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.4044 - accuracy: 0.8705 - val_loss: 0.2994 - val_accuracy: 0.9034\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.4133 - accuracy: 0.8713 - val_loss: 0.2949 - val_accuracy: 0.9011\n",
      "Duration: 0:08:33.497738\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e8ae173",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8c6abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 55s 68ms/step - loss: 0.7860 - accuracy: 0.7265 - val_loss: 0.3748 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4938 - accuracy: 0.8347 - val_loss: 0.3058 - val_accuracy: 0.8885\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.4361 - accuracy: 0.8557 - val_loss: 0.2927 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.4112 - accuracy: 0.8659 - val_loss: 0.2845 - val_accuracy: 0.9001\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3976 - accuracy: 0.8709 - val_loss: 0.3073 - val_accuracy: 0.9019\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 54s 68ms/step - loss: 0.3937 - accuracy: 0.8740 - val_loss: 0.2904 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3953 - accuracy: 0.8742 - val_loss: 0.3181 - val_accuracy: 0.8948\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3948 - accuracy: 0.8744 - val_loss: 0.3078 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 54s 69ms/step - loss: 0.3966 - accuracy: 0.8744 - val_loss: 0.3191 - val_accuracy: 0.8938\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 55s 69ms/step - loss: 0.3993 - accuracy: 0.8730 - val_loss: 0.3040 - val_accuracy: 0.9006\n",
      "Duration: 0:09:01.243392\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed4a70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55682411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 58s 68ms/step - loss: 0.7716 - accuracy: 0.7266 - val_loss: 0.3857 - val_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4790 - accuracy: 0.8377 - val_loss: 0.3375 - val_accuracy: 0.8752\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4230 - accuracy: 0.8603 - val_loss: 0.3213 - val_accuracy: 0.8886\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.4028 - accuracy: 0.8681 - val_loss: 0.2914 - val_accuracy: 0.8952\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3876 - accuracy: 0.8732 - val_loss: 0.2845 - val_accuracy: 0.9006\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3838 - accuracy: 0.8761 - val_loss: 0.2885 - val_accuracy: 0.8984\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 56s 68ms/step - loss: 0.3839 - accuracy: 0.8752 - val_loss: 0.2804 - val_accuracy: 0.9003\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3843 - accuracy: 0.8773 - val_loss: 0.3443 - val_accuracy: 0.8931\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 57s 69ms/step - loss: 0.3880 - accuracy: 0.8766 - val_loss: 0.3451 - val_accuracy: 0.8920\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 58s 70ms/step - loss: 0.3878 - accuracy: 0.8769 - val_loss: 0.2932 - val_accuracy: 0.8959\n",
      "Duration: 0:09:27.963510\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "83cc5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1ec790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 59s 66ms/step - loss: 0.7134 - accuracy: 0.7499 - val_loss: 0.3788 - val_accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.4468 - accuracy: 0.8508 - val_loss: 0.3112 - val_accuracy: 0.8868\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 58s 66ms/step - loss: 0.3958 - accuracy: 0.8694 - val_loss: 0.2896 - val_accuracy: 0.8948\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 58s 67ms/step - loss: 0.3756 - accuracy: 0.8770 - val_loss: 0.2838 - val_accuracy: 0.8966\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 59s 67ms/step - loss: 0.3648 - accuracy: 0.8814 - val_loss: 0.2880 - val_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 59s 68ms/step - loss: 0.3628 - accuracy: 0.8838 - val_loss: 0.3080 - val_accuracy: 0.8981\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3621 - accuracy: 0.8852 - val_loss: 0.2893 - val_accuracy: 0.8981\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 60s 69ms/step - loss: 0.3661 - accuracy: 0.8834 - val_loss: 0.3234 - val_accuracy: 0.8951\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 61s 70ms/step - loss: 0.3653 - accuracy: 0.8832 - val_loss: 0.2912 - val_accuracy: 0.9004\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3662 - accuracy: 0.8851 - val_loss: 0.2961 - val_accuracy: 0.8986\n",
      "Duration: 0:09:58.100153\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "822aa540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_dg_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_dg_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_dg_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_dg:\n",
    "    model.save(new_model_dg_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87737d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_dg = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(5):\n",
    "        model_dg_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_gn_e1_\"+str(i)\n",
    "        print(model_dg_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_dg_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_dg.append(model)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2139719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del deep_gini_values\n",
    "    del top_images_by_dg\n",
    "    del top_labels_by_dg\n",
    "    del image_sets_dg\n",
    "    del label_sets_dg\n",
    "    del models_dg\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8986882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89881"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bfcff",
   "metadata": {},
   "source": [
    "### Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3b6b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax values\n",
    "se_direction = \"D:/guided-retraining/data/\"+dataset+\"/softmax_values.npy\"\n",
    "se_values = np.load(se_direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a389aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by LSA values\n",
    "top_images_by_se  = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),x_train_and_adversary)\n",
    "top_labels_by_se = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "74bdb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "\n",
    "n = 0\n",
    "image_sets_se = []\n",
    "label_sets_se = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_se)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_se)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_se)%m))\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m])\n",
    "    image_sets_se.append(top_images_by_se_n)\n",
    "    label_sets_se.append(top_labels_by_se_n)\n",
    "    print(len(top_images_by_se_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14e3cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "models_se = []\n",
    "for i in range(len(label_sets_se)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False)\n",
    "    model.compile_model()\n",
    "    models_se.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f66277ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 7s 150ms/step - loss: 1.9257 - accuracy: 0.2686 - val_loss: 2.1967 - val_accuracy: 0.1976\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 7s 151ms/step - loss: 1.7486 - accuracy: 0.3064 - val_loss: 1.9976 - val_accuracy: 0.2734\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 147ms/step - loss: 1.6588 - accuracy: 0.3229 - val_loss: 1.9463 - val_accuracy: 0.3512\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 6s 146ms/step - loss: 1.6029 - accuracy: 0.3518 - val_loss: 1.8095 - val_accuracy: 0.4104\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 7s 152ms/step - loss: 1.5278 - accuracy: 0.3689 - val_loss: 1.6251 - val_accuracy: 0.4654\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 7s 153ms/step - loss: 1.4790 - accuracy: 0.3907 - val_loss: 1.5533 - val_accuracy: 0.4620\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 7s 161ms/step - loss: 1.4571 - accuracy: 0.3989 - val_loss: 1.6140 - val_accuracy: 0.4807\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 7s 155ms/step - loss: 1.4231 - accuracy: 0.4175 - val_loss: 1.4444 - val_accuracy: 0.4899\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 7s 155ms/step - loss: 1.3922 - accuracy: 0.4154 - val_loss: 1.4383 - val_accuracy: 0.5123\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 7s 156ms/step - loss: 1.3615 - accuracy: 0.4321 - val_loss: 1.3591 - val_accuracy: 0.5277\n",
      "Duration: 0:01:07.346984\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5bb251b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 11s 111ms/step - loss: 1.8150 - accuracy: 0.2818 - val_loss: 1.9546 - val_accuracy: 0.3190\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 1.5295 - accuracy: 0.3663 - val_loss: 1.8295 - val_accuracy: 0.3435\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 10s 111ms/step - loss: 1.4266 - accuracy: 0.3918 - val_loss: 1.6637 - val_accuracy: 0.4196\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3654 - accuracy: 0.4223 - val_loss: 1.5720 - val_accuracy: 0.4561\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 10s 110ms/step - loss: 1.3170 - accuracy: 0.4264 - val_loss: 1.4876 - val_accuracy: 0.5003\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 10s 112ms/step - loss: 1.2723 - accuracy: 0.4464 - val_loss: 1.4158 - val_accuracy: 0.5252\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.2437 - accuracy: 0.4655 - val_loss: 1.3540 - val_accuracy: 0.4889\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.2058 - accuracy: 0.4684 - val_loss: 1.2538 - val_accuracy: 0.5485\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.1773 - accuracy: 0.4861 - val_loss: 1.2386 - val_accuracy: 0.5326\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.1533 - accuracy: 0.4927 - val_loss: 1.1886 - val_accuracy: 0.5373\n",
      "Duration: 0:01:39.529852\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c68ec68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 14s 100ms/step - loss: 1.6619 - accuracy: 0.3410 - val_loss: 1.7984 - val_accuracy: 0.4689\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 13s 98ms/step - loss: 1.3640 - accuracy: 0.4317 - val_loss: 1.6418 - val_accuracy: 0.4531\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 1.2693 - accuracy: 0.4586 - val_loss: 1.4674 - val_accuracy: 0.4836\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 1.2141 - accuracy: 0.4721 - val_loss: 1.5016 - val_accuracy: 0.4526\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 1.1632 - accuracy: 0.4951 - val_loss: 1.3837 - val_accuracy: 0.4914\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 1.1308 - accuracy: 0.5050 - val_loss: 1.3371 - val_accuracy: 0.5303\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 1.1042 - accuracy: 0.5192 - val_loss: 1.1825 - val_accuracy: 0.5365\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 14s 103ms/step - loss: 1.0716 - accuracy: 0.5389 - val_loss: 1.1851 - val_accuracy: 0.5409\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 14s 106ms/step - loss: 1.0467 - accuracy: 0.5464 - val_loss: 1.1787 - val_accuracy: 0.5572\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 14s 108ms/step - loss: 1.0098 - accuracy: 0.5645 - val_loss: 1.1071 - val_accuracy: 0.5550\n",
      "Duration: 0:02:19.201022\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0117093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 18s 97ms/step - loss: 1.5689 - accuracy: 0.3746 - val_loss: 1.6466 - val_accuracy: 0.4607\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 17s 96ms/step - loss: 1.2749 - accuracy: 0.4671 - val_loss: 1.6217 - val_accuracy: 0.5050\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 17s 97ms/step - loss: 1.1786 - accuracy: 0.4966 - val_loss: 1.4143 - val_accuracy: 0.5027\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 17s 95ms/step - loss: 1.1348 - accuracy: 0.5098 - val_loss: 1.3753 - val_accuracy: 0.4854\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 17s 96ms/step - loss: 1.0768 - accuracy: 0.5354 - val_loss: 1.2650 - val_accuracy: 0.5333\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 17s 98ms/step - loss: 1.0448 - accuracy: 0.5539 - val_loss: 1.2492 - val_accuracy: 0.5499\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 17s 97ms/step - loss: 1.0093 - accuracy: 0.5683 - val_loss: 1.2352 - val_accuracy: 0.5386\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 17s 95ms/step - loss: 0.9824 - accuracy: 0.5826 - val_loss: 1.1243 - val_accuracy: 0.5709\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 17s 95ms/step - loss: 0.9474 - accuracy: 0.6067 - val_loss: 1.1486 - val_accuracy: 0.5715\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 17s 94ms/step - loss: 0.9281 - accuracy: 0.6096 - val_loss: 1.1102 - val_accuracy: 0.5683\n",
      "Duration: 0:02:48.520295\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0fd6ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 21s 92ms/step - loss: 1.5121 - accuracy: 0.3961 - val_loss: 1.6422 - val_accuracy: 0.4790\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 1.2065 - accuracy: 0.4867 - val_loss: 1.6129 - val_accuracy: 0.5238\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 1.1128 - accuracy: 0.5264 - val_loss: 1.4593 - val_accuracy: 0.5197\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 1.0493 - accuracy: 0.5521 - val_loss: 1.3516 - val_accuracy: 0.5561\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 1.0022 - accuracy: 0.5809 - val_loss: 1.2291 - val_accuracy: 0.5726\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 0.9511 - accuracy: 0.6029 - val_loss: 1.2346 - val_accuracy: 0.5825\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 0.9292 - accuracy: 0.6164 - val_loss: 1.2011 - val_accuracy: 0.5969\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 20s 90ms/step - loss: 0.8901 - accuracy: 0.6389 - val_loss: 1.0643 - val_accuracy: 0.6171\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 0.8724 - accuracy: 0.6480 - val_loss: 1.1072 - val_accuracy: 0.6251\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 20s 91ms/step - loss: 0.8293 - accuracy: 0.6664 - val_loss: 1.1833 - val_accuracy: 0.6121\n",
      "Duration: 0:03:19.721935\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4da2afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 24s 89ms/step - loss: 1.3937 - accuracy: 0.4311 - val_loss: 1.5954 - val_accuracy: 0.5152\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 1.1214 - accuracy: 0.5255 - val_loss: 1.3981 - val_accuracy: 0.5288\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 23s 89ms/step - loss: 1.0334 - accuracy: 0.5713 - val_loss: 1.2977 - val_accuracy: 0.5659\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.9700 - accuracy: 0.6061 - val_loss: 1.1875 - val_accuracy: 0.5835\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.9216 - accuracy: 0.6328 - val_loss: 1.2014 - val_accuracy: 0.5953\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.8847 - accuracy: 0.6473 - val_loss: 1.1021 - val_accuracy: 0.5953\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.8440 - accuracy: 0.6667 - val_loss: 1.0425 - val_accuracy: 0.6033\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 24s 92ms/step - loss: 0.8218 - accuracy: 0.6767 - val_loss: 1.0474 - val_accuracy: 0.6141\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 23s 86ms/step - loss: 0.7917 - accuracy: 0.6962 - val_loss: 1.2452 - val_accuracy: 0.6122\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 23s 87ms/step - loss: 0.7710 - accuracy: 0.7086 - val_loss: 1.0081 - val_accuracy: 0.6322\n",
      "Duration: 0:03:51.117589\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "708b003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 27s 84ms/step - loss: 1.4029 - accuracy: 0.4405 - val_loss: 1.7059 - val_accuracy: 0.5264\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 1.0842 - accuracy: 0.5616 - val_loss: 1.3774 - val_accuracy: 0.5454\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.9828 - accuracy: 0.6101 - val_loss: 1.2305 - val_accuracy: 0.5914\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.9231 - accuracy: 0.6377 - val_loss: 1.2269 - val_accuracy: 0.5656\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.8571 - accuracy: 0.6702 - val_loss: 1.0766 - val_accuracy: 0.5959\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.8222 - accuracy: 0.6885 - val_loss: 1.0230 - val_accuracy: 0.6091\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.7835 - accuracy: 0.7087 - val_loss: 0.9987 - val_accuracy: 0.6196\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 26s 83ms/step - loss: 0.7523 - accuracy: 0.7202 - val_loss: 0.9150 - val_accuracy: 0.6206\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 26s 84ms/step - loss: 0.7279 - accuracy: 0.7333 - val_loss: 0.8407 - val_accuracy: 0.6524\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 25s 82ms/step - loss: 0.7076 - accuracy: 0.7433 - val_loss: 0.8487 - val_accuracy: 0.6430\n",
      "Duration: 0:04:17.537884\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58947fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 29s 81ms/step - loss: 1.2957 - accuracy: 0.4851 - val_loss: 1.3148 - val_accuracy: 0.5428\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.9772 - accuracy: 0.6224 - val_loss: 1.2582 - val_accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.8768 - accuracy: 0.6746 - val_loss: 0.9971 - val_accuracy: 0.6032\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.7980 - accuracy: 0.7098 - val_loss: 1.0057 - val_accuracy: 0.6146\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.7490 - accuracy: 0.7275 - val_loss: 0.9857 - val_accuracy: 0.6419\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.7119 - accuracy: 0.7438 - val_loss: 0.8000 - val_accuracy: 0.7358\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6815 - accuracy: 0.7540 - val_loss: 0.8144 - val_accuracy: 0.6863\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 28s 81ms/step - loss: 0.6555 - accuracy: 0.7648 - val_loss: 0.8253 - val_accuracy: 0.7239\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 28s 80ms/step - loss: 0.6434 - accuracy: 0.7772 - val_loss: 0.7336 - val_accuracy: 0.7449\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 28s 79ms/step - loss: 0.6255 - accuracy: 0.7816 - val_loss: 0.9716 - val_accuracy: 0.7241\n",
      "Duration: 0:04:42.824548\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2f2a2891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 33s 81ms/step - loss: 1.2615 - accuracy: 0.5199 - val_loss: 1.3805 - val_accuracy: 0.5671\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 34s 85ms/step - loss: 0.9131 - accuracy: 0.6682 - val_loss: 1.1548 - val_accuracy: 0.5837\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 32s 82ms/step - loss: 0.8018 - accuracy: 0.7116 - val_loss: 1.0594 - val_accuracy: 0.6182\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.7387 - accuracy: 0.7383 - val_loss: 0.9732 - val_accuracy: 0.6354\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.7013 - accuracy: 0.7546 - val_loss: 0.9375 - val_accuracy: 0.6441\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.6694 - accuracy: 0.7634 - val_loss: 1.0235 - val_accuracy: 0.6331\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.6414 - accuracy: 0.7802 - val_loss: 0.7444 - val_accuracy: 0.6791\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.6313 - accuracy: 0.7838 - val_loss: 0.8628 - val_accuracy: 0.7118\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 32s 81ms/step - loss: 0.6162 - accuracy: 0.7919 - val_loss: 0.8950 - val_accuracy: 0.7232\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 33s 83ms/step - loss: 0.6060 - accuracy: 0.7940 - val_loss: 0.8153 - val_accuracy: 0.7438\n",
      "Duration: 0:05:23.793178\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56ab5ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 37s 81ms/step - loss: 1.1491 - accuracy: 0.5663 - val_loss: 1.1931 - val_accuracy: 0.5666\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.8229 - accuracy: 0.7054 - val_loss: 0.9253 - val_accuracy: 0.6203\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 35s 81ms/step - loss: 0.7250 - accuracy: 0.7470 - val_loss: 0.8509 - val_accuracy: 0.6477\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.6781 - accuracy: 0.7642 - val_loss: 0.8220 - val_accuracy: 0.6611\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.6428 - accuracy: 0.7787 - val_loss: 0.8521 - val_accuracy: 0.7082\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 35s 80ms/step - loss: 0.6186 - accuracy: 0.7909 - val_loss: 0.7192 - val_accuracy: 0.7495\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 34s 79ms/step - loss: 0.5977 - accuracy: 0.7946 - val_loss: 0.6789 - val_accuracy: 0.7665\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5825 - accuracy: 0.7998 - val_loss: 0.6499 - val_accuracy: 0.7701\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5840 - accuracy: 0.8048 - val_loss: 0.7182 - val_accuracy: 0.7480\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 35s 79ms/step - loss: 0.5723 - accuracy: 0.8067 - val_loss: 0.7984 - val_accuracy: 0.7589\n",
      "Duration: 0:05:50.807107\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "00e27d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 39s 79ms/step - loss: 1.0876 - accuracy: 0.6045 - val_loss: 1.1207 - val_accuracy: 0.5791\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.7518 - accuracy: 0.7370 - val_loss: 0.8300 - val_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 39s 81ms/step - loss: 0.6707 - accuracy: 0.7703 - val_loss: 0.7441 - val_accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.6167 - accuracy: 0.7906 - val_loss: 0.7188 - val_accuracy: 0.7669\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5886 - accuracy: 0.7981 - val_loss: 0.6263 - val_accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5716 - accuracy: 0.8061 - val_loss: 0.5822 - val_accuracy: 0.7834\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5538 - accuracy: 0.8152 - val_loss: 0.5647 - val_accuracy: 0.7909\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5418 - accuracy: 0.8196 - val_loss: 0.5030 - val_accuracy: 0.8160\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 39s 80ms/step - loss: 0.5357 - accuracy: 0.8232 - val_loss: 0.5218 - val_accuracy: 0.8045\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 38s 79ms/step - loss: 0.5331 - accuracy: 0.8229 - val_loss: 0.8872 - val_accuracy: 0.7739\n",
      "Duration: 0:06:23.942102\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b47a8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 43s 80ms/step - loss: 1.0759 - accuracy: 0.6095 - val_loss: 0.9534 - val_accuracy: 0.6153\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 42s 79ms/step - loss: 0.7367 - accuracy: 0.7460 - val_loss: 0.7843 - val_accuracy: 0.6488\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 41s 77ms/step - loss: 0.6490 - accuracy: 0.7786 - val_loss: 0.6398 - val_accuracy: 0.7615\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 41s 79ms/step - loss: 0.5975 - accuracy: 0.7966 - val_loss: 0.5650 - val_accuracy: 0.7922\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 42s 80ms/step - loss: 0.5724 - accuracy: 0.8056 - val_loss: 0.5334 - val_accuracy: 0.8064\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5451 - accuracy: 0.8185 - val_loss: 0.5450 - val_accuracy: 0.8180\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5325 - accuracy: 0.8212 - val_loss: 0.4745 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 41s 78ms/step - loss: 0.5281 - accuracy: 0.8261 - val_loss: 0.5917 - val_accuracy: 0.8128\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5280 - accuracy: 0.8246 - val_loss: 0.4240 - val_accuracy: 0.8654\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 40s 77ms/step - loss: 0.5193 - accuracy: 0.8303 - val_loss: 0.3767 - val_accuracy: 0.8794\n",
      "Duration: 0:06:52.113650\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ddf3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 1.0113 - accuracy: 0.6434 - val_loss: 0.7878 - val_accuracy: 0.6399\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.6960 - accuracy: 0.7609 - val_loss: 0.5588 - val_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.6156 - accuracy: 0.7926 - val_loss: 0.4718 - val_accuracy: 0.8312\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.5711 - accuracy: 0.8065 - val_loss: 0.4670 - val_accuracy: 0.8418\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.5399 - accuracy: 0.8202 - val_loss: 0.3493 - val_accuracy: 0.8855\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.5216 - accuracy: 0.8265 - val_loss: 0.3749 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 44s 77ms/step - loss: 0.5084 - accuracy: 0.8309 - val_loss: 0.3280 - val_accuracy: 0.8920\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 44s 78ms/step - loss: 0.5043 - accuracy: 0.8363 - val_loss: 0.3932 - val_accuracy: 0.8729\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 45s 78ms/step - loss: 0.5031 - accuracy: 0.8351 - val_loss: 0.3541 - val_accuracy: 0.8775\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 45s 79ms/step - loss: 0.5024 - accuracy: 0.8367 - val_loss: 0.3268 - val_accuracy: 0.8920\n",
      "Duration: 0:07:22.428590\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6dd3b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 50s 79ms/step - loss: 0.9763 - accuracy: 0.6557 - val_loss: 0.6411 - val_accuracy: 0.7625\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 50s 82ms/step - loss: 0.6579 - accuracy: 0.7715 - val_loss: 0.4435 - val_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 49s 79ms/step - loss: 0.5714 - accuracy: 0.8071 - val_loss: 0.3580 - val_accuracy: 0.8838\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 49s 80ms/step - loss: 0.5313 - accuracy: 0.8245 - val_loss: 0.3070 - val_accuracy: 0.8903\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 49s 80ms/step - loss: 0.5017 - accuracy: 0.8326 - val_loss: 0.2883 - val_accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 48s 79ms/step - loss: 0.4787 - accuracy: 0.8410 - val_loss: 0.2806 - val_accuracy: 0.8997\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 47s 76ms/step - loss: 0.4760 - accuracy: 0.8432 - val_loss: 0.2839 - val_accuracy: 0.9014\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4687 - accuracy: 0.8462 - val_loss: 0.3538 - val_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 47s 77ms/step - loss: 0.4649 - accuracy: 0.8480 - val_loss: 0.2905 - val_accuracy: 0.8982\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 48s 78ms/step - loss: 0.4641 - accuracy: 0.8508 - val_loss: 0.3242 - val_accuracy: 0.9049\n",
      "Duration: 0:08:03.423549\n"
     ]
    }
   ],
   "source": [
    "n=13\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5d71002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 0.9648 - accuracy: 0.6623 - val_loss: 0.5096 - val_accuracy: 0.8176\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.6315 - accuracy: 0.7872 - val_loss: 0.3413 - val_accuracy: 0.8740\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.5385 - accuracy: 0.8201 - val_loss: 0.3048 - val_accuracy: 0.8864\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.4945 - accuracy: 0.8336 - val_loss: 0.2857 - val_accuracy: 0.8953\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4592 - accuracy: 0.8470 - val_loss: 0.2759 - val_accuracy: 0.9009\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.4524 - accuracy: 0.8519 - val_loss: 0.2731 - val_accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.4399 - accuracy: 0.8576 - val_loss: 0.3488 - val_accuracy: 0.8985\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.4388 - accuracy: 0.8599 - val_loss: 0.3324 - val_accuracy: 0.8951\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.4450 - accuracy: 0.8561 - val_loss: 0.3072 - val_accuracy: 0.9034\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.4329 - accuracy: 0.8590 - val_loss: 0.3110 - val_accuracy: 0.9039\n",
      "Duration: 0:08:35.382903\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d31122c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 55s 78ms/step - loss: 0.8786 - accuracy: 0.6904 - val_loss: 0.3956 - val_accuracy: 0.8570\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.5634 - accuracy: 0.8125 - val_loss: 0.3215 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4839 - accuracy: 0.8404 - val_loss: 0.2785 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4459 - accuracy: 0.8510 - val_loss: 0.2706 - val_accuracy: 0.9010\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 53s 76ms/step - loss: 0.4336 - accuracy: 0.8592 - val_loss: 0.2792 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4170 - accuracy: 0.8606 - val_loss: 0.2655 - val_accuracy: 0.9049\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4140 - accuracy: 0.8663 - val_loss: 0.2840 - val_accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4140 - accuracy: 0.8686 - val_loss: 0.2786 - val_accuracy: 0.9065\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 53s 75ms/step - loss: 0.4172 - accuracy: 0.8668 - val_loss: 0.2734 - val_accuracy: 0.9039\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 52s 75ms/step - loss: 0.4187 - accuracy: 0.8688 - val_loss: 0.2932 - val_accuracy: 0.9046\n",
      "Duration: 0:08:51.780811\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1670fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9dfc2d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 54s 71ms/step - loss: 0.8545 - accuracy: 0.6976 - val_loss: 0.3769 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 53s 72ms/step - loss: 0.5348 - accuracy: 0.8228 - val_loss: 0.3122 - val_accuracy: 0.8859\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.4676 - accuracy: 0.8450 - val_loss: 0.2916 - val_accuracy: 0.8984\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.4309 - accuracy: 0.8589 - val_loss: 0.2838 - val_accuracy: 0.8999\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4201 - accuracy: 0.8629 - val_loss: 0.2805 - val_accuracy: 0.9005\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 51s 68ms/step - loss: 0.4124 - accuracy: 0.8679 - val_loss: 0.2706 - val_accuracy: 0.9016\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4136 - accuracy: 0.8689 - val_loss: 0.2761 - val_accuracy: 0.9036\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 52s 69ms/step - loss: 0.4131 - accuracy: 0.8684 - val_loss: 0.2856 - val_accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 51s 69ms/step - loss: 0.4141 - accuracy: 0.8682 - val_loss: 0.3255 - val_accuracy: 0.8989\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 52s 70ms/step - loss: 0.4212 - accuracy: 0.8686 - val_loss: 0.3332 - val_accuracy: 0.8982\n",
      "Duration: 0:08:39.395290\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b91ad678",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3facdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 51s 63ms/step - loss: 0.8371 - accuracy: 0.7009 - val_loss: 0.4094 - val_accuracy: 0.8502\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 50s 64ms/step - loss: 0.5088 - accuracy: 0.8278 - val_loss: 0.3531 - val_accuracy: 0.8748\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 50s 64ms/step - loss: 0.4487 - accuracy: 0.8500 - val_loss: 0.3005 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 48s 61ms/step - loss: 0.4164 - accuracy: 0.8623 - val_loss: 0.3074 - val_accuracy: 0.8904\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 48s 61ms/step - loss: 0.4075 - accuracy: 0.8680 - val_loss: 0.3219 - val_accuracy: 0.8959\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.4001 - accuracy: 0.8722 - val_loss: 0.2944 - val_accuracy: 0.9009\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.3976 - accuracy: 0.8731 - val_loss: 0.3221 - val_accuracy: 0.8989\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.3989 - accuracy: 0.8737 - val_loss: 0.2907 - val_accuracy: 0.8949\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.4037 - accuracy: 0.8706 - val_loss: 0.3084 - val_accuracy: 0.8999\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 47s 60ms/step - loss: 0.4062 - accuracy: 0.8707 - val_loss: 0.2923 - val_accuracy: 0.8934\n",
      "Duration: 0:08:03.818619\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "39f645c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "06125a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 52s 62ms/step - loss: 0.7674 - accuracy: 0.7311 - val_loss: 0.4047 - val_accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 52s 63ms/step - loss: 0.4789 - accuracy: 0.8403 - val_loss: 0.3205 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 51s 61ms/step - loss: 0.4132 - accuracy: 0.8624 - val_loss: 0.2944 - val_accuracy: 0.8964\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 51s 62ms/step - loss: 0.3934 - accuracy: 0.8732 - val_loss: 0.3239 - val_accuracy: 0.8970\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 49s 59ms/step - loss: 0.3821 - accuracy: 0.8758 - val_loss: 0.3242 - val_accuracy: 0.8996\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 49s 59ms/step - loss: 0.3798 - accuracy: 0.8787 - val_loss: 0.2915 - val_accuracy: 0.8994\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 50s 60ms/step - loss: 0.3767 - accuracy: 0.8803 - val_loss: 0.3316 - val_accuracy: 0.8772\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 50s 60ms/step - loss: 0.3759 - accuracy: 0.8805 - val_loss: 0.3148 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 50s 60ms/step - loss: 0.3816 - accuracy: 0.8806 - val_loss: 0.2980 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 50s 60ms/step - loss: 0.3865 - accuracy: 0.8799 - val_loss: 0.3579 - val_accuracy: 0.8759\n",
      "Duration: 0:08:24.449651\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c99cd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c859c93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 53s 60ms/step - loss: 0.7241 - accuracy: 0.7428 - val_loss: 0.3854 - val_accuracy: 0.8638\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 52s 60ms/step - loss: 0.4487 - accuracy: 0.8489 - val_loss: 0.3119 - val_accuracy: 0.8833\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 52s 59ms/step - loss: 0.3977 - accuracy: 0.8697 - val_loss: 0.2828 - val_accuracy: 0.8971\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 53s 60ms/step - loss: 0.3722 - accuracy: 0.8792 - val_loss: 0.2918 - val_accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 58s 67ms/step - loss: 0.3594 - accuracy: 0.8858 - val_loss: 0.2945 - val_accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 61s 69ms/step - loss: 0.3589 - accuracy: 0.8850 - val_loss: 0.2972 - val_accuracy: 0.8956\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 61s 70ms/step - loss: 0.3637 - accuracy: 0.8872 - val_loss: 0.2915 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3681 - accuracy: 0.8833 - val_loss: 0.2963 - val_accuracy: 0.8923\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3693 - accuracy: 0.8841 - val_loss: 0.2908 - val_accuracy: 0.8960\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 62s 71ms/step - loss: 0.3729 - accuracy: 0.8836 - val_loss: 0.3012 - val_accuracy: 0.8936\n",
      "Duration: 0:09:36.568603\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "61d40f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "825c1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_se_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_se_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_se_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_se:\n",
    "    model.save(new_model_se_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "95d86000",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del se_values\n",
    "    del top_images_by_se\n",
    "    del top_labels_by_se\n",
    "    del image_sets_se\n",
    "    del label_sets_se\n",
    "    del models_se\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fcf7c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78274"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11198aa3",
   "metadata": {},
   "source": [
    "## Training guided by Random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3581436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43703, 34094, 54014, 19868, 43544, 18605, 53966, 20381, 5989, 10792]\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_indexes =list(range(len(x_train_and_adversary)))\n",
    "random.shuffle(random_indexes)\n",
    "print(random_indexes[:10])\n",
    "print(len(random_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eca574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"D:/guided-retraining/data/\"+dataset+\"/random_values.npy\"\n",
    "\n",
    "\n",
    "random_indexes = np.load(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a735c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d13ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by random values\n",
    "top_images_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),x_train_and_adversary)\n",
    "top_labels_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),y_train_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1209ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_random = []\n",
    "label_sets_random = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_random)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_random)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_random)%m))\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m])\n",
    "    image_sets_random.append(top_images_by_random_n)\n",
    "    label_sets_random.append(top_labels_by_random_n)\n",
    "    print(len(top_images_by_random_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ed47a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f03e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_random = []\n",
    "for i in range(len(label_sets_random)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False,None)\n",
    "    model.compile_model()\n",
    "    models_random.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6b62e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_random[0].evaluate(x_test_and_adversary,y_test_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14912c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 6s 125ms/step - loss: 1.7979 - accuracy: 0.3364 - val_loss: 0.9375 - val_accuracy: 0.7007\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 1.1753 - accuracy: 0.5946 - val_loss: 0.7113 - val_accuracy: 0.7587\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 5s 120ms/step - loss: 0.9541 - accuracy: 0.6636 - val_loss: 0.6012 - val_accuracy: 0.7811\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 125ms/step - loss: 0.8366 - accuracy: 0.7100 - val_loss: 0.5722 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.7682 - accuracy: 0.7343 - val_loss: 0.5538 - val_accuracy: 0.7926\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 126ms/step - loss: 0.6788 - accuracy: 0.7561 - val_loss: 0.5234 - val_accuracy: 0.8057\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.6433 - accuracy: 0.7625 - val_loss: 0.5200 - val_accuracy: 0.8114\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 6s 129ms/step - loss: 0.5796 - accuracy: 0.7911 - val_loss: 0.4989 - val_accuracy: 0.8086\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 123ms/step - loss: 0.5788 - accuracy: 0.7900 - val_loss: 0.4719 - val_accuracy: 0.8291\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 6s 130ms/step - loss: 0.5554 - accuracy: 0.8021 - val_loss: 0.4767 - val_accuracy: 0.8289\n",
      "Duration: 0:00:55.612964\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f28e27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 9s 94ms/step - loss: 1.4871 - accuracy: 0.4582 - val_loss: 0.8110 - val_accuracy: 0.7110\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 8s 94ms/step - loss: 0.9249 - accuracy: 0.6777 - val_loss: 0.6209 - val_accuracy: 0.7743\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 0.7587 - accuracy: 0.7343 - val_loss: 0.5208 - val_accuracy: 0.8035\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 0.6641 - accuracy: 0.7573 - val_loss: 0.4774 - val_accuracy: 0.8100\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 0.6018 - accuracy: 0.7839 - val_loss: 0.4828 - val_accuracy: 0.8238\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 0.5540 - accuracy: 0.7925 - val_loss: 0.4383 - val_accuracy: 0.8349\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 0.5283 - accuracy: 0.8121 - val_loss: 0.4501 - val_accuracy: 0.8225\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 0.4934 - accuracy: 0.8268 - val_loss: 0.4134 - val_accuracy: 0.8459\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.4771 - accuracy: 0.8307 - val_loss: 0.3971 - val_accuracy: 0.8631\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 0.4539 - accuracy: 0.8398 - val_loss: 0.4067 - val_accuracy: 0.8562\n",
      "Duration: 0:01:19.565426\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00a45124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 11s 78ms/step - loss: 1.3501 - accuracy: 0.5213 - val_loss: 0.7359 - val_accuracy: 0.7259\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8201 - accuracy: 0.7132 - val_loss: 0.5366 - val_accuracy: 0.8031\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.6739 - accuracy: 0.7658 - val_loss: 0.4591 - val_accuracy: 0.8256\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.5953 - accuracy: 0.7886 - val_loss: 0.4349 - val_accuracy: 0.8439\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.5538 - accuracy: 0.8073 - val_loss: 0.4123 - val_accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.5123 - accuracy: 0.8267 - val_loss: 0.3956 - val_accuracy: 0.8546\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4703 - accuracy: 0.8332 - val_loss: 0.3747 - val_accuracy: 0.8652\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.4457 - accuracy: 0.8448 - val_loss: 0.3747 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4324 - accuracy: 0.8544 - val_loss: 0.3809 - val_accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.4196 - accuracy: 0.8583 - val_loss: 0.3685 - val_accuracy: 0.8667\n",
      "Duration: 0:01:41.847770\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2855a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 14s 73ms/step - loss: 1.1924 - accuracy: 0.5748 - val_loss: 0.5803 - val_accuracy: 0.7807\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 12s 72ms/step - loss: 0.7349 - accuracy: 0.7408 - val_loss: 0.4816 - val_accuracy: 0.8131\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 13s 72ms/step - loss: 0.6228 - accuracy: 0.7852 - val_loss: 0.4466 - val_accuracy: 0.8328\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.5555 - accuracy: 0.8079 - val_loss: 0.4106 - val_accuracy: 0.8504\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.5114 - accuracy: 0.8266 - val_loss: 0.3926 - val_accuracy: 0.8546\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.4654 - accuracy: 0.8375 - val_loss: 0.3583 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.4470 - accuracy: 0.8501 - val_loss: 0.3631 - val_accuracy: 0.8677\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.4175 - accuracy: 0.8604 - val_loss: 0.3414 - val_accuracy: 0.8773\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.4004 - accuracy: 0.8651 - val_loss: 0.3345 - val_accuracy: 0.8823\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.3738 - accuracy: 0.8709 - val_loss: 0.3259 - val_accuracy: 0.8864\n",
      "Duration: 0:02:06.761300\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1bd0c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 25s 103ms/step - loss: 1.1369 - accuracy: 0.6015 - val_loss: 0.5630 - val_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 20s 93ms/step - loss: 0.6775 - accuracy: 0.7611 - val_loss: 0.4664 - val_accuracy: 0.8163\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 22s 99ms/step - loss: 0.5694 - accuracy: 0.8037 - val_loss: 0.4465 - val_accuracy: 0.8321\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 22s 100ms/step - loss: 0.5042 - accuracy: 0.8280 - val_loss: 0.3877 - val_accuracy: 0.8566\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 22s 100ms/step - loss: 0.4577 - accuracy: 0.8444 - val_loss: 0.3607 - val_accuracy: 0.8714\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 22s 100ms/step - loss: 0.4260 - accuracy: 0.8568 - val_loss: 0.3670 - val_accuracy: 0.8683\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 21s 98ms/step - loss: 0.4013 - accuracy: 0.8631 - val_loss: 0.3363 - val_accuracy: 0.8809\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 22s 100ms/step - loss: 0.3825 - accuracy: 0.8715 - val_loss: 0.3129 - val_accuracy: 0.8894\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 22s 101ms/step - loss: 0.3617 - accuracy: 0.8786 - val_loss: 0.3419 - val_accuracy: 0.8861\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 22s 100ms/step - loss: 0.3513 - accuracy: 0.8809 - val_loss: 0.3186 - val_accuracy: 0.8865\n",
      "Duration: 0:03:40.169454\n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2860ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 27s 97ms/step - loss: 1.0252 - accuracy: 0.6324 - val_loss: 0.5235 - val_accuracy: 0.8029\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 0.6185 - accuracy: 0.7814 - val_loss: 0.4446 - val_accuracy: 0.8403\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 0.5189 - accuracy: 0.8231 - val_loss: 0.4071 - val_accuracy: 0.8472\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.4713 - accuracy: 0.8416 - val_loss: 0.3746 - val_accuracy: 0.8596\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 25s 93ms/step - loss: 0.4381 - accuracy: 0.8538 - val_loss: 0.3509 - val_accuracy: 0.8769\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.4143 - accuracy: 0.8601 - val_loss: 0.3353 - val_accuracy: 0.8811\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.3874 - accuracy: 0.8702 - val_loss: 0.3467 - val_accuracy: 0.8719\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 0.3697 - accuracy: 0.8761 - val_loss: 0.3447 - val_accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 25s 95ms/step - loss: 0.3587 - accuracy: 0.8824 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 26s 98ms/step - loss: 0.3511 - accuracy: 0.8851 - val_loss: 0.3202 - val_accuracy: 0.8887\n",
      "Duration: 0:04:14.837917\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40781770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 20s 64ms/step - loss: 0.3407 - accuracy: 0.8884 - val_loss: 0.3046 - val_accuracy: 0.8924\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 20s 64ms/step - loss: 0.3308 - accuracy: 0.8909 - val_loss: 0.3061 - val_accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 21s 67ms/step - loss: 0.3303 - accuracy: 0.8898 - val_loss: 0.2987 - val_accuracy: 0.9014\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 21s 68ms/step - loss: 0.3352 - accuracy: 0.8919 - val_loss: 0.3232 - val_accuracy: 0.8918\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 21s 69ms/step - loss: 0.3299 - accuracy: 0.8914 - val_loss: 0.3045 - val_accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 20s 66ms/step - loss: 0.3301 - accuracy: 0.8931 - val_loss: 0.3172 - val_accuracy: 0.8901\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 21s 67ms/step - loss: 0.3185 - accuracy: 0.8956 - val_loss: 0.3689 - val_accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 21s 69ms/step - loss: 0.3156 - accuracy: 0.8963 - val_loss: 0.3076 - val_accuracy: 0.8977\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 21s 68ms/step - loss: 0.3235 - accuracy: 0.8950 - val_loss: 0.3189 - val_accuracy: 0.8909\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 22s 72ms/step - loss: 0.3165 - accuracy: 0.8951 - val_loss: 0.3640 - val_accuracy: 0.8921\n",
      "Duration: 0:03:26.785765\n"
     ]
    }
   ],
   "source": [
    "n=6\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a224e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 24s 68ms/step - loss: 0.3308 - accuracy: 0.8907 - val_loss: 0.2863 - val_accuracy: 0.9005\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 22s 64ms/step - loss: 0.3233 - accuracy: 0.8952 - val_loss: 0.2821 - val_accuracy: 0.9021\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 22s 64ms/step - loss: 0.3242 - accuracy: 0.8914 - val_loss: 0.3260 - val_accuracy: 0.8980\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 23s 65ms/step - loss: 0.3206 - accuracy: 0.8925 - val_loss: 0.3165 - val_accuracy: 0.9011\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 24s 68ms/step - loss: 0.3160 - accuracy: 0.8986 - val_loss: 0.2923 - val_accuracy: 0.8998\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 23s 67ms/step - loss: 0.3226 - accuracy: 0.8976 - val_loss: 0.3257 - val_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 23s 66ms/step - loss: 0.3208 - accuracy: 0.8963 - val_loss: 0.3093 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 23s 66ms/step - loss: 0.3238 - accuracy: 0.8963 - val_loss: 0.3594 - val_accuracy: 0.8970\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 23s 66ms/step - loss: 0.3230 - accuracy: 0.8979 - val_loss: 0.3183 - val_accuracy: 0.8988\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 23s 67ms/step - loss: 0.3226 - accuracy: 0.8981 - val_loss: 0.3211 - val_accuracy: 0.8897\n",
      "Duration: 0:03:51.060305\n"
     ]
    }
   ],
   "source": [
    "n=7\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e896788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 38s 92ms/step - loss: 0.9475 - accuracy: 0.6648 - val_loss: 0.5252 - val_accuracy: 0.7994\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 37s 93ms/step - loss: 0.5669 - accuracy: 0.8038 - val_loss: 0.3926 - val_accuracy: 0.8548\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.4779 - accuracy: 0.8409 - val_loss: 0.3416 - val_accuracy: 0.8721\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.4269 - accuracy: 0.8555 - val_loss: 0.3342 - val_accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.4002 - accuracy: 0.8649 - val_loss: 0.3250 - val_accuracy: 0.8836\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.3825 - accuracy: 0.8720 - val_loss: 0.3011 - val_accuracy: 0.8933\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.3648 - accuracy: 0.8776 - val_loss: 0.2980 - val_accuracy: 0.8894\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 36s 91ms/step - loss: 0.3558 - accuracy: 0.8810 - val_loss: 0.2961 - val_accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 36s 92ms/step - loss: 0.3562 - accuracy: 0.8830 - val_loss: 0.2876 - val_accuracy: 0.8965\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 35s 88ms/step - loss: 0.3473 - accuracy: 0.8855 - val_loss: 0.3208 - val_accuracy: 0.8856\n",
      "Duration: 0:06:00.340299\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97b092f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 41s 89ms/step - loss: 0.8829 - accuracy: 0.6855 - val_loss: 0.4561 - val_accuracy: 0.8366\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.5431 - accuracy: 0.8118 - val_loss: 0.3783 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 29s 67ms/step - loss: 0.4610 - accuracy: 0.8444 - val_loss: 0.3357 - val_accuracy: 0.8753\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 28s 63ms/step - loss: 0.4184 - accuracy: 0.8602 - val_loss: 0.3431 - val_accuracy: 0.8774\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 28s 63ms/step - loss: 0.3955 - accuracy: 0.8702 - val_loss: 0.3312 - val_accuracy: 0.8834\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 28s 64ms/step - loss: 0.3726 - accuracy: 0.8778 - val_loss: 0.3224 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 29s 66ms/step - loss: 0.3652 - accuracy: 0.8774 - val_loss: 0.3268 - val_accuracy: 0.8939\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 28s 63ms/step - loss: 0.3521 - accuracy: 0.8815 - val_loss: 0.3361 - val_accuracy: 0.8885\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 33s 74ms/step - loss: 0.3453 - accuracy: 0.8869 - val_loss: 0.3033 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 37s 84ms/step - loss: 0.3373 - accuracy: 0.8896 - val_loss: 0.2973 - val_accuracy: 0.8951\n",
      "Duration: 0:05:16.608981\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fd850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 31s 63ms/step - loss: 0.8609 - accuracy: 0.6935 - val_loss: 0.4874 - val_accuracy: 0.8172\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 29s 61ms/step - loss: 0.5161 - accuracy: 0.8235 - val_loss: 0.4061 - val_accuracy: 0.8485\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 30s 61ms/step - loss: 0.4428 - accuracy: 0.8526 - val_loss: 0.3362 - val_accuracy: 0.8761\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 30s 63ms/step - loss: 0.4003 - accuracy: 0.8668 - val_loss: 0.3279 - val_accuracy: 0.8851\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 31s 64ms/step - loss: 0.3792 - accuracy: 0.8737 - val_loss: 0.3283 - val_accuracy: 0.8841\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 31s 65ms/step - loss: 0.3695 - accuracy: 0.8787 - val_loss: 0.3066 - val_accuracy: 0.8909\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 31s 64ms/step - loss: 0.3564 - accuracy: 0.8824 - val_loss: 0.3012 - val_accuracy: 0.8905\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 30s 62ms/step - loss: 0.3542 - accuracy: 0.8838 - val_loss: 0.3024 - val_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 31s 64ms/step - loss: 0.3475 - accuracy: 0.8879 - val_loss: 0.2922 - val_accuracy: 0.8964\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 33s 67ms/step - loss: 0.3442 - accuracy: 0.8877 - val_loss: 0.2959 - val_accuracy: 0.9000\n",
      "Duration: 0:05:06.751503\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85693a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 35s 65ms/step - loss: 0.8291 - accuracy: 0.7013 - val_loss: 0.4307 - val_accuracy: 0.8471\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 32s 61ms/step - loss: 0.5022 - accuracy: 0.8299 - val_loss: 0.3691 - val_accuracy: 0.8691\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 32s 60ms/step - loss: 0.4330 - accuracy: 0.8558 - val_loss: 0.3373 - val_accuracy: 0.8771\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 32s 61ms/step - loss: 0.3925 - accuracy: 0.8706 - val_loss: 0.2959 - val_accuracy: 0.8901\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 34s 65ms/step - loss: 0.3749 - accuracy: 0.8768 - val_loss: 0.2888 - val_accuracy: 0.8990\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 33s 63ms/step - loss: 0.3595 - accuracy: 0.8807 - val_loss: 0.3037 - val_accuracy: 0.8997\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 35s 67ms/step - loss: 0.3522 - accuracy: 0.8838 - val_loss: 0.2997 - val_accuracy: 0.8945\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 34s 65ms/step - loss: 0.3516 - accuracy: 0.8856 - val_loss: 0.3149 - val_accuracy: 0.8881\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 33s 62ms/step - loss: 0.3526 - accuracy: 0.8853 - val_loss: 0.2934 - val_accuracy: 0.8986\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 36s 68ms/step - loss: 0.3550 - accuracy: 0.8865 - val_loss: 0.2922 - val_accuracy: 0.8979\n",
      "Duration: 0:05:35.686618\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8afbd045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 36s 63ms/step - loss: 0.8285 - accuracy: 0.7039 - val_loss: 0.4253 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 36s 63ms/step - loss: 0.5042 - accuracy: 0.8277 - val_loss: 0.3822 - val_accuracy: 0.8658\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.4307 - accuracy: 0.8562 - val_loss: 0.3161 - val_accuracy: 0.8854\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 35s 62ms/step - loss: 0.3994 - accuracy: 0.8675 - val_loss: 0.3219 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.3773 - accuracy: 0.8757 - val_loss: 0.3012 - val_accuracy: 0.8957\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.3728 - accuracy: 0.8784 - val_loss: 0.2915 - val_accuracy: 0.8963\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.3597 - accuracy: 0.8833 - val_loss: 0.2880 - val_accuracy: 0.8949\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 34s 60ms/step - loss: 0.3589 - accuracy: 0.8834 - val_loss: 0.2885 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 34s 59ms/step - loss: 0.3559 - accuracy: 0.8877 - val_loss: 0.3136 - val_accuracy: 0.8930\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 34s 59ms/step - loss: 0.3598 - accuracy: 0.8864 - val_loss: 0.2990 - val_accuracy: 0.9004\n",
      "Duration: 0:05:48.462701\n"
     ]
    }
   ],
   "source": [
    "n=12\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da217c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(models_random[12].model.layers[-1].weights[0][0])\n",
    "#print(models_random[14].model.layers[-1].weights[0][0])\n",
    "#print(models_random[16].model.layers[-1].weights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19d31001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 37s 59ms/step - loss: 0.7981 - accuracy: 0.7181 - val_loss: 0.4059 - val_accuracy: 0.8486\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 36s 59ms/step - loss: 0.4883 - accuracy: 0.8370 - val_loss: 0.3369 - val_accuracy: 0.8779\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 36s 59ms/step - loss: 0.4163 - accuracy: 0.8633 - val_loss: 0.3097 - val_accuracy: 0.8894\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 38s 61ms/step - loss: 0.3830 - accuracy: 0.8722 - val_loss: 0.2965 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 38s 62ms/step - loss: 0.3624 - accuracy: 0.8803 - val_loss: 0.3965 - val_accuracy: 0.8891\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 36s 59ms/step - loss: 0.3522 - accuracy: 0.8852 - val_loss: 0.2879 - val_accuracy: 0.8983\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 41s 68ms/step - loss: 0.3555 - accuracy: 0.8857 - val_loss: 0.2969 - val_accuracy: 0.9008\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 37s 61ms/step - loss: 0.3497 - accuracy: 0.8861 - val_loss: 0.3932 - val_accuracy: 0.8965\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 38s 62ms/step - loss: 0.3474 - accuracy: 0.8897 - val_loss: 0.2956 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 38s 63ms/step - loss: 0.3507 - accuracy: 0.8883 - val_loss: 0.3326 - val_accuracy: 0.8898\n",
      "Duration: 0:06:16.258892\n"
     ]
    }
   ],
   "source": [
    "n=13\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1dc0bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 44s 66ms/step - loss: 0.7816 - accuracy: 0.7330 - val_loss: 0.4135 - val_accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 44s 66ms/step - loss: 0.4667 - accuracy: 0.8425 - val_loss: 0.4008 - val_accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 42s 64ms/step - loss: 0.4118 - accuracy: 0.8642 - val_loss: 0.3174 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 46s 70ms/step - loss: 0.3820 - accuracy: 0.8745 - val_loss: 0.3333 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 45s 69ms/step - loss: 0.3594 - accuracy: 0.8813 - val_loss: 0.3134 - val_accuracy: 0.8882\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 53s 81ms/step - loss: 0.3608 - accuracy: 0.8834 - val_loss: 0.3145 - val_accuracy: 0.8956\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 45s 69ms/step - loss: 0.3542 - accuracy: 0.8862 - val_loss: 0.3413 - val_accuracy: 0.8946\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.3551 - accuracy: 0.8857 - val_loss: 0.3246 - val_accuracy: 0.8992\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.3527 - accuracy: 0.8892 - val_loss: 0.2922 - val_accuracy: 0.9026\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 44s 67ms/step - loss: 0.3425 - accuracy: 0.8905 - val_loss: 0.3422 - val_accuracy: 0.9011\n",
      "Duration: 0:07:29.897287\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eddbcc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 45s 63ms/step - loss: 0.7469 - accuracy: 0.7340 - val_loss: 0.3981 - val_accuracy: 0.8526\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 44s 62ms/step - loss: 0.4598 - accuracy: 0.8460 - val_loss: 0.3347 - val_accuracy: 0.8781\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 49s 71ms/step - loss: 0.4069 - accuracy: 0.8661 - val_loss: 0.3335 - val_accuracy: 0.8817\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 46s 66ms/step - loss: 0.3764 - accuracy: 0.8752 - val_loss: 0.3015 - val_accuracy: 0.8940\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 49s 70ms/step - loss: 0.3696 - accuracy: 0.8800 - val_loss: 0.2757 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 46s 66ms/step - loss: 0.3560 - accuracy: 0.8843 - val_loss: 0.2848 - val_accuracy: 0.8996\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 45s 65ms/step - loss: 0.3519 - accuracy: 0.8867 - val_loss: 0.2797 - val_accuracy: 0.8999\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 48s 68ms/step - loss: 0.3507 - accuracy: 0.8869 - val_loss: 0.3164 - val_accuracy: 0.8964\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 43s 62ms/step - loss: 0.3573 - accuracy: 0.8866 - val_loss: 0.2995 - val_accuracy: 0.8935\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 48s 69ms/step - loss: 0.3581 - accuracy: 0.8865 - val_loss: 0.2858 - val_accuracy: 0.8979\n",
      "Duration: 0:07:44.854318\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9541290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 69s 90ms/step - loss: 0.7695 - accuracy: 0.7334 - val_loss: 0.3913 - val_accuracy: 0.8535\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 64s 86ms/step - loss: 0.4685 - accuracy: 0.8436 - val_loss: 0.3224 - val_accuracy: 0.8808\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.4089 - accuracy: 0.8648 - val_loss: 0.3026 - val_accuracy: 0.8916\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3838 - accuracy: 0.8746 - val_loss: 0.3054 - val_accuracy: 0.8932\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3705 - accuracy: 0.8793 - val_loss: 0.3085 - val_accuracy: 0.8878\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3633 - accuracy: 0.8803 - val_loss: 0.3038 - val_accuracy: 0.8946\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3598 - accuracy: 0.8844 - val_loss: 0.3038 - val_accuracy: 0.8941\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3607 - accuracy: 0.8830 - val_loss: 0.3085 - val_accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 67s 90ms/step - loss: 0.3612 - accuracy: 0.8853 - val_loss: 0.3452 - val_accuracy: 0.8905\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 66s 89ms/step - loss: 0.3625 - accuracy: 0.8850 - val_loss: 0.3301 - val_accuracy: 0.8964\n",
      "Duration: 0:11:08.807954\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4967f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 71s 88ms/step - loss: 0.7413 - accuracy: 0.7424 - val_loss: 0.3878 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 70s 88ms/step - loss: 0.4538 - accuracy: 0.8455 - val_loss: 0.3324 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 69s 88ms/step - loss: 0.4010 - accuracy: 0.8660 - val_loss: 0.3057 - val_accuracy: 0.8923\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 68s 86ms/step - loss: 0.3748 - accuracy: 0.8753 - val_loss: 0.3127 - val_accuracy: 0.8909\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 68s 87ms/step - loss: 0.3659 - accuracy: 0.8792 - val_loss: 0.2957 - val_accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 69s 88ms/step - loss: 0.3676 - accuracy: 0.8815 - val_loss: 0.3567 - val_accuracy: 0.8918\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 69s 88ms/step - loss: 0.3633 - accuracy: 0.8836 - val_loss: 0.3693 - val_accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 71s 90ms/step - loss: 0.3600 - accuracy: 0.8852 - val_loss: 0.3013 - val_accuracy: 0.8978\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 70s 89ms/step - loss: 0.3592 - accuracy: 0.8858 - val_loss: 0.3046 - val_accuracy: 0.8968\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 69s 87ms/step - loss: 0.3620 - accuracy: 0.8863 - val_loss: 0.3230 - val_accuracy: 0.8978\n",
      "Duration: 0:11:34.323182\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f385c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 76s 90ms/step - loss: 0.7411 - accuracy: 0.7405 - val_loss: 0.3844 - val_accuracy: 0.8551\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 72s 87ms/step - loss: 0.4594 - accuracy: 0.8460 - val_loss: 0.3205 - val_accuracy: 0.8853\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 72s 87ms/step - loss: 0.4020 - accuracy: 0.8677 - val_loss: 0.3376 - val_accuracy: 0.8849\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 72s 87ms/step - loss: 0.3780 - accuracy: 0.8766 - val_loss: 0.3481 - val_accuracy: 0.8816\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 72s 87ms/step - loss: 0.3712 - accuracy: 0.8792 - val_loss: 0.3436 - val_accuracy: 0.8911\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 74s 89ms/step - loss: 0.3627 - accuracy: 0.8843 - val_loss: 0.3091 - val_accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 75s 90ms/step - loss: 0.3626 - accuracy: 0.8837 - val_loss: 0.3371 - val_accuracy: 0.8961\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 74s 89ms/step - loss: 0.3611 - accuracy: 0.8854 - val_loss: 0.3185 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 75s 90ms/step - loss: 0.3625 - accuracy: 0.8859 - val_loss: 0.3075 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 74s 89ms/step - loss: 0.3648 - accuracy: 0.8856 - val_loss: 0.3065 - val_accuracy: 0.8959\n",
      "Duration: 0:12:17.016854\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f624a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa4e4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 79s 88ms/step - loss: 0.7248 - accuracy: 0.7473 - val_loss: 0.3649 - val_accuracy: 0.8676\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 78s 89ms/step - loss: 0.4424 - accuracy: 0.8544 - val_loss: 0.3003 - val_accuracy: 0.8912\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 78s 89ms/step - loss: 0.3896 - accuracy: 0.8723 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 76s 87ms/step - loss: 0.3729 - accuracy: 0.8788 - val_loss: 0.2946 - val_accuracy: 0.8961\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 75s 86ms/step - loss: 0.3654 - accuracy: 0.8824 - val_loss: 0.2846 - val_accuracy: 0.8977\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 75s 85ms/step - loss: 0.3586 - accuracy: 0.8853 - val_loss: 0.2778 - val_accuracy: 0.9007\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 77s 88ms/step - loss: 0.3611 - accuracy: 0.8858 - val_loss: 0.3045 - val_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 76s 86ms/step - loss: 0.3578 - accuracy: 0.8861 - val_loss: 0.2809 - val_accuracy: 0.9038\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 77s 88ms/step - loss: 0.3666 - accuracy: 0.8854 - val_loss: 0.3841 - val_accuracy: 0.8858\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 75s 86ms/step - loss: 0.3690 - accuracy: 0.8851 - val_loss: 0.3052 - val_accuracy: 0.8950\n",
      "Duration: 0:12:45.415014\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad8e3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24dc2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_random_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_random_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_random_e1\"\n",
    "\n",
    "i=12\n",
    "\n",
    "for model in models_random[i:]:\n",
    "    model.save(new_model_random_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d243087",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_random = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_random_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_random_e1_\"+str(i)\n",
    "        print(model_random_dir)\n",
    "        model =utils.My_model('gtsrb',True,model_random_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_random.append(model)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85078e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del random_indexes\n",
    "    del top_images_by_random\n",
    "    del top_labels_by_random\n",
    "    del image_sets_random\n",
    "    del label_sets_random\n",
    "    del models_random\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a4c9d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24242"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a54b05",
   "metadata": {},
   "source": [
    "## Training guided by NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e53f2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC\n",
    "nc_values = []\n",
    "for i in range(1,17):\n",
    "    #save_dir = \"C:/Users/fjdur/Desktop/upc/project_notebooks/github_project/DL_notebooks/NC_values/nc_values_\"+str(i)+\".npy\"\n",
    "    save_dir = \"D:/guided-retraining/data/\"+dataset+\"/\"+dataset+\"_nc_values_\"+str(i)+\".npy\"\n",
    "\n",
    "    #print(save_dir_rand)\n",
    "    tmp_values = np.load(save_dir)\n",
    "    #print(tmp_values.shape)\n",
    "    nc_values = np.append(nc_values,tmp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "637de522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55998,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "024f3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_images_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),x_train_and_adversary)\n",
    "top_labels_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),y_train_and_adversary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7490c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  2800\n",
      "2800\n",
      "1 :\n",
      "0  ->  5600\n",
      "5600\n",
      "2 :\n",
      "0  ->  8400\n",
      "8400\n",
      "3 :\n",
      "0  ->  11200\n",
      "11200\n",
      "4 :\n",
      "0  ->  14000\n",
      "14000\n",
      "5 :\n",
      "0  ->  16800\n",
      "16800\n",
      "6 :\n",
      "0  ->  19600\n",
      "19600\n",
      "7 :\n",
      "0  ->  22400\n",
      "22400\n",
      "8 :\n",
      "0  ->  25200\n",
      "25200\n",
      "9 :\n",
      "0  ->  28000\n",
      "28000\n",
      "10 :\n",
      "0  ->  30800\n",
      "30800\n",
      "11 :\n",
      "0  ->  33600\n",
      "33600\n",
      "12 :\n",
      "0  ->  36400\n",
      "36400\n",
      "13 :\n",
      "0  ->  39200\n",
      "39200\n",
      "14 :\n",
      "0  ->  42000\n",
      "42000\n",
      "15 :\n",
      "0  ->  44800\n",
      "44800\n",
      "16 :\n",
      "0  ->  47600\n",
      "47600\n",
      "17 :\n",
      "0  ->  50400\n",
      "50400\n",
      "18 :\n",
      "0  ->  53200\n",
      "53200\n",
      "19 :\n",
      "Last\n",
      "0  ->  58798\n",
      "55998\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_nc = []\n",
    "label_sets_nc = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_nc)//m)+1):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_nc)//m)+1)):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_nc)%m))\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m])\n",
    "    image_sets_nc.append(top_images_by_nc_n)\n",
    "    label_sets_nc.append(top_labels_by_nc_n)\n",
    "    print(len(top_images_by_nc_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a65e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model compiled\n",
      "1 :\n",
      "Model compiled\n",
      "2 :\n",
      "Model compiled\n",
      "3 :\n",
      "Model compiled\n",
      "4 :\n",
      "Model compiled\n",
      "5 :\n",
      "Model compiled\n",
      "6 :\n",
      "Model compiled\n",
      "7 :\n",
      "Model compiled\n",
      "8 :\n",
      "Model compiled\n",
      "9 :\n",
      "Model compiled\n",
      "10 :\n",
      "Model compiled\n",
      "11 :\n",
      "Model compiled\n",
      "12 :\n",
      "Model compiled\n",
      "13 :\n",
      "Model compiled\n",
      "14 :\n",
      "Model compiled\n",
      "15 :\n",
      "Model compiled\n",
      "16 :\n",
      "Model compiled\n",
      "17 :\n",
      "Model compiled\n",
      "18 :\n",
      "Model compiled\n",
      "19 :\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_nc = []\n",
    "for i in range(len(label_sets_nc)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,False,None)\n",
    "    model.compile_model()\n",
    "    models_nc.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df0b6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 10s 207ms/step - loss: 0.9771 - accuracy: 0.7225 - val_loss: 2.9484 - val_accuracy: 0.1834\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 9s 205ms/step - loss: 0.5966 - accuracy: 0.8457 - val_loss: 2.7337 - val_accuracy: 0.2197\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 9s 198ms/step - loss: 0.5260 - accuracy: 0.8582 - val_loss: 2.4956 - val_accuracy: 0.2156\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 8s 194ms/step - loss: 0.4722 - accuracy: 0.8693 - val_loss: 2.5077 - val_accuracy: 0.2276\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 8s 193ms/step - loss: 0.4408 - accuracy: 0.8736 - val_loss: 2.3435 - val_accuracy: 0.2252\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 9s 197ms/step - loss: 0.4233 - accuracy: 0.8761 - val_loss: 2.9106 - val_accuracy: 0.2361\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 8s 193ms/step - loss: 0.3953 - accuracy: 0.8786 - val_loss: 2.2638 - val_accuracy: 0.2342\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 9s 196ms/step - loss: 0.3822 - accuracy: 0.8814 - val_loss: 2.5507 - val_accuracy: 0.2429\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 8s 194ms/step - loss: 0.3743 - accuracy: 0.8850 - val_loss: 2.8249 - val_accuracy: 0.2679\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 8s 193ms/step - loss: 0.3496 - accuracy: 0.8914 - val_loss: 2.7832 - val_accuracy: 0.2626\n",
      "Duration: 0:01:27.212597\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f4f3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "88/88 [==============================] - 14s 139ms/step - loss: 0.9480 - accuracy: 0.7202 - val_loss: 2.6829 - val_accuracy: 0.3553\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.5636 - accuracy: 0.8368 - val_loss: 2.7969 - val_accuracy: 0.3506\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.4849 - accuracy: 0.8600 - val_loss: 2.4802 - val_accuracy: 0.3899\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 0.4298 - accuracy: 0.8725 - val_loss: 2.5577 - val_accuracy: 0.4104\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 0.3865 - accuracy: 0.8838 - val_loss: 2.8332 - val_accuracy: 0.4143\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.3683 - accuracy: 0.8923 - val_loss: 2.1529 - val_accuracy: 0.4240\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 0.3492 - accuracy: 0.8957 - val_loss: 2.8989 - val_accuracy: 0.4151\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.3303 - accuracy: 0.9011 - val_loss: 2.5770 - val_accuracy: 0.4454\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 0.3169 - accuracy: 0.9068 - val_loss: 2.3844 - val_accuracy: 0.4631\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 0.3027 - accuracy: 0.9104 - val_loss: 2.5291 - val_accuracy: 0.4556\n",
      "Duration: 0:01:59.164890\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f72b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 17s 120ms/step - loss: 0.8583 - accuracy: 0.7501 - val_loss: 2.1843 - val_accuracy: 0.4253\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.4762 - accuracy: 0.8705 - val_loss: 2.2112 - val_accuracy: 0.4868\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.3990 - accuracy: 0.8900 - val_loss: 2.3643 - val_accuracy: 0.5601\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 0.3463 - accuracy: 0.9029 - val_loss: 1.8761 - val_accuracy: 0.5784\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 16s 118ms/step - loss: 0.3168 - accuracy: 0.9118 - val_loss: 2.4389 - val_accuracy: 0.6059\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.3062 - accuracy: 0.9151 - val_loss: 2.3951 - val_accuracy: 0.6071\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 15s 117ms/step - loss: 0.2736 - accuracy: 0.9250 - val_loss: 2.3926 - val_accuracy: 0.6139\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.2753 - accuracy: 0.9252 - val_loss: 2.2285 - val_accuracy: 0.6058\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 0.2496 - accuracy: 0.9314 - val_loss: 2.0137 - val_accuracy: 0.6613\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 0.2345 - accuracy: 0.9329 - val_loss: 1.5535 - val_accuracy: 0.6568\n",
      "Duration: 0:02:35.982298\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08f19179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "175/175 [==============================] - 20s 106ms/step - loss: 0.8070 - accuracy: 0.7565 - val_loss: 2.2828 - val_accuracy: 0.5090\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.4484 - accuracy: 0.8756 - val_loss: 1.9367 - val_accuracy: 0.6516\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.3704 - accuracy: 0.9001 - val_loss: 1.9511 - val_accuracy: 0.6996\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 19s 107ms/step - loss: 0.3257 - accuracy: 0.9129 - val_loss: 1.9800 - val_accuracy: 0.7241\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.2977 - accuracy: 0.9194 - val_loss: 1.8426 - val_accuracy: 0.7221\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 18s 102ms/step - loss: 0.2747 - accuracy: 0.9274 - val_loss: 1.8320 - val_accuracy: 0.7282\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.2557 - accuracy: 0.9307 - val_loss: 1.7351 - val_accuracy: 0.7243\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 18s 103ms/step - loss: 0.2377 - accuracy: 0.9357 - val_loss: 1.8971 - val_accuracy: 0.7400\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.2301 - accuracy: 0.9370 - val_loss: 2.7736 - val_accuracy: 0.7246\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.2166 - accuracy: 0.9416 - val_loss: 2.0403 - val_accuracy: 0.7290\n",
      "Duration: 0:03:05.403986\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf71df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "219/219 [==============================] - 26s 112ms/step - loss: 0.8142 - accuracy: 0.7518 - val_loss: 2.0669 - val_accuracy: 0.6498\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 24s 108ms/step - loss: 0.4129 - accuracy: 0.8846 - val_loss: 1.9900 - val_accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 23s 107ms/step - loss: 0.3275 - accuracy: 0.9114 - val_loss: 2.3065 - val_accuracy: 0.7220\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 23s 106ms/step - loss: 0.2957 - accuracy: 0.9203 - val_loss: 2.3855 - val_accuracy: 0.7267\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 23s 107ms/step - loss: 0.2669 - accuracy: 0.9291 - val_loss: 1.8780 - val_accuracy: 0.7330 \n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 0.2528 - accuracy: 0.9308 - val_loss: 1.4845 - val_accuracy: 0.7389\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 22s 101ms/step - loss: 0.2353 - accuracy: 0.9371 - val_loss: 2.0213 - val_accuracy: 0.7337\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 23s 103ms/step - loss: 0.2208 - accuracy: 0.9410 - val_loss: 1.5216 - val_accuracy: 0.7427\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 23s 103ms/step - loss: 0.2192 - accuracy: 0.9396 - val_loss: 1.9039 - val_accuracy: 0.7409\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 0.2062 - accuracy: 0.9440 - val_loss: 1.1693 - val_accuracy: 0.7464\n",
      "Duration: 0:03:52.684293\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c3d36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 28s 103ms/step - loss: 0.7770 - accuracy: 0.7561 - val_loss: 1.8881 - val_accuracy: 0.6827\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.3877 - accuracy: 0.8892 - val_loss: 2.0738 - val_accuracy: 0.7106\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 27s 102ms/step - loss: 0.3081 - accuracy: 0.9158 - val_loss: 1.8955 - val_accuracy: 0.7330\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 0.2767 - accuracy: 0.9246 - val_loss: 1.7315 - val_accuracy: 0.7392\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 27s 103ms/step - loss: 0.2467 - accuracy: 0.9355 - val_loss: 1.6940 - val_accuracy: 0.7443\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 0.2251 - accuracy: 0.9412 - val_loss: 1.5940 - val_accuracy: 0.7456\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 0.2151 - accuracy: 0.9421 - val_loss: 1.6104 - val_accuracy: 0.7473\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 0.2081 - accuracy: 0.9446 - val_loss: 1.3861 - val_accuracy: 0.7464\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 25s 96ms/step - loss: 0.2002 - accuracy: 0.9477 - val_loss: 2.2079 - val_accuracy: 0.7462\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 26s 100ms/step - loss: 0.2002 - accuracy: 0.9478 - val_loss: 1.6151 - val_accuracy: 0.7487\n",
      "Duration: 0:04:29.938878\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "052013fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 32s 98ms/step - loss: 0.7073 - accuracy: 0.7784 - val_loss: 2.4072 - val_accuracy: 0.7026\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 30s 99ms/step - loss: 0.3393 - accuracy: 0.9048 - val_loss: 2.6282 - val_accuracy: 0.7286\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 33s 107ms/step - loss: 0.2799 - accuracy: 0.9256 - val_loss: 2.4791 - val_accuracy: 0.7426\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 30s 97ms/step - loss: 0.2492 - accuracy: 0.9348 - val_loss: 2.3416 - val_accuracy: 0.7493\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 30s 98ms/step - loss: 0.2281 - accuracy: 0.9409 - val_loss: 2.0473 - val_accuracy: 0.7504\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 29s 95ms/step - loss: 0.2203 - accuracy: 0.9434 - val_loss: 2.2664 - val_accuracy: 0.7391\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 29s 96ms/step - loss: 0.2086 - accuracy: 0.9460 - val_loss: 1.5475 - val_accuracy: 0.7521\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 30s 98ms/step - loss: 0.2007 - accuracy: 0.9493 - val_loss: 1.4677 - val_accuracy: 0.7628\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 30s 97ms/step - loss: 0.2048 - accuracy: 0.9472 - val_loss: 2.2292 - val_accuracy: 0.7571\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 30s 98ms/step - loss: 0.2043 - accuracy: 0.9503 - val_loss: 1.2171 - val_accuracy: 0.7511\n",
      "Duration: 0:05:03.252175\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bbe30246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "350/350 [==============================] - 62s 176ms/step - loss: 0.6784 - accuracy: 0.7894 - val_loss: 2.0806 - val_accuracy: 0.7151\n",
      "Epoch 2/10\n",
      "350/350 [==============================] - 35s 101ms/step - loss: 0.3394 - accuracy: 0.9058 - val_loss: 1.9993 - val_accuracy: 0.7365\n",
      "Epoch 3/10\n",
      "350/350 [==============================] - 35s 101ms/step - loss: 0.2705 - accuracy: 0.9282 - val_loss: 2.5328 - val_accuracy: 0.7498\n",
      "Epoch 4/10\n",
      "350/350 [==============================] - 35s 99ms/step - loss: 0.2445 - accuracy: 0.9354 - val_loss: 1.4971 - val_accuracy: 0.7507\n",
      "Epoch 5/10\n",
      "350/350 [==============================] - 35s 100ms/step - loss: 0.2240 - accuracy: 0.9432 - val_loss: 2.9312 - val_accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "350/350 [==============================] - 34s 96ms/step - loss: 0.2136 - accuracy: 0.9450 - val_loss: 1.4298 - val_accuracy: 0.7527\n",
      "Epoch 7/10\n",
      "350/350 [==============================] - 34s 96ms/step - loss: 0.2050 - accuracy: 0.9472 - val_loss: 1.4034 - val_accuracy: 0.7617\n",
      "Epoch 8/10\n",
      "350/350 [==============================] - 33s 95ms/step - loss: 0.1968 - accuracy: 0.9480 - val_loss: 1.2047 - val_accuracy: 0.7639\n",
      "Epoch 9/10\n",
      "350/350 [==============================] - 33s 95ms/step - loss: 0.2041 - accuracy: 0.9492 - val_loss: 2.2765 - val_accuracy: 0.7692\n",
      "Epoch 10/10\n",
      "350/350 [==============================] - 33s 95ms/step - loss: 0.1991 - accuracy: 0.9502 - val_loss: 2.4140 - val_accuracy: 0.7603\n",
      "Duration: 0:06:09.545507\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cd1b82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "394/394 [==============================] - 39s 97ms/step - loss: 0.6754 - accuracy: 0.7827 - val_loss: 2.2921 - val_accuracy: 0.7216\n",
      "Epoch 2/10\n",
      "394/394 [==============================] - 38s 97ms/step - loss: 0.3247 - accuracy: 0.9083 - val_loss: 1.8502 - val_accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.2609 - accuracy: 0.9307 - val_loss: 1.6027 - val_accuracy: 0.7544\n",
      "Epoch 4/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.2337 - accuracy: 0.9392 - val_loss: 0.9835 - val_accuracy: 0.7653\n",
      "Epoch 5/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.2129 - accuracy: 0.9445 - val_loss: 1.8594 - val_accuracy: 0.7646\n",
      "Epoch 6/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.2077 - accuracy: 0.9456 - val_loss: 1.4654 - val_accuracy: 0.7631\n",
      "Epoch 7/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.2044 - accuracy: 0.9477 - val_loss: 1.1656 - val_accuracy: 0.7709\n",
      "Epoch 8/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.1949 - accuracy: 0.9494 - val_loss: 1.5616 - val_accuracy: 0.7661\n",
      "Epoch 9/10\n",
      "394/394 [==============================] - 38s 96ms/step - loss: 0.1997 - accuracy: 0.9493 - val_loss: 1.0014 - val_accuracy: 0.7737\n",
      "Epoch 10/10\n",
      "394/394 [==============================] - 42s 106ms/step - loss: 0.1950 - accuracy: 0.9499 - val_loss: 1.5638 - val_accuracy: 0.7645\n",
      "Duration: 0:06:24.506786\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aaec4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "438/438 [==============================] - 45s 99ms/step - loss: 0.6725 - accuracy: 0.7885 - val_loss: 1.5828 - val_accuracy: 0.7275\n",
      "Epoch 2/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.3094 - accuracy: 0.9149 - val_loss: 1.1094 - val_accuracy: 0.7454\n",
      "Epoch 3/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.2547 - accuracy: 0.9335 - val_loss: 0.8390 - val_accuracy: 0.7634\n",
      "Epoch 4/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.2296 - accuracy: 0.9410 - val_loss: 0.8618 - val_accuracy: 0.7717\n",
      "Epoch 5/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.2103 - accuracy: 0.9445 - val_loss: 0.9518 - val_accuracy: 0.7735\n",
      "Epoch 6/10\n",
      "438/438 [==============================] - 43s 97ms/step - loss: 0.2091 - accuracy: 0.9467 - val_loss: 0.9112 - val_accuracy: 0.7731\n",
      "Epoch 7/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.1993 - accuracy: 0.9492 - val_loss: 1.0023 - val_accuracy: 0.7679\n",
      "Epoch 8/10\n",
      "438/438 [==============================] - 43s 98ms/step - loss: 0.1997 - accuracy: 0.9498 - val_loss: 0.9482 - val_accuracy: 0.7677\n",
      "Epoch 9/10\n",
      "438/438 [==============================] - 42s 95ms/step - loss: 0.1906 - accuracy: 0.9505 - val_loss: 0.9071 - val_accuracy: 0.7676\n",
      "Epoch 10/10\n",
      "438/438 [==============================] - 43s 97ms/step - loss: 0.1992 - accuracy: 0.9510 - val_loss: 0.8646 - val_accuracy: 0.7726\n",
      "Duration: 0:07:09.319752\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80bb2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "482/482 [==============================] - 48s 97ms/step - loss: 0.6361 - accuracy: 0.7950 - val_loss: 0.6216 - val_accuracy: 0.8204\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 47s 97ms/step - loss: 0.3021 - accuracy: 0.9150 - val_loss: 0.5051 - val_accuracy: 0.8482\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 47s 97ms/step - loss: 0.2531 - accuracy: 0.9316 - val_loss: 0.4824 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 47s 97ms/step - loss: 0.2247 - accuracy: 0.9402 - val_loss: 0.5070 - val_accuracy: 0.8547\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 46s 96ms/step - loss: 0.2139 - accuracy: 0.9452 - val_loss: 0.5100 - val_accuracy: 0.8671\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 47s 96ms/step - loss: 0.2079 - accuracy: 0.9455 - val_loss: 0.5914 - val_accuracy: 0.8617\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 47s 97ms/step - loss: 0.1985 - accuracy: 0.9483 - val_loss: 0.5364 - val_accuracy: 0.8698\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 46s 95ms/step - loss: 0.1939 - accuracy: 0.9492 - val_loss: 0.5236 - val_accuracy: 0.8754\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 45s 93ms/step - loss: 0.1963 - accuracy: 0.9494 - val_loss: 0.5678 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 44s 92ms/step - loss: 0.1968 - accuracy: 0.9489 - val_loss: 0.5149 - val_accuracy: 0.8680\n",
      "Duration: 0:07:43.281881\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05eb10ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "525/525 [==============================] - 49s 91ms/step - loss: 0.6247 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.8354\n",
      "Epoch 2/10\n",
      "525/525 [==============================] - 47s 89ms/step - loss: 0.3016 - accuracy: 0.9152 - val_loss: 0.4905 - val_accuracy: 0.8536\n",
      "Epoch 3/10\n",
      "525/525 [==============================] - 47s 90ms/step - loss: 0.2447 - accuracy: 0.9330 - val_loss: 0.4590 - val_accuracy: 0.8664\n",
      "Epoch 4/10\n",
      "525/525 [==============================] - 146s 279ms/step - loss: 0.2253 - accuracy: 0.9385 - val_loss: 0.4412 - val_accuracy: 0.8696\n",
      "Epoch 5/10\n",
      "525/525 [==============================] - 44s 84ms/step - loss: 0.2160 - accuracy: 0.9443 - val_loss: 0.4069 - val_accuracy: 0.8768\n",
      "Epoch 6/10\n",
      "525/525 [==============================] - 38s 72ms/step - loss: 0.2053 - accuracy: 0.9457 - val_loss: 0.4706 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "525/525 [==============================] - 35s 68ms/step - loss: 0.2080 - accuracy: 0.9466 - val_loss: 0.4838 - val_accuracy: 0.8747\n",
      "Epoch 8/10\n",
      "525/525 [==============================] - 33s 63ms/step - loss: 0.2009 - accuracy: 0.9469 - val_loss: 0.4493 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "525/525 [==============================] - 34s 64ms/step - loss: 0.2074 - accuracy: 0.9461 - val_loss: 0.4588 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "525/525 [==============================] - 36s 68ms/step - loss: 0.2032 - accuracy: 0.9488 - val_loss: 0.4989 - val_accuracy: 0.8756\n",
      "Duration: 0:08:29.247958\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a022543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "569/569 [==============================] - 47s 81ms/step - loss: 0.5996 - accuracy: 0.8072 - val_loss: 0.5561 - val_accuracy: 0.8334\n",
      "Epoch 2/10\n",
      "569/569 [==============================] - 37s 64ms/step - loss: 0.2982 - accuracy: 0.9167 - val_loss: 0.4371 - val_accuracy: 0.8597\n",
      "Epoch 3/10\n",
      "569/569 [==============================] - 36s 63ms/step - loss: 0.2467 - accuracy: 0.9340 - val_loss: 0.4463 - val_accuracy: 0.8709\n",
      "Epoch 4/10\n",
      "569/569 [==============================] - 35s 62ms/step - loss: 0.2264 - accuracy: 0.9394 - val_loss: 0.4361 - val_accuracy: 0.8709\n",
      "Epoch 5/10\n",
      "569/569 [==============================] - 35s 62ms/step - loss: 0.2165 - accuracy: 0.9429 - val_loss: 0.3996 - val_accuracy: 0.8779\n",
      "Epoch 6/10\n",
      "569/569 [==============================] - 36s 62ms/step - loss: 0.2071 - accuracy: 0.9463 - val_loss: 0.4938 - val_accuracy: 0.8729\n",
      "Epoch 7/10\n",
      "569/569 [==============================] - 36s 64ms/step - loss: 0.2053 - accuracy: 0.9470 - val_loss: 0.3782 - val_accuracy: 0.8784\n",
      "Epoch 8/10\n",
      "569/569 [==============================] - 36s 63ms/step - loss: 0.2081 - accuracy: 0.9470 - val_loss: 0.3979 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.2072 - accuracy: 0.9462 - val_loss: 0.4602 - val_accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "569/569 [==============================] - 35s 61ms/step - loss: 0.2029 - accuracy: 0.9484 - val_loss: 0.5916 - val_accuracy: 0.8742\n",
      "Duration: 0:06:07.897347\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f74c0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "613/613 [==============================] - 40s 64ms/step - loss: 0.6240 - accuracy: 0.7973 - val_loss: 0.4709 - val_accuracy: 0.8453\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 38s 62ms/step - loss: 0.3128 - accuracy: 0.9115 - val_loss: 0.4156 - val_accuracy: 0.8676\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 39s 63ms/step - loss: 0.2590 - accuracy: 0.9290 - val_loss: 0.4355 - val_accuracy: 0.8690\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 39s 64ms/step - loss: 0.2379 - accuracy: 0.9357 - val_loss: 0.4077 - val_accuracy: 0.8768\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2192 - accuracy: 0.9398 - val_loss: 0.3686 - val_accuracy: 0.8809\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 42s 69ms/step - loss: 0.2160 - accuracy: 0.9409 - val_loss: 0.4197 - val_accuracy: 0.8819\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 41s 67ms/step - loss: 0.2176 - accuracy: 0.9438 - val_loss: 0.4499 - val_accuracy: 0.8850\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 41s 68ms/step - loss: 0.2221 - accuracy: 0.9421 - val_loss: 0.4043 - val_accuracy: 0.8808\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 41s 67ms/step - loss: 0.2172 - accuracy: 0.9432 - val_loss: 0.5551 - val_accuracy: 0.8802\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 40s 65ms/step - loss: 0.2223 - accuracy: 0.9427 - val_loss: 0.6402 - val_accuracy: 0.8752\n",
      "Duration: 0:06:42.237113\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "582a5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 46s 68ms/step - loss: 0.6202 - accuracy: 0.8008 - val_loss: 0.4868 - val_accuracy: 0.8407\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 45s 68ms/step - loss: 0.3125 - accuracy: 0.9100 - val_loss: 0.4580 - val_accuracy: 0.8666\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 44s 67ms/step - loss: 0.2690 - accuracy: 0.9257 - val_loss: 0.3900 - val_accuracy: 0.8710\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 44s 67ms/step - loss: 0.2426 - accuracy: 0.9334 - val_loss: 0.4985 - val_accuracy: 0.8704\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 43s 66ms/step - loss: 0.2319 - accuracy: 0.9380 - val_loss: 0.5503 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 43s 66ms/step - loss: 0.2320 - accuracy: 0.9374 - val_loss: 0.4424 - val_accuracy: 0.8783\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.2248 - accuracy: 0.9390 - val_loss: 0.5606 - val_accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 0.2317 - accuracy: 0.9398 - val_loss: 0.6428 - val_accuracy: 0.8839\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 42s 64ms/step - loss: 0.2336 - accuracy: 0.9392 - val_loss: 0.4829 - val_accuracy: 0.8629\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 43s 66ms/step - loss: 0.2388 - accuracy: 0.9371 - val_loss: 0.4340 - val_accuracy: 0.8869\n",
      "Duration: 0:07:16.662030\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1a9a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 50s 70ms/step - loss: 0.5905 - accuracy: 0.8092 - val_loss: 0.4198 - val_accuracy: 0.8585\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 48s 69ms/step - loss: 0.3113 - accuracy: 0.9096 - val_loss: 0.4170 - val_accuracy: 0.8715\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 47s 68ms/step - loss: 0.2669 - accuracy: 0.9263 - val_loss: 0.3738 - val_accuracy: 0.8799\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 47s 68ms/step - loss: 0.2444 - accuracy: 0.9319 - val_loss: 0.3619 - val_accuracy: 0.8832\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 49s 70ms/step - loss: 0.2333 - accuracy: 0.9352 - val_loss: 0.3881 - val_accuracy: 0.8859\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 47s 67ms/step - loss: 0.2334 - accuracy: 0.9361 - val_loss: 0.4251 - val_accuracy: 0.8873\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 48s 68ms/step - loss: 0.2342 - accuracy: 0.9362 - val_loss: 0.4089 - val_accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 46s 66ms/step - loss: 0.2333 - accuracy: 0.9373 - val_loss: 0.4042 - val_accuracy: 0.8891\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 46s 66ms/step - loss: 0.2337 - accuracy: 0.9374 - val_loss: 0.3768 - val_accuracy: 0.8859\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 49s 70ms/step - loss: 0.2373 - accuracy: 0.9370 - val_loss: 0.3553 - val_accuracy: 0.8807\n",
      "Duration: 0:07:57.778964\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cb1c2372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "744/744 [==============================] - 52s 68ms/step - loss: 0.6276 - accuracy: 0.7914 - val_loss: 0.4122 - val_accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "744/744 [==============================] - 50s 67ms/step - loss: 0.3414 - accuracy: 0.8971 - val_loss: 0.3573 - val_accuracy: 0.8764\n",
      "Epoch 3/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.2948 - accuracy: 0.9136 - val_loss: 0.3192 - val_accuracy: 0.8914\n",
      "Epoch 4/10\n",
      "744/744 [==============================] - 50s 68ms/step - loss: 0.2686 - accuracy: 0.9225 - val_loss: 0.3931 - val_accuracy: 0.8867\n",
      "Epoch 5/10\n",
      "744/744 [==============================] - 49s 65ms/step - loss: 0.2654 - accuracy: 0.9248 - val_loss: 0.3463 - val_accuracy: 0.8933\n",
      "Epoch 6/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.2575 - accuracy: 0.9273 - val_loss: 0.3734 - val_accuracy: 0.8880\n",
      "Epoch 7/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.2630 - accuracy: 0.9279 - val_loss: 0.3435 - val_accuracy: 0.8902\n",
      "Epoch 8/10\n",
      "744/744 [==============================] - 49s 65ms/step - loss: 0.2615 - accuracy: 0.9277 - val_loss: 0.4536 - val_accuracy: 0.8871\n",
      "Epoch 9/10\n",
      "744/744 [==============================] - 49s 66ms/step - loss: 0.2609 - accuracy: 0.9280 - val_loss: 0.3461 - val_accuracy: 0.8894\n",
      "Epoch 10/10\n",
      "744/744 [==============================] - 49s 65ms/step - loss: 0.2638 - accuracy: 0.9264 - val_loss: 0.3306 - val_accuracy: 0.8927\n",
      "Duration: 0:08:14.134518\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c55183",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "535ec0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "788/788 [==============================] - 54s 67ms/step - loss: 0.6610 - accuracy: 0.7794 - val_loss: 0.3961 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "788/788 [==============================] - 52s 66ms/step - loss: 0.3725 - accuracy: 0.8838 - val_loss: 0.3494 - val_accuracy: 0.8786\n",
      "Epoch 3/10\n",
      "788/788 [==============================] - 53s 67ms/step - loss: 0.3235 - accuracy: 0.9029 - val_loss: 0.3188 - val_accuracy: 0.8903\n",
      "Epoch 4/10\n",
      "788/788 [==============================] - 52s 66ms/step - loss: 0.3011 - accuracy: 0.9087 - val_loss: 0.3238 - val_accuracy: 0.8881\n",
      "Epoch 5/10\n",
      "788/788 [==============================] - 52s 66ms/step - loss: 0.2897 - accuracy: 0.9144 - val_loss: 0.3307 - val_accuracy: 0.8921\n",
      "Epoch 6/10\n",
      "788/788 [==============================] - 52s 66ms/step - loss: 0.2911 - accuracy: 0.9144 - val_loss: 0.3152 - val_accuracy: 0.8941\n",
      "Epoch 7/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.2914 - accuracy: 0.9166 - val_loss: 0.2998 - val_accuracy: 0.8984\n",
      "Epoch 8/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.2901 - accuracy: 0.9175 - val_loss: 0.3052 - val_accuracy: 0.8985\n",
      "Epoch 9/10\n",
      "788/788 [==============================] - 51s 64ms/step - loss: 0.2932 - accuracy: 0.9163 - val_loss: 0.3390 - val_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "788/788 [==============================] - 51s 65ms/step - loss: 0.2915 - accuracy: 0.9158 - val_loss: 0.3683 - val_accuracy: 0.8880\n",
      "Duration: 0:08:38.471565\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bea1905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.6946 - accuracy: 0.7583 - val_loss: 0.3816 - val_accuracy: 0.8627\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.4116 - accuracy: 0.8675 - val_loss: 0.3220 - val_accuracy: 0.8865\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.3594 - accuracy: 0.8846 - val_loss: 0.3169 - val_accuracy: 0.8853\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3397 - accuracy: 0.8941 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 57s 68ms/step - loss: 0.3282 - accuracy: 0.8965 - val_loss: 0.3592 - val_accuracy: 0.8946\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 56s 67ms/step - loss: 0.3289 - accuracy: 0.8982 - val_loss: 0.2951 - val_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 55s 66ms/step - loss: 0.3248 - accuracy: 0.9001 - val_loss: 0.3050 - val_accuracy: 0.8974\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 54s 64ms/step - loss: 0.3277 - accuracy: 0.8989 - val_loss: 0.3240 - val_accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 53s 64ms/step - loss: 0.3347 - accuracy: 0.8968 - val_loss: 0.3391 - val_accuracy: 0.8930\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 55s 67ms/step - loss: 0.3320 - accuracy: 0.8986 - val_loss: 0.3392 - val_accuracy: 0.8904\n",
      "Duration: 0:09:16.063907\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ab4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b220b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "875/875 [==============================] - 67s 75ms/step - loss: 0.7234 - accuracy: 0.7427 - val_loss: 0.3851 - val_accuracy: 0.8583\n",
      "Epoch 2/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.4522 - accuracy: 0.8494 - val_loss: 0.3280 - val_accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3998 - accuracy: 0.8690 - val_loss: 0.2930 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3790 - accuracy: 0.8758 - val_loss: 0.2863 - val_accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3715 - accuracy: 0.8795 - val_loss: 0.3073 - val_accuracy: 0.8971\n",
      "Epoch 6/10\n",
      "875/875 [==============================] - 63s 73ms/step - loss: 0.3695 - accuracy: 0.8819 - val_loss: 0.2908 - val_accuracy: 0.9011\n",
      "Epoch 7/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3665 - accuracy: 0.8827 - val_loss: 0.3077 - val_accuracy: 0.8909\n",
      "Epoch 8/10\n",
      "875/875 [==============================] - 63s 72ms/step - loss: 0.3652 - accuracy: 0.8820 - val_loss: 0.2951 - val_accuracy: 0.9025\n",
      "Epoch 9/10\n",
      "875/875 [==============================] - 63s 73ms/step - loss: 0.3642 - accuracy: 0.8844 - val_loss: 0.2853 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "875/875 [==============================] - 64s 73ms/step - loss: 0.3692 - accuracy: 0.8835 - val_loss: 0.3050 - val_accuracy: 0.8926\n",
      "Duration: 0:10:40.401604\n"
     ]
    }
   ],
   "source": [
    "print(n)#\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43bd398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C1/fashion_model_c1_may_nc_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "new_model_nc_dir  = \"D:/models/aug_22/\"+dataset+\"/C1/\"+dataset+\"_model_c1_may_nc_e1\"\n",
    "\n",
    "i=7\n",
    "\n",
    "for model in models_nc[i:]:\n",
    "    model.save(new_model_nc_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "models_nc = []\n",
    "\n",
    "if loading:\n",
    "    for i in range(20):\n",
    "        model_nc_dir = \"D:/models/aug_22/gtsrb/C1/gtsrb_model_c1_aug_nc_e1\"+str(i)\n",
    "        print(model_nc_dir)\n",
    "        model =utils.My_model(dataset,True,model_nc_dir)\n",
    "        model.model.compile(loss= 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        models_nc.append(model)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47e2faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del nc_values\n",
    "    del top_images_by_nc\n",
    "    del top_labels_by_nc\n",
    "    del image_sets_nc\n",
    "    del label_sets_nc\n",
    "    del models_nc\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98f93725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90765"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4813c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
