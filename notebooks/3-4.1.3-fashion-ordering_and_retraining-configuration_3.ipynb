{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f216e2a2",
   "metadata": {},
   "source": [
    "# Ordering by metrics and retraining phase\n",
    "\n",
    "## Dataset: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790af13b",
   "metadata": {},
   "source": [
    "## Experiment configuration 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90383afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user tensorflow==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1386e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0aa2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ == '2.5.0' # Version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93a3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\guided-retraining\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa923a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\guided-retraining\\utils\n"
     ]
    }
   ],
   "source": [
    "cd ../utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723735cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "keras\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# utils for project\n",
    "#import utils_guided_retraining2 as utils\n",
    "import utils_guided_retraining2 as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6a307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd '../notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1bd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fashion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c2b3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/fashion/x_train.npy\n",
      "x_set len:  48999\n",
      "D:/guided-retraining/data/fashion/y_train.npy\n",
      "y_set len:  48999\n",
      "D:/guided-retraining/data/fashion/x_val.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/fashion/y_val.npy\n",
      "y_set len:  14000\n",
      "D:/guided-retraining/data/fashion/x_test.npy\n",
      "x_set len:  7001\n",
      "D:/guided-retraining/data/fashion/y_test.npy\n",
      "y_set len:  7001\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = utils.get_data(dataset,\"Train\",verbose=True)\n",
    "x_val,y_val = utils.get_data(dataset,\"Val\",verbose=True)\n",
    "x_test,y_test = utils.get_data(dataset,\"Test\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f6f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary.npy\n",
      "x_set len:  55998\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/train_and_adversary_labels.npy\n",
      "y_set len:  55998\n"
     ]
    }
   ],
   "source": [
    "x_train_and_adversary,y_train_and_adversary = utils.get_data(dataset,\"Train_and_adversary\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53dcdf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_training = x_train_and_adversary[len(x_train):]\n",
    "print(len(x_adversary_training))\n",
    "y_adversary_training = y_train_and_adversary[len(y_train):]\n",
    "\n",
    "print(len(y_adversary_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fd2c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary.npy\n",
      "x_set len:  14000\n",
      "D:/guided-retraining/data/data_adversarial_july/fashion/test_and_adversary_labels.npy\n",
      "y_set len:  14000\n"
     ]
    }
   ],
   "source": [
    "# Obtaining adversarial examples for testing \n",
    "x_test_and_adversary,y_test_and_adversary = utils.get_adversarial_data(dataset,'Test_adversarial',True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c27698e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "x_adversary_test = x_test_and_adversary[len(x_test):]\n",
    "print(len(x_adversary_test))\n",
    "y_adversary_test = y_test_and_adversary[len(y_test):]\n",
    "\n",
    "print(len(y_adversary_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb4e3b",
   "metadata": {},
   "source": [
    "## ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1560941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model \n",
    "\n",
    "model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06/\"\n",
    "if(dataset == 'gtsrb'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/tf_model_25-06\"\n",
    "elif(dataset == 'intel'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/intel_model_21_10\"\n",
    "elif(dataset == 'mnist'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/models2\"\n",
    "elif(dataset == 'cifar'):\n",
    "    model_dir = \"C:/Users/fjdur/Documents/upc-july/models/model_02\"\n",
    "elif(dataset == 'fashion'):\n",
    "    model_dir = \"D:/guided-retraining/models/model_fashion_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5478616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "Model loaded correctly\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "model_original = utils.My_model(dataset,True, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81f5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "print(len(x_adversary_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea0bc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6999, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_adversary_training.shape)\n",
    "len(x_adversary_training)//20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983373d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_points = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7537e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edd1c7",
   "metadata": {},
   "source": [
    "## Loading LSA and DSA values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd62896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/lsa_values.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62da548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsa_direction = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/lsa_values.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbe684c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "lsa_values = np.load(lsa_direction)[len(x_train):] \n",
    "print(len(lsa_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e725932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ec186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtaining top n images by LSA values\n",
    "top_images_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),x_adversary_training)\n",
    "top_labels_by_lsa = utils.get_x_of_indexes(list(np.flip(np.argsort(lsa_values))),y_adversary_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f9ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "262a4841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_lsa = []\n",
    "label_sets_lsa = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_lsa)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_lsa)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_lsa)%m))\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m+(len(top_images_by_lsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_lsa_n = np.array(top_images_by_lsa[:n+m])\n",
    "        top_labels_by_lsa_n = np.array(top_labels_by_lsa[:n+m])\n",
    "    image_sets_lsa.append(top_images_by_lsa_n)\n",
    "    label_sets_lsa.append(top_labels_by_lsa_n)\n",
    "    print(len(top_images_by_lsa_n))\n",
    "    n += m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e3a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_lsa[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a68e",
   "metadata": {},
   "source": [
    "## Training guided by LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa4de5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_sets_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21782029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daef1b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_lsa = []\n",
    "for i in range(len(label_sets_lsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_lsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "282cec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 2s 8ms/step - loss: 0.2254 - accuracy: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2253975123167038, 0.9190115928649902]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[0].evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e1b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 3s 7ms/step - loss: 0.5032 - accuracy: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5032416582107544, 0.8342142701148987]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lsa[0].evaluate(x_test_and_adversary,y_test_and_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3665e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 3s 562ms/step - loss: 1.3568 - accuracy: 0.5500 - val_loss: 0.2490 - val_accuracy: 0.9096\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 3s 535ms/step - loss: 0.8383 - accuracy: 0.7147 - val_loss: 0.2768 - val_accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.5518 - accuracy: 0.8029 - val_loss: 0.2842 - val_accuracy: 0.9009\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 3s 522ms/step - loss: 0.5022 - accuracy: 0.8206 - val_loss: 0.2922 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 3s 602ms/step - loss: 0.4368 - accuracy: 0.8441 - val_loss: 0.2993 - val_accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 3s 610ms/step - loss: 0.3806 - accuracy: 0.8618 - val_loss: 0.3027 - val_accuracy: 0.8953\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 3s 661ms/step - loss: 0.3461 - accuracy: 0.8971 - val_loss: 0.3115 - val_accuracy: 0.8910\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 3s 633ms/step - loss: 0.3900 - accuracy: 0.8735 - val_loss: 0.3099 - val_accuracy: 0.8941\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 3s 628ms/step - loss: 0.3648 - accuracy: 0.8588 - val_loss: 0.3369 - val_accuracy: 0.8828\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 3s 660ms/step - loss: 0.2713 - accuracy: 0.8912 - val_loss: 0.3550 - val_accuracy: 0.8774\n",
      "Duration: 0:00:30.844022\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2f79099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 4s 379ms/step - loss: 1.1050 - accuracy: 0.6485 - val_loss: 0.2729 - val_accuracy: 0.8994\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 4s 351ms/step - loss: 0.7583 - accuracy: 0.7632 - val_loss: 0.2810 - val_accuracy: 0.8966\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 333ms/step - loss: 0.6103 - accuracy: 0.7912 - val_loss: 0.2882 - val_accuracy: 0.8925\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 4s 359ms/step - loss: 0.5423 - accuracy: 0.8250 - val_loss: 0.2996 - val_accuracy: 0.8874\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 340ms/step - loss: 0.4902 - accuracy: 0.8456 - val_loss: 0.2959 - val_accuracy: 0.8892\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 343ms/step - loss: 0.3965 - accuracy: 0.8544 - val_loss: 0.3132 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 335ms/step - loss: 0.3819 - accuracy: 0.8809 - val_loss: 0.3128 - val_accuracy: 0.8880\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 3s 336ms/step - loss: 0.3628 - accuracy: 0.8721 - val_loss: 0.3121 - val_accuracy: 0.8861\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 3s 328ms/step - loss: 0.3281 - accuracy: 0.8868 - val_loss: 0.3307 - val_accuracy: 0.8819\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 330ms/step - loss: 0.3350 - accuracy: 0.8912 - val_loss: 0.3253 - val_accuracy: 0.8860\n",
      "Duration: 0:00:35.592917\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val,epochs=10,batch_size = 64)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9f7fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 1.0377 - accuracy: 0.6833 - val_loss: 0.2835 - val_accuracy: 0.8946\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.7162 - accuracy: 0.7637 - val_loss: 0.2969 - val_accuracy: 0.8884\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.5703 - accuracy: 0.8098 - val_loss: 0.3001 - val_accuracy: 0.8838\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.5006 - accuracy: 0.8343 - val_loss: 0.3016 - val_accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 5s 318ms/step - loss: 0.4166 - accuracy: 0.8490 - val_loss: 0.3202 - val_accuracy: 0.8798\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 0.3835 - accuracy: 0.8725 - val_loss: 0.3215 - val_accuracy: 0.8791\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.3965 - accuracy: 0.8716 - val_loss: 0.3108 - val_accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.3199 - accuracy: 0.8824 - val_loss: 0.3191 - val_accuracy: 0.8839\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.3039 - accuracy: 0.8980 - val_loss: 0.3243 - val_accuracy: 0.8876\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.2948 - accuracy: 0.8951 - val_loss: 0.3379 - val_accuracy: 0.8817\n",
      "Duration: 0:00:40.704501\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4586fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 5s 190ms/step - loss: 0.7879 - accuracy: 0.7566 - val_loss: 0.3002 - val_accuracy: 0.8832\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.5575 - accuracy: 0.8007 - val_loss: 0.2971 - val_accuracy: 0.8853\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.4584 - accuracy: 0.8412 - val_loss: 0.3023 - val_accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.3922 - accuracy: 0.8699 - val_loss: 0.3186 - val_accuracy: 0.8789\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.4018 - accuracy: 0.8684 - val_loss: 0.3135 - val_accuracy: 0.8821\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 200ms/step - loss: 0.3331 - accuracy: 0.8897 - val_loss: 0.3125 - val_accuracy: 0.8864\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 197ms/step - loss: 0.3099 - accuracy: 0.9015 - val_loss: 0.3273 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 0.2862 - accuracy: 0.9044 - val_loss: 0.3206 - val_accuracy: 0.8859\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.2449 - accuracy: 0.9213 - val_loss: 0.3372 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.2419 - accuracy: 0.9265 - val_loss: 0.3247 - val_accuracy: 0.8863\n",
      "Duration: 0:00:40.719872\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "681edfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 5s 165ms/step - loss: 0.7198 - accuracy: 0.7724 - val_loss: 0.2885 - val_accuracy: 0.8893\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.4789 - accuracy: 0.8382 - val_loss: 0.3142 - val_accuracy: 0.8785\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.3856 - accuracy: 0.8729 - val_loss: 0.3169 - val_accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.3271 - accuracy: 0.8912 - val_loss: 0.3315 - val_accuracy: 0.8769\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.3232 - accuracy: 0.8882 - val_loss: 0.3002 - val_accuracy: 0.8860\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 161ms/step - loss: 0.2749 - accuracy: 0.9012 - val_loss: 0.3224 - val_accuracy: 0.8819\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 169ms/step - loss: 0.2601 - accuracy: 0.9088 - val_loss: 0.3298 - val_accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.2407 - accuracy: 0.9182 - val_loss: 0.3197 - val_accuracy: 0.8839\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.2071 - accuracy: 0.9282 - val_loss: 0.3268 - val_accuracy: 0.8852\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.1970 - accuracy: 0.9276 - val_loss: 0.3299 - val_accuracy: 0.8859\n",
      "Duration: 0:00:43.311559\n"
     ]
    }
   ],
   "source": [
    "print(n) #4\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68bcdd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.6409 - accuracy: 0.8010 - val_loss: 0.2910 - val_accuracy: 0.8931\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.4295 - accuracy: 0.8618 - val_loss: 0.2852 - val_accuracy: 0.8868\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 0.3784 - accuracy: 0.8725 - val_loss: 0.3095 - val_accuracy: 0.8826\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.3230 - accuracy: 0.8946 - val_loss: 0.3133 - val_accuracy: 0.8804\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.2876 - accuracy: 0.9034 - val_loss: 0.3058 - val_accuracy: 0.8845\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 4s 142ms/step - loss: 0.2712 - accuracy: 0.9103 - val_loss: 0.3026 - val_accuracy: 0.8854\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.2332 - accuracy: 0.9211 - val_loss: 0.3124 - val_accuracy: 0.8844\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 0.2308 - accuracy: 0.9186 - val_loss: 0.3145 - val_accuracy: 0.8836\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.2080 - accuracy: 0.9250 - val_loss: 0.3248 - val_accuracy: 0.8861\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.1757 - accuracy: 0.9382 - val_loss: 0.3275 - val_accuracy: 0.8879\n",
      "Duration: 0:00:45.964896\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39a60446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.6478 - accuracy: 0.7899 - val_loss: 0.3051 - val_accuracy: 0.8876\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.4705 - accuracy: 0.8378 - val_loss: 0.3016 - val_accuracy: 0.8872\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 0.3843 - accuracy: 0.8626 - val_loss: 0.3070 - val_accuracy: 0.8829\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 5s 130ms/step - loss: 0.3271 - accuracy: 0.8870 - val_loss: 0.3149 - val_accuracy: 0.8811\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 5s 129ms/step - loss: 0.3037 - accuracy: 0.8945 - val_loss: 0.3039 - val_accuracy: 0.8843\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.2931 - accuracy: 0.8983 - val_loss: 0.3299 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 5s 127ms/step - loss: 0.2652 - accuracy: 0.9113 - val_loss: 0.3156 - val_accuracy: 0.8824\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 0.2200 - accuracy: 0.9172 - val_loss: 0.3382 - val_accuracy: 0.8826\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.2247 - accuracy: 0.9151 - val_loss: 0.3325 - val_accuracy: 0.8839\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 0.1941 - accuracy: 0.9353 - val_loss: 0.3567 - val_accuracy: 0.8812\n",
      "Duration: 0:00:48.885388\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6ca03ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 6s 122ms/step - loss: 0.6263 - accuracy: 0.7941 - val_loss: 0.3136 - val_accuracy: 0.8839\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.4579 - accuracy: 0.8445 - val_loss: 0.3053 - val_accuracy: 0.8849\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.3928 - accuracy: 0.8647 - val_loss: 0.3029 - val_accuracy: 0.8862\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.3598 - accuracy: 0.8676 - val_loss: 0.3383 - val_accuracy: 0.8771\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 5s 128ms/step - loss: 0.3273 - accuracy: 0.8938 - val_loss: 0.3352 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.3098 - accuracy: 0.8938 - val_loss: 0.3213 - val_accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.2886 - accuracy: 0.9004 - val_loss: 0.3184 - val_accuracy: 0.8833\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.2652 - accuracy: 0.9088 - val_loss: 0.3327 - val_accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.2377 - accuracy: 0.9162 - val_loss: 0.3421 - val_accuracy: 0.8835\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 6s 131ms/step - loss: 0.2343 - accuracy: 0.9151 - val_loss: 0.3333 - val_accuracy: 0.8834\n",
      "Duration: 0:00:53.694028\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26c6cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6205 - accuracy: 0.8072 - val_loss: 0.2840 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 0.4417 - accuracy: 0.8493 - val_loss: 0.2920 - val_accuracy: 0.8914\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 0.3722 - accuracy: 0.8699 - val_loss: 0.3085 - val_accuracy: 0.8854\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 5s 115ms/step - loss: 0.3441 - accuracy: 0.8830 - val_loss: 0.3098 - val_accuracy: 0.8845\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 6s 120ms/step - loss: 0.3085 - accuracy: 0.8980 - val_loss: 0.3133 - val_accuracy: 0.8877\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 6s 121ms/step - loss: 0.2971 - accuracy: 0.9029 - val_loss: 0.3121 - val_accuracy: 0.8882\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 0.2683 - accuracy: 0.9075 - val_loss: 0.3020 - val_accuracy: 0.8904\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 0.2564 - accuracy: 0.9092 - val_loss: 0.3159 - val_accuracy: 0.8886\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 5s 115ms/step - loss: 0.2529 - accuracy: 0.9163 - val_loss: 0.3198 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 6s 122ms/step - loss: 0.2130 - accuracy: 0.9314 - val_loss: 0.3210 - val_accuracy: 0.8909\n",
      "Duration: 0:00:55.962090\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a6dfa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 7s 112ms/step - loss: 0.5558 - accuracy: 0.8212 - val_loss: 0.3150 - val_accuracy: 0.8873\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 0.4243 - accuracy: 0.8624 - val_loss: 0.3100 - val_accuracy: 0.8834\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 6s 111ms/step - loss: 0.3667 - accuracy: 0.8785 - val_loss: 0.3160 - val_accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 6s 111ms/step - loss: 0.3292 - accuracy: 0.8915 - val_loss: 0.3140 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 6s 109ms/step - loss: 0.3069 - accuracy: 0.8944 - val_loss: 0.3177 - val_accuracy: 0.8826\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 0.3009 - accuracy: 0.9012 - val_loss: 0.3156 - val_accuracy: 0.8851\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 6s 109ms/step - loss: 0.2663 - accuracy: 0.9088 - val_loss: 0.3235 - val_accuracy: 0.8873\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.2384 - accuracy: 0.9165 - val_loss: 0.3255 - val_accuracy: 0.8903\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.2328 - accuracy: 0.9156 - val_loss: 0.3556 - val_accuracy: 0.8820\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 7s 138ms/step - loss: 0.2224 - accuracy: 0.9324 - val_loss: 0.3509 - val_accuracy: 0.8850\n",
      "Duration: 0:01:03.565261\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2974fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 8s 118ms/step - loss: 0.5217 - accuracy: 0.8286 - val_loss: 0.2860 - val_accuracy: 0.8892\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 0.3851 - accuracy: 0.8733 - val_loss: 0.3119 - val_accuracy: 0.8812\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 6s 111ms/step - loss: 0.3572 - accuracy: 0.8845 - val_loss: 0.3141 - val_accuracy: 0.8836\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 7s 115ms/step - loss: 0.3201 - accuracy: 0.8944 - val_loss: 0.3048 - val_accuracy: 0.8880\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.2970 - accuracy: 0.8995 - val_loss: 0.3044 - val_accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.2702 - accuracy: 0.9083 - val_loss: 0.3234 - val_accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.2670 - accuracy: 0.9155 - val_loss: 0.3237 - val_accuracy: 0.8866\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.2490 - accuracy: 0.9176 - val_loss: 0.3127 - val_accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.2269 - accuracy: 0.9273 - val_loss: 0.3264 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.2211 - accuracy: 0.9286 - val_loss: 0.3228 - val_accuracy: 0.8889\n",
      "Duration: 0:01:04.614558\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84013f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 0.5183 - accuracy: 0.8284 - val_loss: 0.3070 - val_accuracy: 0.8845\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.4002 - accuracy: 0.8635 - val_loss: 0.3152 - val_accuracy: 0.8849\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 0.3433 - accuracy: 0.8853 - val_loss: 0.3217 - val_accuracy: 0.8841\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 0.3069 - accuracy: 0.8931 - val_loss: 0.3289 - val_accuracy: 0.8851\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.2891 - accuracy: 0.9054 - val_loss: 0.3220 - val_accuracy: 0.8805\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.2556 - accuracy: 0.9135 - val_loss: 0.3196 - val_accuracy: 0.8849\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 7s 107ms/step - loss: 0.2465 - accuracy: 0.9191 - val_loss: 0.3162 - val_accuracy: 0.8887\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 0.2445 - accuracy: 0.9233 - val_loss: 0.3602 - val_accuracy: 0.8846\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 0.2085 - accuracy: 0.9304 - val_loss: 0.3345 - val_accuracy: 0.8822\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 0.2055 - accuracy: 0.9294 - val_loss: 0.3467 - val_accuracy: 0.8816\n",
      "Duration: 0:01:08.976256\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55e7d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 8s 104ms/step - loss: 0.5448 - accuracy: 0.8115 - val_loss: 0.3151 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.4237 - accuracy: 0.8532 - val_loss: 0.3145 - val_accuracy: 0.8797\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.3642 - accuracy: 0.8695 - val_loss: 0.3109 - val_accuracy: 0.8853\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.3322 - accuracy: 0.8824 - val_loss: 0.3425 - val_accuracy: 0.8799\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.3168 - accuracy: 0.8966 - val_loss: 0.3361 - val_accuracy: 0.8794\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.3018 - accuracy: 0.8962 - val_loss: 0.3191 - val_accuracy: 0.8857\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.2567 - accuracy: 0.9149 - val_loss: 0.3444 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 8s 117ms/step - loss: 0.2591 - accuracy: 0.9109 - val_loss: 0.3426 - val_accuracy: 0.8841\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.2343 - accuracy: 0.9186 - val_loss: 0.3284 - val_accuracy: 0.8893\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 7s 102ms/step - loss: 0.2164 - accuracy: 0.9242 - val_loss: 0.3291 - val_accuracy: 0.8876\n",
      "Duration: 0:01:14.100945\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bb45aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 8s 98ms/step - loss: 0.5426 - accuracy: 0.8174 - val_loss: 0.3080 - val_accuracy: 0.8793\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 7s 100ms/step - loss: 0.4409 - accuracy: 0.8477 - val_loss: 0.3038 - val_accuracy: 0.8850\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 7s 98ms/step - loss: 0.3918 - accuracy: 0.8626 - val_loss: 0.3163 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 7s 99ms/step - loss: 0.3497 - accuracy: 0.8775 - val_loss: 0.2993 - val_accuracy: 0.8892\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 7s 99ms/step - loss: 0.3187 - accuracy: 0.8937 - val_loss: 0.3194 - val_accuracy: 0.8870\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 7s 99ms/step - loss: 0.3018 - accuracy: 0.8956 - val_loss: 0.3149 - val_accuracy: 0.8852\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 7s 100ms/step - loss: 0.2837 - accuracy: 0.9034 - val_loss: 0.3255 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 8s 101ms/step - loss: 0.2560 - accuracy: 0.9120 - val_loss: 0.3310 - val_accuracy: 0.8869\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 7s 99ms/step - loss: 0.2452 - accuracy: 0.9166 - val_loss: 0.3420 - val_accuracy: 0.8810\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 8s 103ms/step - loss: 0.2293 - accuracy: 0.9187 - val_loss: 0.3212 - val_accuracy: 0.8896\n",
      "Duration: 0:01:14.968964\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffbe2e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 9s 100ms/step - loss: 0.5823 - accuracy: 0.7971 - val_loss: 0.2843 - val_accuracy: 0.8888\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.4532 - accuracy: 0.8394 - val_loss: 0.3072 - val_accuracy: 0.8814\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 0.4007 - accuracy: 0.8549 - val_loss: 0.2902 - val_accuracy: 0.8898\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.3693 - accuracy: 0.8741 - val_loss: 0.2932 - val_accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3453 - accuracy: 0.8839 - val_loss: 0.3077 - val_accuracy: 0.8904\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3113 - accuracy: 0.8927 - val_loss: 0.3017 - val_accuracy: 0.8895\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2963 - accuracy: 0.8990 - val_loss: 0.3053 - val_accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.2653 - accuracy: 0.9090 - val_loss: 0.3203 - val_accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.2535 - accuracy: 0.9151 - val_loss: 0.3252 - val_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.2541 - accuracy: 0.9225 - val_loss: 0.3105 - val_accuracy: 0.8947\n",
      "Duration: 0:01:20.691135\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebdd2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 9s 103ms/step - loss: 0.5885 - accuracy: 0.7923 - val_loss: 0.2863 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 8s 101ms/step - loss: 0.4672 - accuracy: 0.8313 - val_loss: 0.2861 - val_accuracy: 0.8901\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.4175 - accuracy: 0.8540 - val_loss: 0.2804 - val_accuracy: 0.8941\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 9s 102ms/step - loss: 0.3968 - accuracy: 0.8614 - val_loss: 0.2907 - val_accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 8s 100ms/step - loss: 0.3489 - accuracy: 0.8790 - val_loss: 0.2862 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 8s 99ms/step - loss: 0.3407 - accuracy: 0.8877 - val_loss: 0.2878 - val_accuracy: 0.8950\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 8s 100ms/step - loss: 0.3025 - accuracy: 0.9000 - val_loss: 0.2970 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 8s 99ms/step - loss: 0.2754 - accuracy: 0.9020 - val_loss: 0.2947 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.2644 - accuracy: 0.9107 - val_loss: 0.3141 - val_accuracy: 0.8913\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 9s 104ms/step - loss: 0.2380 - accuracy: 0.9233 - val_loss: 0.3495 - val_accuracy: 0.8852\n",
      "Duration: 0:01:26.608339\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a22ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 10s 98ms/step - loss: 0.5945 - accuracy: 0.7888 - val_loss: 0.2802 - val_accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.4944 - accuracy: 0.8244 - val_loss: 0.2846 - val_accuracy: 0.8949\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 9s 99ms/step - loss: 0.4339 - accuracy: 0.8439 - val_loss: 0.2768 - val_accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.4095 - accuracy: 0.8583 - val_loss: 0.2842 - val_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.3757 - accuracy: 0.8682 - val_loss: 0.2885 - val_accuracy: 0.8978\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.3640 - accuracy: 0.8772 - val_loss: 0.2869 - val_accuracy: 0.9004\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.3108 - accuracy: 0.8865 - val_loss: 0.2923 - val_accuracy: 0.8960\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.3121 - accuracy: 0.8948 - val_loss: 0.3017 - val_accuracy: 0.8978\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.2946 - accuracy: 0.9007 - val_loss: 0.3051 - val_accuracy: 0.8985\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.2606 - accuracy: 0.9102 - val_loss: 0.3047 - val_accuracy: 0.9009\n",
      "Duration: 0:01:28.692542\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08a857e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 10s 96ms/step - loss: 0.6138 - accuracy: 0.7827 - val_loss: 0.2790 - val_accuracy: 0.8903\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.4867 - accuracy: 0.8206 - val_loss: 0.2942 - val_accuracy: 0.8913\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 9s 98ms/step - loss: 0.4428 - accuracy: 0.8355 - val_loss: 0.2845 - val_accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 9s 96ms/step - loss: 0.4105 - accuracy: 0.8500 - val_loss: 0.2914 - val_accuracy: 0.8949\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.3685 - accuracy: 0.8673 - val_loss: 0.2807 - val_accuracy: 0.8984\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.3485 - accuracy: 0.8776 - val_loss: 0.3041 - val_accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 0.3315 - accuracy: 0.8859 - val_loss: 0.2932 - val_accuracy: 0.8999\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 9s 96ms/step - loss: 0.3119 - accuracy: 0.8949 - val_loss: 0.2911 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.2868 - accuracy: 0.8995 - val_loss: 0.2936 - val_accuracy: 0.8979\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.2741 - accuracy: 0.9025 - val_loss: 0.2979 - val_accuracy: 0.8919\n",
      "Duration: 0:01:31.820413\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6957df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 10s 94ms/step - loss: 0.5947 - accuracy: 0.7839 - val_loss: 0.2784 - val_accuracy: 0.8934\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.4790 - accuracy: 0.8238 - val_loss: 0.2723 - val_accuracy: 0.8964\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.4376 - accuracy: 0.8423 - val_loss: 0.2725 - val_accuracy: 0.8977\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.4230 - accuracy: 0.8560 - val_loss: 0.2795 - val_accuracy: 0.8971\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.3811 - accuracy: 0.8633 - val_loss: 0.2828 - val_accuracy: 0.8990\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.3430 - accuracy: 0.8802 - val_loss: 0.2986 - val_accuracy: 0.8955\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.3111 - accuracy: 0.8916 - val_loss: 0.2886 - val_accuracy: 0.8977\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.3074 - accuracy: 0.8967 - val_loss: 0.3072 - val_accuracy: 0.8993\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.2750 - accuracy: 0.9031 - val_loss: 0.2892 - val_accuracy: 0.8990\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.2678 - accuracy: 0.9063 - val_loss: 0.3051 - val_accuracy: 0.9029\n",
      "Duration: 0:01:34.810875\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1080b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 11s 92ms/step - loss: 0.5514 - accuracy: 0.8060 - val_loss: 0.2649 - val_accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.4708 - accuracy: 0.8361 - val_loss: 0.2735 - val_accuracy: 0.8984\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.4158 - accuracy: 0.8491 - val_loss: 0.2875 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.3923 - accuracy: 0.8638 - val_loss: 0.2955 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.3612 - accuracy: 0.8740 - val_loss: 0.2898 - val_accuracy: 0.8989\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.3218 - accuracy: 0.8873 - val_loss: 0.3031 - val_accuracy: 0.8946\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.3064 - accuracy: 0.8946 - val_loss: 0.3083 - val_accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.2811 - accuracy: 0.8991 - val_loss: 0.3012 - val_accuracy: 0.9012\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.2750 - accuracy: 0.9067 - val_loss: 0.2830 - val_accuracy: 0.9056\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2649 - accuracy: 0.9130 - val_loss: 0.3023 - val_accuracy: 0.9019\n",
      "Duration: 0:01:48.628131\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_lsa[n].fit_model(image_sets_lsa[n],label_sets_lsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cf4ae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_lsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_lsa_dir  = \"D:/models/gtsrb_models/C3/gtsrb_model_c3_sep_lsa_e1\"\n",
    "new_model_lsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_may_lsa_e1\"\n",
    "#new_model_lsa_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_lsa_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_lsa:\n",
    "    model.save(new_model_lsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52746ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7733ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del lsa_values\n",
    "    del top_images_by_lsa\n",
    "    del top_labels_by_lsa\n",
    "    del image_sets_lsa\n",
    "    del label_sets_lsa\n",
    "    del models_lsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "402aa433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316972"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ef06e",
   "metadata": {},
   "source": [
    "## Training guided by DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14fc6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa_direction = \"D:/guided-retraining/data/\"+dataset+\"/dsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9781aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsa_direction = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/dsa_values.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "585cd8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "dsa_values = np.load(dsa_direction)[len(x_train):] \n",
    "print(len(dsa_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5944946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_images_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),x_adversary_training)\n",
    "top_labels_by_dsa = utils.get_x_of_indexes(list(np.flip(np.argsort(dsa_values))),y_adversary_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "099c7fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dsa = []\n",
    "label_sets_dsa = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_dsa)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dsa)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dsa)%m))\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m+(len(top_images_by_dsa)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dsa_n = np.array(top_images_by_dsa[:n+m])\n",
    "        top_labels_by_dsa_n = np.array(top_labels_by_dsa[:n+m])\n",
    "    image_sets_dsa.append(top_images_by_dsa_n)\n",
    "    label_sets_dsa.append(top_labels_by_dsa_n)\n",
    "    print(len(top_images_by_dsa_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8713d09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_dsa = []\n",
    "for i in range(len(label_sets_dsa)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_dsa.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9990e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.3093 - accuracy: 0.5029 - val_loss: 0.2801 - val_accuracy: 0.9015\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.9539 - accuracy: 0.6324 - val_loss: 0.3072 - val_accuracy: 0.8899\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7443 - accuracy: 0.7206 - val_loss: 0.3112 - val_accuracy: 0.8891\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7412 - accuracy: 0.7118 - val_loss: 0.3108 - val_accuracy: 0.8878\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.6309 - accuracy: 0.7412 - val_loss: 0.3177 - val_accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.5479 - accuracy: 0.8118 - val_loss: 0.3234 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.4976 - accuracy: 0.8265 - val_loss: 0.3269 - val_accuracy: 0.8856\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.5065 - accuracy: 0.8265 - val_loss: 0.3313 - val_accuracy: 0.8857\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.4425 - accuracy: 0.8176 - val_loss: 0.3443 - val_accuracy: 0.8861\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.4385 - accuracy: 0.8235 - val_loss: 0.3514 - val_accuracy: 0.8834\n",
      "Duration: 0:00:54.805289\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c24fa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 8s 616ms/step - loss: 1.2424 - accuracy: 0.5500 - val_loss: 0.2998 - val_accuracy: 0.8935\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 6s 568ms/step - loss: 0.8973 - accuracy: 0.6765 - val_loss: 0.3239 - val_accuracy: 0.8865\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 6s 551ms/step - loss: 0.6935 - accuracy: 0.7250 - val_loss: 0.3293 - val_accuracy: 0.8838\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 6s 571ms/step - loss: 0.6518 - accuracy: 0.7529 - val_loss: 0.3234 - val_accuracy: 0.8860\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 6s 561ms/step - loss: 0.5975 - accuracy: 0.7544 - val_loss: 0.3254 - val_accuracy: 0.8841\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 6s 549ms/step - loss: 0.5465 - accuracy: 0.8015 - val_loss: 0.3261 - val_accuracy: 0.8844\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 6s 579ms/step - loss: 0.4843 - accuracy: 0.8191 - val_loss: 0.3158 - val_accuracy: 0.8886\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 6s 557ms/step - loss: 0.5000 - accuracy: 0.8132 - val_loss: 0.3220 - val_accuracy: 0.8919\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 6s 562ms/step - loss: 0.4610 - accuracy: 0.8265 - val_loss: 0.3256 - val_accuracy: 0.8899\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 6s 562ms/step - loss: 0.4068 - accuracy: 0.8456 - val_loss: 0.3439 - val_accuracy: 0.8881\n",
      "Duration: 0:00:59.473204\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "print(n)\n",
    "\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfb68060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 420ms/step - loss: 1.1775 - accuracy: 0.5755 - val_loss: 0.2992 - val_accuracy: 0.8916\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 6s 405ms/step - loss: 0.8336 - accuracy: 0.6882 - val_loss: 0.3089 - val_accuracy: 0.8868\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 6s 393ms/step - loss: 0.6873 - accuracy: 0.7333 - val_loss: 0.3195 - val_accuracy: 0.8807\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 6s 403ms/step - loss: 0.6190 - accuracy: 0.7667 - val_loss: 0.3149 - val_accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 6s 409ms/step - loss: 0.5453 - accuracy: 0.7804 - val_loss: 0.3230 - val_accuracy: 0.8854\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 6s 411ms/step - loss: 0.5110 - accuracy: 0.8098 - val_loss: 0.3160 - val_accuracy: 0.8884\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 6s 404ms/step - loss: 0.4922 - accuracy: 0.8265 - val_loss: 0.3317 - val_accuracy: 0.8849\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 6s 404ms/step - loss: 0.4698 - accuracy: 0.8206 - val_loss: 0.3219 - val_accuracy: 0.8884\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 6s 402ms/step - loss: 0.4084 - accuracy: 0.8471 - val_loss: 0.3338 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 6s 395ms/step - loss: 0.3760 - accuracy: 0.8500 - val_loss: 0.3632 - val_accuracy: 0.8883\n",
      "Duration: 0:01:02.954693\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c5d20d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 8s 322ms/step - loss: 1.1221 - accuracy: 0.5875 - val_loss: 0.2999 - val_accuracy: 0.8862\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 7s 308ms/step - loss: 0.7995 - accuracy: 0.7103 - val_loss: 0.3142 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 6s 304ms/step - loss: 0.7477 - accuracy: 0.7140 - val_loss: 0.3269 - val_accuracy: 0.8759\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 7s 308ms/step - loss: 0.6392 - accuracy: 0.7551 - val_loss: 0.3178 - val_accuracy: 0.8842\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 6s 306ms/step - loss: 0.5877 - accuracy: 0.7853 - val_loss: 0.3228 - val_accuracy: 0.8822\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 7s 315ms/step - loss: 0.5485 - accuracy: 0.7890 - val_loss: 0.3338 - val_accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 7s 310ms/step - loss: 0.4977 - accuracy: 0.8103 - val_loss: 0.3201 - val_accuracy: 0.8871\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 7s 309ms/step - loss: 0.4633 - accuracy: 0.8294 - val_loss: 0.3320 - val_accuracy: 0.8873\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 7s 310ms/step - loss: 0.4404 - accuracy: 0.8346 - val_loss: 0.3239 - val_accuracy: 0.8881\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 6s 303ms/step - loss: 0.4122 - accuracy: 0.8419 - val_loss: 0.3440 - val_accuracy: 0.8915\n",
      "Duration: 0:01:07.299915\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccb7a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 8s 276ms/step - loss: 1.1026 - accuracy: 0.5788 - val_loss: 0.3070 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 0.8143 - accuracy: 0.6818 - val_loss: 0.3130 - val_accuracy: 0.8821\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 0.7182 - accuracy: 0.7247 - val_loss: 0.3228 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 0.6493 - accuracy: 0.7518 - val_loss: 0.3197 - val_accuracy: 0.8814\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 0.6204 - accuracy: 0.7594 - val_loss: 0.3142 - val_accuracy: 0.8851\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 7s 259ms/step - loss: 0.6087 - accuracy: 0.7788 - val_loss: 0.3059 - val_accuracy: 0.8868\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 7s 263ms/step - loss: 0.5395 - accuracy: 0.7912 - val_loss: 0.3239 - val_accuracy: 0.8837\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 7s 259ms/step - loss: 0.5117 - accuracy: 0.8106 - val_loss: 0.3356 - val_accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 7s 252ms/step - loss: 0.4820 - accuracy: 0.8141 - val_loss: 0.3309 - val_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 0.4698 - accuracy: 0.8276 - val_loss: 0.3303 - val_accuracy: 0.8849\n",
      "Duration: 0:01:10.383666\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0e3117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 9s 242ms/step - loss: 1.0801 - accuracy: 0.5897 - val_loss: 0.2996 - val_accuracy: 0.8863\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 0.7905 - accuracy: 0.6985 - val_loss: 0.3048 - val_accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.7129 - accuracy: 0.7230 - val_loss: 0.3088 - val_accuracy: 0.8787\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 239ms/step - loss: 0.6374 - accuracy: 0.7569 - val_loss: 0.3070 - val_accuracy: 0.8811\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.5993 - accuracy: 0.7691 - val_loss: 0.3123 - val_accuracy: 0.8839\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 7s 239ms/step - loss: 0.5681 - accuracy: 0.7887 - val_loss: 0.2974 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 7s 237ms/step - loss: 0.5523 - accuracy: 0.7985 - val_loss: 0.3051 - val_accuracy: 0.8878\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 8s 254ms/step - loss: 0.5151 - accuracy: 0.8015 - val_loss: 0.3164 - val_accuracy: 0.8869\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 0.4897 - accuracy: 0.8142 - val_loss: 0.3169 - val_accuracy: 0.8856\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 238ms/step - loss: 0.4527 - accuracy: 0.8353 - val_loss: 0.3234 - val_accuracy: 0.8867\n",
      "Duration: 0:01:17.123473\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73dbf589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 9s 218ms/step - loss: 1.0777 - accuracy: 0.6034 - val_loss: 0.3024 - val_accuracy: 0.8792\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 8s 217ms/step - loss: 0.8490 - accuracy: 0.6845 - val_loss: 0.2870 - val_accuracy: 0.8884\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 8s 220ms/step - loss: 0.7296 - accuracy: 0.7071 - val_loss: 0.3111 - val_accuracy: 0.8799\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 8s 219ms/step - loss: 0.6721 - accuracy: 0.7479 - val_loss: 0.2971 - val_accuracy: 0.8845\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 0.6159 - accuracy: 0.7592 - val_loss: 0.3056 - val_accuracy: 0.8872\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 8s 204ms/step - loss: 0.5902 - accuracy: 0.7735 - val_loss: 0.2973 - val_accuracy: 0.8934\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.5200 - accuracy: 0.8042 - val_loss: 0.3077 - val_accuracy: 0.8864\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 8s 211ms/step - loss: 0.5032 - accuracy: 0.8143 - val_loss: 0.3111 - val_accuracy: 0.8879\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.4731 - accuracy: 0.8239 - val_loss: 0.3312 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 8s 212ms/step - loss: 0.4563 - accuracy: 0.8265 - val_loss: 0.3150 - val_accuracy: 0.8914\n",
      "Duration: 0:01:20.969868\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "096fa5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 10s 208ms/step - loss: 1.0572 - accuracy: 0.6154 - val_loss: 0.3098 - val_accuracy: 0.8789\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 8s 195ms/step - loss: 0.7920 - accuracy: 0.7007 - val_loss: 0.3039 - val_accuracy: 0.8779\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 8s 195ms/step - loss: 0.6817 - accuracy: 0.7357 - val_loss: 0.2976 - val_accuracy: 0.8831\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 9s 201ms/step - loss: 0.6440 - accuracy: 0.7518 - val_loss: 0.2981 - val_accuracy: 0.8851\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 8s 194ms/step - loss: 0.5928 - accuracy: 0.7846 - val_loss: 0.3061 - val_accuracy: 0.8846\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 8s 195ms/step - loss: 0.5452 - accuracy: 0.8022 - val_loss: 0.3049 - val_accuracy: 0.8871\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 8s 194ms/step - loss: 0.5292 - accuracy: 0.8059 - val_loss: 0.3034 - val_accuracy: 0.8854\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 8s 196ms/step - loss: 0.4772 - accuracy: 0.8276 - val_loss: 0.3080 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 8s 194ms/step - loss: 0.4862 - accuracy: 0.8228 - val_loss: 0.2964 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 8s 195ms/step - loss: 0.4174 - accuracy: 0.8518 - val_loss: 0.3087 - val_accuracy: 0.8931\n",
      "Duration: 0:01:24.856924\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bb81a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 10s 190ms/step - loss: 0.9782 - accuracy: 0.6366 - val_loss: 0.3037 - val_accuracy: 0.8840\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 9s 184ms/step - loss: 0.7565 - accuracy: 0.7098 - val_loss: 0.3086 - val_accuracy: 0.8769\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 9s 187ms/step - loss: 0.6797 - accuracy: 0.7373 - val_loss: 0.3056 - val_accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.6177 - accuracy: 0.7657 - val_loss: 0.2985 - val_accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 9s 193ms/step - loss: 0.5724 - accuracy: 0.7886 - val_loss: 0.2974 - val_accuracy: 0.8887\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 9s 185ms/step - loss: 0.5312 - accuracy: 0.8065 - val_loss: 0.2996 - val_accuracy: 0.8880\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 9s 186ms/step - loss: 0.4775 - accuracy: 0.8173 - val_loss: 0.2976 - val_accuracy: 0.8927\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 8s 178ms/step - loss: 0.4836 - accuracy: 0.8229 - val_loss: 0.2917 - val_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 9s 183ms/step - loss: 0.4284 - accuracy: 0.8418 - val_loss: 0.3027 - val_accuracy: 0.8929\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 9s 186ms/step - loss: 0.3823 - accuracy: 0.8582 - val_loss: 0.3062 - val_accuracy: 0.8944\n",
      "Duration: 0:01:29.373333\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3043bc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 11s 176ms/step - loss: 0.8958 - accuracy: 0.6603 - val_loss: 0.3025 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 9s 170ms/step - loss: 0.7376 - accuracy: 0.7250 - val_loss: 0.3182 - val_accuracy: 0.8801\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 9s 172ms/step - loss: 0.6310 - accuracy: 0.7559 - val_loss: 0.3124 - val_accuracy: 0.8832\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 9s 171ms/step - loss: 0.5928 - accuracy: 0.7788 - val_loss: 0.2991 - val_accuracy: 0.8841\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 9s 170ms/step - loss: 0.5537 - accuracy: 0.8003 - val_loss: 0.3121 - val_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 9s 170ms/step - loss: 0.5173 - accuracy: 0.8097 - val_loss: 0.2986 - val_accuracy: 0.8894\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 9s 170ms/step - loss: 0.4774 - accuracy: 0.8309 - val_loss: 0.3053 - val_accuracy: 0.8864\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 9s 164ms/step - loss: 0.4267 - accuracy: 0.8488 - val_loss: 0.2974 - val_accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 9s 177ms/step - loss: 0.3917 - accuracy: 0.8615 - val_loss: 0.3255 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 9s 177ms/step - loss: 0.3849 - accuracy: 0.8606 - val_loss: 0.3061 - val_accuracy: 0.8904\n",
      "Duration: 0:01:33.266756\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38509dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 12s 172ms/step - loss: 0.8447 - accuracy: 0.6909 - val_loss: 0.2939 - val_accuracy: 0.8823\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 10s 163ms/step - loss: 0.6331 - accuracy: 0.7618 - val_loss: 0.3071 - val_accuracy: 0.8794\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.5721 - accuracy: 0.7933 - val_loss: 0.2984 - val_accuracy: 0.8844\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 10s 164ms/step - loss: 0.5419 - accuracy: 0.8043 - val_loss: 0.2931 - val_accuracy: 0.8909\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.4832 - accuracy: 0.8222 - val_loss: 0.2983 - val_accuracy: 0.8903\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.4433 - accuracy: 0.8396 - val_loss: 0.3116 - val_accuracy: 0.8867\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 10s 164ms/step - loss: 0.4214 - accuracy: 0.8457 - val_loss: 0.3123 - val_accuracy: 0.8879\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.3910 - accuracy: 0.8626 - val_loss: 0.3128 - val_accuracy: 0.8895\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 10s 166ms/step - loss: 0.3440 - accuracy: 0.8810 - val_loss: 0.3032 - val_accuracy: 0.8938\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 10s 172ms/step - loss: 0.3131 - accuracy: 0.8909 - val_loss: 0.3263 - val_accuracy: 0.8931\n",
      "Duration: 0:01:38.645953\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e5bd2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 11s 160ms/step - loss: 0.7888 - accuracy: 0.7100 - val_loss: 0.2953 - val_accuracy: 0.8865\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 10s 157ms/step - loss: 0.6106 - accuracy: 0.7779 - val_loss: 0.3030 - val_accuracy: 0.8848\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 10s 158ms/step - loss: 0.5326 - accuracy: 0.8017 - val_loss: 0.2855 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.5006 - accuracy: 0.8167 - val_loss: 0.2930 - val_accuracy: 0.8875\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 10s 160ms/step - loss: 0.4498 - accuracy: 0.8333 - val_loss: 0.2923 - val_accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 10s 157ms/step - loss: 0.4160 - accuracy: 0.8517 - val_loss: 0.3031 - val_accuracy: 0.8859\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 10s 158ms/step - loss: 0.4067 - accuracy: 0.8544 - val_loss: 0.2883 - val_accuracy: 0.8958\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 10s 158ms/step - loss: 0.3738 - accuracy: 0.8686 - val_loss: 0.3117 - val_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 158ms/step - loss: 0.3207 - accuracy: 0.8887 - val_loss: 0.3009 - val_accuracy: 0.8953\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 10s 154ms/step - loss: 0.2923 - accuracy: 0.8988 - val_loss: 0.3035 - val_accuracy: 0.8936\n",
      "Duration: 0:01:41.969992\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8030a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 13s 159ms/step - loss: 0.7578 - accuracy: 0.7231 - val_loss: 0.2942 - val_accuracy: 0.8859\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 10s 140ms/step - loss: 0.5746 - accuracy: 0.7835 - val_loss: 0.3000 - val_accuracy: 0.8864\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 10s 149ms/step - loss: 0.5038 - accuracy: 0.8090 - val_loss: 0.2943 - val_accuracy: 0.8891\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.4872 - accuracy: 0.8210 - val_loss: 0.3074 - val_accuracy: 0.8819\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 11s 158ms/step - loss: 0.4455 - accuracy: 0.8391 - val_loss: 0.2968 - val_accuracy: 0.8867\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.4154 - accuracy: 0.8534 - val_loss: 0.3138 - val_accuracy: 0.8863\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 10s 149ms/step - loss: 0.3817 - accuracy: 0.8627 - val_loss: 0.2997 - val_accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.3501 - accuracy: 0.8776 - val_loss: 0.3309 - val_accuracy: 0.8879\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 11s 154ms/step - loss: 0.3359 - accuracy: 0.8783 - val_loss: 0.3207 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.3037 - accuracy: 0.8955 - val_loss: 0.3069 - val_accuracy: 0.8942\n",
      "Duration: 0:01:47.633657\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fb5a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 13s 152ms/step - loss: 0.7226 - accuracy: 0.7284 - val_loss: 0.2883 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 11s 149ms/step - loss: 0.5574 - accuracy: 0.7870 - val_loss: 0.2927 - val_accuracy: 0.8901\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 11s 149ms/step - loss: 0.5221 - accuracy: 0.8080 - val_loss: 0.2891 - val_accuracy: 0.8926\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 11s 148ms/step - loss: 0.4765 - accuracy: 0.8242 - val_loss: 0.2905 - val_accuracy: 0.8917\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 11s 148ms/step - loss: 0.4549 - accuracy: 0.8359 - val_loss: 0.2872 - val_accuracy: 0.8939\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 11s 148ms/step - loss: 0.4026 - accuracy: 0.8529 - val_loss: 0.2905 - val_accuracy: 0.8935\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 11s 149ms/step - loss: 0.3742 - accuracy: 0.8660 - val_loss: 0.2854 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 11s 152ms/step - loss: 0.3669 - accuracy: 0.8702 - val_loss: 0.2920 - val_accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 11s 144ms/step - loss: 0.3530 - accuracy: 0.8811 - val_loss: 0.2925 - val_accuracy: 0.8966\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 11s 146ms/step - loss: 0.3151 - accuracy: 0.8887 - val_loss: 0.3005 - val_accuracy: 0.8960\n",
      "Duration: 0:01:51.975204\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f82df5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 13s 148ms/step - loss: 0.6948 - accuracy: 0.7425 - val_loss: 0.2884 - val_accuracy: 0.8888\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 12s 145ms/step - loss: 0.5571 - accuracy: 0.7878 - val_loss: 0.2819 - val_accuracy: 0.8967\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.5124 - accuracy: 0.8118 - val_loss: 0.2802 - val_accuracy: 0.8908\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 12s 152ms/step - loss: 0.4788 - accuracy: 0.8255 - val_loss: 0.2853 - val_accuracy: 0.8921\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.4487 - accuracy: 0.8376 - val_loss: 0.2950 - val_accuracy: 0.8891\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 11s 144ms/step - loss: 0.4199 - accuracy: 0.8473 - val_loss: 0.2878 - val_accuracy: 0.8980\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 11s 143ms/step - loss: 0.3866 - accuracy: 0.8582 - val_loss: 0.2837 - val_accuracy: 0.8967\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 12s 153ms/step - loss: 0.3607 - accuracy: 0.8692 - val_loss: 0.2973 - val_accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 0.3353 - accuracy: 0.8831 - val_loss: 0.2857 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.3014 - accuracy: 0.8922 - val_loss: 0.2983 - val_accuracy: 0.8976\n",
      "Duration: 0:01:59.630225\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "614d629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 13s 142ms/step - loss: 0.6996 - accuracy: 0.7410 - val_loss: 0.2828 - val_accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 12s 139ms/step - loss: 0.5666 - accuracy: 0.7925 - val_loss: 0.2940 - val_accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 12s 142ms/step - loss: 0.5064 - accuracy: 0.8197 - val_loss: 0.2800 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 12s 137ms/step - loss: 0.4719 - accuracy: 0.8228 - val_loss: 0.2856 - val_accuracy: 0.8952\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 12s 138ms/step - loss: 0.4428 - accuracy: 0.8450 - val_loss: 0.2855 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 12s 138ms/step - loss: 0.4073 - accuracy: 0.8577 - val_loss: 0.2882 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 11s 135ms/step - loss: 0.3805 - accuracy: 0.8687 - val_loss: 0.2850 - val_accuracy: 0.9014\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 12s 139ms/step - loss: 0.3535 - accuracy: 0.8789 - val_loss: 0.2876 - val_accuracy: 0.8999\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 12s 140ms/step - loss: 0.3087 - accuracy: 0.8925 - val_loss: 0.3135 - val_accuracy: 0.8919\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 12s 140ms/step - loss: 0.2946 - accuracy: 0.8996 - val_loss: 0.3042 - val_accuracy: 0.8962\n",
      "Duration: 0:01:59.207041\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36499bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 14s 142ms/step - loss: 0.6468 - accuracy: 0.7611 - val_loss: 0.2915 - val_accuracy: 0.8891\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 13s 141ms/step - loss: 0.5267 - accuracy: 0.8087 - val_loss: 0.2786 - val_accuracy: 0.8967\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 13s 144ms/step - loss: 0.4854 - accuracy: 0.8240 - val_loss: 0.2833 - val_accuracy: 0.8978\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 13s 138ms/step - loss: 0.4346 - accuracy: 0.8388 - val_loss: 0.2943 - val_accuracy: 0.8924\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 13s 139ms/step - loss: 0.4236 - accuracy: 0.8476 - val_loss: 0.2746 - val_accuracy: 0.9003\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 13s 138ms/step - loss: 0.3934 - accuracy: 0.8600 - val_loss: 0.2790 - val_accuracy: 0.9032\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 12s 137ms/step - loss: 0.3665 - accuracy: 0.8706 - val_loss: 0.2836 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 13s 139ms/step - loss: 0.3408 - accuracy: 0.8824 - val_loss: 0.3008 - val_accuracy: 0.8989\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 13s 140ms/step - loss: 0.3116 - accuracy: 0.8929 - val_loss: 0.3185 - val_accuracy: 0.8922\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 13s 138ms/step - loss: 0.2893 - accuracy: 0.9017 - val_loss: 0.3202 - val_accuracy: 0.8936\n",
      "Duration: 0:02:07.994669\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fdd3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 15s 138ms/step - loss: 0.6256 - accuracy: 0.7750 - val_loss: 0.2796 - val_accuracy: 0.8916\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 13s 136ms/step - loss: 0.5164 - accuracy: 0.8165 - val_loss: 0.2767 - val_accuracy: 0.8949\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 13s 135ms/step - loss: 0.4608 - accuracy: 0.8302 - val_loss: 0.2783 - val_accuracy: 0.8931\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 13s 135ms/step - loss: 0.4458 - accuracy: 0.8415 - val_loss: 0.2881 - val_accuracy: 0.8919\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 13s 134ms/step - loss: 0.4079 - accuracy: 0.8547 - val_loss: 0.2779 - val_accuracy: 0.8984\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 13s 134ms/step - loss: 0.3709 - accuracy: 0.8704 - val_loss: 0.2856 - val_accuracy: 0.8996\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 13s 134ms/step - loss: 0.3530 - accuracy: 0.8747 - val_loss: 0.2796 - val_accuracy: 0.9019\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 0.3245 - accuracy: 0.8851 - val_loss: 0.3007 - val_accuracy: 0.9005\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 13s 133ms/step - loss: 0.3081 - accuracy: 0.8964 - val_loss: 0.2943 - val_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 13s 134ms/step - loss: 0.2883 - accuracy: 0.9047 - val_loss: 0.2986 - val_accuracy: 0.9054\n",
      "Duration: 0:02:10.146447\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "998c89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 15s 134ms/step - loss: 0.5901 - accuracy: 0.7921 - val_loss: 0.2844 - val_accuracy: 0.8863\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 13s 131ms/step - loss: 0.4876 - accuracy: 0.8310 - val_loss: 0.2848 - val_accuracy: 0.8936\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 13s 130ms/step - loss: 0.4499 - accuracy: 0.8373 - val_loss: 0.2775 - val_accuracy: 0.8980\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 13s 130ms/step - loss: 0.4161 - accuracy: 0.8599 - val_loss: 0.2760 - val_accuracy: 0.8991\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 13s 132ms/step - loss: 0.3948 - accuracy: 0.8611 - val_loss: 0.2794 - val_accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 13s 132ms/step - loss: 0.3697 - accuracy: 0.8697 - val_loss: 0.2863 - val_accuracy: 0.8992\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 13s 131ms/step - loss: 0.3391 - accuracy: 0.8824 - val_loss: 0.2794 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 13s 130ms/step - loss: 0.3030 - accuracy: 0.8958 - val_loss: 0.3029 - val_accuracy: 0.9005\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 13s 133ms/step - loss: 0.2858 - accuracy: 0.9002 - val_loss: 0.2918 - val_accuracy: 0.9041\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 13s 134ms/step - loss: 0.2841 - accuracy: 0.9045 - val_loss: 0.3061 - val_accuracy: 0.9045\n",
      "Duration: 0:02:13.795344\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "608b6028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 16s 133ms/step - loss: 0.5634 - accuracy: 0.8028 - val_loss: 0.2922 - val_accuracy: 0.8866\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.4586 - accuracy: 0.8351 - val_loss: 0.2820 - val_accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 0.4066 - accuracy: 0.8574 - val_loss: 0.2812 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.3762 - accuracy: 0.8627 - val_loss: 0.2844 - val_accuracy: 0.8958\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.3490 - accuracy: 0.8710 - val_loss: 0.2830 - val_accuracy: 0.9016\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.3316 - accuracy: 0.8874 - val_loss: 0.3105 - val_accuracy: 0.8941\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.3024 - accuracy: 0.8958 - val_loss: 0.2981 - val_accuracy: 0.8991\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 0.2788 - accuracy: 0.9061 - val_loss: 0.3077 - val_accuracy: 0.8960\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 14s 132ms/step - loss: 0.2547 - accuracy: 0.9118 - val_loss: 0.3073 - val_accuracy: 0.8966\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.2371 - accuracy: 0.9201 - val_loss: 0.2990 - val_accuracy: 0.9046\n",
      "Duration: 0:02:25.293408\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dsa[n].fit_model(image_sets_dsa[n],label_sets_dsa[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5efcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dsa_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_dsa_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_dsa_e1\"\n",
    "new_model_dsa_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_may_dsa_e1\"\n",
    "\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_dsa:\n",
    "    model.save(new_model_dsa_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77836993",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del dsa_values\n",
    "    del top_images_by_dsa\n",
    "    del top_labels_by_dsa\n",
    "    del image_sets_dsa\n",
    "    del label_sets_dsa\n",
    "    del models_dsa\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2d78dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327980"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73510f",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ac6d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "#dg_direction = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/deep_gini_values.npy\"\n",
    "\n",
    "#deep_gini_values = np.load(dg_direction)\n",
    "dg_direction = \"D:/guided-retraining/data/\"+dataset+\"/deep_gini_values.npy\"\n",
    "\n",
    "deep_gini_values = np.load(dg_direction)[len(x_train):] \n",
    "print(len(deep_gini_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d85ee221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by dg values\n",
    "top_images_by_dg  = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),x_adversary_training)\n",
    "top_labels_by_dg = utils.get_x_of_indexes(list(np.flip(np.argsort(deep_gini_values))),y_adversary_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7636eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_dg = []\n",
    "label_sets_dg = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_dg)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_dg)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_dg)%m))\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m+(len(top_images_by_dg)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_dg_n = np.array(top_images_by_dg[:n+m])\n",
    "        top_labels_by_dg_n = np.array(top_labels_by_dg[:n+m])\n",
    "    image_sets_dg.append(top_images_by_dg_n)\n",
    "    label_sets_dg.append(top_labels_by_dg_n)\n",
    "    print(len(top_images_by_dg_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8235ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "models_dg = []\n",
    "#for i in range(len(label_sets_lsa)):\n",
    "for i in range(len(label_sets_dg)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_dg.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e0ae2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.5148 - accuracy: 0.4765 - val_loss: 0.2901 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 1.1188 - accuracy: 0.6000 - val_loss: 0.3109 - val_accuracy: 0.8911\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.9627 - accuracy: 0.6618 - val_loss: 0.3365 - val_accuracy: 0.8895\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7582 - accuracy: 0.7265 - val_loss: 0.3590 - val_accuracy: 0.8847\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7518 - accuracy: 0.7265 - val_loss: 0.3643 - val_accuracy: 0.8849\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.6995 - accuracy: 0.7412 - val_loss: 0.3715 - val_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.7021 - accuracy: 0.7647 - val_loss: 0.3785 - val_accuracy: 0.8822\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.6781 - accuracy: 0.7618 - val_loss: 0.3602 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.5723 - accuracy: 0.7765 - val_loss: 0.3824 - val_accuracy: 0.8871\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.5982 - accuracy: 0.7676 - val_loss: 0.3970 - val_accuracy: 0.8841\n",
      "Duration: 0:00:55.679264\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9111d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 7s 592ms/step - loss: 1.2421 - accuracy: 0.5265 - val_loss: 0.2852 - val_accuracy: 0.8985\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 6s 571ms/step - loss: 0.9577 - accuracy: 0.6412 - val_loss: 0.2797 - val_accuracy: 0.9011\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 6s 562ms/step - loss: 0.7538 - accuracy: 0.7088 - val_loss: 0.2904 - val_accuracy: 0.8991\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 6s 588ms/step - loss: 0.7710 - accuracy: 0.6971 - val_loss: 0.3036 - val_accuracy: 0.8959\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 6s 568ms/step - loss: 0.7306 - accuracy: 0.7250 - val_loss: 0.3082 - val_accuracy: 0.8967\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 6s 572ms/step - loss: 0.6534 - accuracy: 0.7529 - val_loss: 0.3147 - val_accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 6s 574ms/step - loss: 0.5952 - accuracy: 0.7662 - val_loss: 0.3244 - val_accuracy: 0.8968\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 6s 581ms/step - loss: 0.5950 - accuracy: 0.7735 - val_loss: 0.3466 - val_accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 6s 587ms/step - loss: 0.5516 - accuracy: 0.7809 - val_loss: 0.3417 - val_accuracy: 0.8964\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 6s 585ms/step - loss: 0.5386 - accuracy: 0.7956 - val_loss: 0.3527 - val_accuracy: 0.8954\n",
      "Duration: 0:01:00.047890\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7e4d9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 443ms/step - loss: 1.2271 - accuracy: 0.5206 - val_loss: 0.2724 - val_accuracy: 0.9009\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 6s 427ms/step - loss: 0.9658 - accuracy: 0.5971 - val_loss: 0.2697 - val_accuracy: 0.9034\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 6s 428ms/step - loss: 0.8629 - accuracy: 0.6657 - val_loss: 0.2858 - val_accuracy: 0.9014\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 6s 416ms/step - loss: 0.7639 - accuracy: 0.7069 - val_loss: 0.2818 - val_accuracy: 0.9017\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 6s 414ms/step - loss: 0.7176 - accuracy: 0.7373 - val_loss: 0.2966 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 6s 413ms/step - loss: 0.6892 - accuracy: 0.7353 - val_loss: 0.3044 - val_accuracy: 0.9015\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 7s 432ms/step - loss: 0.6660 - accuracy: 0.7382 - val_loss: 0.3071 - val_accuracy: 0.8989\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 6s 399ms/step - loss: 0.6560 - accuracy: 0.7461 - val_loss: 0.2997 - val_accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 6s 417ms/step - loss: 0.6210 - accuracy: 0.7873 - val_loss: 0.3124 - val_accuracy: 0.8987\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 6s 416ms/step - loss: 0.5510 - accuracy: 0.7853 - val_loss: 0.3296 - val_accuracy: 0.8991\n",
      "Duration: 0:01:05.365860\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "42875fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 8s 314ms/step - loss: 1.1574 - accuracy: 0.5287 - val_loss: 0.2704 - val_accuracy: 0.8995\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 6s 304ms/step - loss: 0.9457 - accuracy: 0.6074 - val_loss: 0.2872 - val_accuracy: 0.8956\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 6s 303ms/step - loss: 0.8114 - accuracy: 0.6779 - val_loss: 0.2851 - val_accuracy: 0.8992\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 6s 305ms/step - loss: 0.8276 - accuracy: 0.6669 - val_loss: 0.2852 - val_accuracy: 0.9019\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 7s 316ms/step - loss: 0.7320 - accuracy: 0.7096 - val_loss: 0.2879 - val_accuracy: 0.8971\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 7s 314ms/step - loss: 0.7238 - accuracy: 0.7118 - val_loss: 0.2913 - val_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 6s 306ms/step - loss: 0.6771 - accuracy: 0.7213 - val_loss: 0.2894 - val_accuracy: 0.9014\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 6s 297ms/step - loss: 0.6346 - accuracy: 0.7426 - val_loss: 0.2890 - val_accuracy: 0.9061\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 6s 306ms/step - loss: 0.6242 - accuracy: 0.7471 - val_loss: 0.2942 - val_accuracy: 0.9044\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 6s 297ms/step - loss: 0.5820 - accuracy: 0.7625 - val_loss: 0.3184 - val_accuracy: 0.8984\n",
      "Duration: 0:01:06.584427\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "efd03b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 8s 268ms/step - loss: 1.1232 - accuracy: 0.5335 - val_loss: 0.2633 - val_accuracy: 0.9049\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 7s 255ms/step - loss: 0.8881 - accuracy: 0.6612 - val_loss: 0.2739 - val_accuracy: 0.9035\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 7s 259ms/step - loss: 0.8052 - accuracy: 0.6700 - val_loss: 0.2763 - val_accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 7s 259ms/step - loss: 0.7419 - accuracy: 0.7135 - val_loss: 0.2821 - val_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 7s 279ms/step - loss: 0.7179 - accuracy: 0.7271 - val_loss: 0.2819 - val_accuracy: 0.8999\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 7s 261ms/step - loss: 0.6490 - accuracy: 0.7429 - val_loss: 0.2889 - val_accuracy: 0.9021\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 0.6370 - accuracy: 0.7559 - val_loss: 0.2935 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 0.6230 - accuracy: 0.7559 - val_loss: 0.3016 - val_accuracy: 0.9019\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 0.5794 - accuracy: 0.7629 - val_loss: 0.3014 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 7s 265ms/step - loss: 0.5500 - accuracy: 0.7853 - val_loss: 0.3007 - val_accuracy: 0.9027\n",
      "Duration: 0:01:11.098952\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94d34929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 9s 243ms/step - loss: 1.0778 - accuracy: 0.5598 - val_loss: 0.2824 - val_accuracy: 0.8985\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 0.8734 - accuracy: 0.6480 - val_loss: 0.2729 - val_accuracy: 0.9010\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 7s 236ms/step - loss: 0.7916 - accuracy: 0.6730 - val_loss: 0.2703 - val_accuracy: 0.9035\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.7133 - accuracy: 0.7137 - val_loss: 0.2778 - val_accuracy: 0.9027\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 0.6972 - accuracy: 0.7250 - val_loss: 0.2779 - val_accuracy: 0.9010\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.6676 - accuracy: 0.7417 - val_loss: 0.2733 - val_accuracy: 0.9052\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 0.6442 - accuracy: 0.7529 - val_loss: 0.2841 - val_accuracy: 0.9046\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 0.5945 - accuracy: 0.7701 - val_loss: 0.2842 - val_accuracy: 0.9039\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 0.5879 - accuracy: 0.7740 - val_loss: 0.2835 - val_accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.5848 - accuracy: 0.7755 - val_loss: 0.2986 - val_accuracy: 0.8966\n",
      "Duration: 0:01:14.819645\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c340580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 9s 198ms/step - loss: 1.0603 - accuracy: 0.5824 - val_loss: 0.2710 - val_accuracy: 0.8974\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7s 192ms/step - loss: 0.8432 - accuracy: 0.6609 - val_loss: 0.2778 - val_accuracy: 0.8921\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 7s 194ms/step - loss: 0.7575 - accuracy: 0.7025 - val_loss: 0.2719 - val_accuracy: 0.9001\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 7s 198ms/step - loss: 0.6909 - accuracy: 0.7345 - val_loss: 0.2731 - val_accuracy: 0.9029\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.6863 - accuracy: 0.7382 - val_loss: 0.2799 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 7s 200ms/step - loss: 0.6404 - accuracy: 0.7538 - val_loss: 0.2838 - val_accuracy: 0.9003\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 8s 202ms/step - loss: 0.6079 - accuracy: 0.7765 - val_loss: 0.2798 - val_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 7s 199ms/step - loss: 0.5891 - accuracy: 0.7819 - val_loss: 0.2731 - val_accuracy: 0.9051\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 8s 205ms/step - loss: 0.5468 - accuracy: 0.7908 - val_loss: 0.2829 - val_accuracy: 0.8995\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 8s 211ms/step - loss: 0.5132 - accuracy: 0.8042 - val_loss: 0.3032 - val_accuracy: 0.8959\n",
      "Duration: 0:01:16.783957\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "658a655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 10s 200ms/step - loss: 1.0148 - accuracy: 0.6070 - val_loss: 0.2650 - val_accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 8s 199ms/step - loss: 0.8347 - accuracy: 0.6842 - val_loss: 0.2753 - val_accuracy: 0.8965\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 8s 192ms/step - loss: 0.7583 - accuracy: 0.7022 - val_loss: 0.2737 - val_accuracy: 0.9002\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 8s 193ms/step - loss: 0.6978 - accuracy: 0.7294 - val_loss: 0.2896 - val_accuracy: 0.8909\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 8s 190ms/step - loss: 0.6721 - accuracy: 0.7449 - val_loss: 0.2786 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 8s 194ms/step - loss: 0.6384 - accuracy: 0.7596 - val_loss: 0.2818 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 8s 196ms/step - loss: 0.6056 - accuracy: 0.7662 - val_loss: 0.2860 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 8s 192ms/step - loss: 0.5701 - accuracy: 0.7835 - val_loss: 0.2856 - val_accuracy: 0.9011\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 8s 192ms/step - loss: 0.5275 - accuracy: 0.7982 - val_loss: 0.3185 - val_accuracy: 0.8974\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 8s 194ms/step - loss: 0.5214 - accuracy: 0.8081 - val_loss: 0.2832 - val_accuracy: 0.9024\n",
      "Duration: 0:01:23.899403\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d53b3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 10s 189ms/step - loss: 0.9966 - accuracy: 0.5980 - val_loss: 0.2746 - val_accuracy: 0.8939\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 9s 182ms/step - loss: 0.7913 - accuracy: 0.6967 - val_loss: 0.2719 - val_accuracy: 0.8947\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 9s 183ms/step - loss: 0.7523 - accuracy: 0.7069 - val_loss: 0.2699 - val_accuracy: 0.8979\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.6992 - accuracy: 0.7386 - val_loss: 0.2706 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 9s 182ms/step - loss: 0.6681 - accuracy: 0.7497 - val_loss: 0.2702 - val_accuracy: 0.9029\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.6173 - accuracy: 0.7667 - val_loss: 0.2850 - val_accuracy: 0.8996\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 9s 182ms/step - loss: 0.5986 - accuracy: 0.7699 - val_loss: 0.2755 - val_accuracy: 0.9017\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 9s 180ms/step - loss: 0.5762 - accuracy: 0.7853 - val_loss: 0.2715 - val_accuracy: 0.9029\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.5363 - accuracy: 0.7954 - val_loss: 0.2828 - val_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.5273 - accuracy: 0.8010 - val_loss: 0.2806 - val_accuracy: 0.9027\n",
      "Duration: 0:01:27.806102\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5a1e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 11s 176ms/step - loss: 0.9698 - accuracy: 0.6335 - val_loss: 0.2779 - val_accuracy: 0.8962\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 9s 167ms/step - loss: 0.7743 - accuracy: 0.6982 - val_loss: 0.2714 - val_accuracy: 0.8953\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 9s 167ms/step - loss: 0.7059 - accuracy: 0.7235 - val_loss: 0.2861 - val_accuracy: 0.8941\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 9s 169ms/step - loss: 0.6781 - accuracy: 0.7424 - val_loss: 0.2846 - val_accuracy: 0.8939\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 9s 168ms/step - loss: 0.6375 - accuracy: 0.7615 - val_loss: 0.2745 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 9s 168ms/step - loss: 0.6052 - accuracy: 0.7779 - val_loss: 0.2868 - val_accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 9s 169ms/step - loss: 0.5840 - accuracy: 0.7844 - val_loss: 0.2921 - val_accuracy: 0.8998\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 9s 173ms/step - loss: 0.5663 - accuracy: 0.7906 - val_loss: 0.2804 - val_accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 9s 173ms/step - loss: 0.5353 - accuracy: 0.8053 - val_loss: 0.2840 - val_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 9s 169ms/step - loss: 0.4822 - accuracy: 0.8182 - val_loss: 0.3062 - val_accuracy: 0.8958\n",
      "Duration: 0:01:32.249096\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3a38f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 11s 170ms/step - loss: 0.9441 - accuracy: 0.6455 - val_loss: 0.2751 - val_accuracy: 0.8953\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 10s 164ms/step - loss: 0.7690 - accuracy: 0.7115 - val_loss: 0.2698 - val_accuracy: 0.8957\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 10s 163ms/step - loss: 0.6982 - accuracy: 0.7302 - val_loss: 0.2732 - val_accuracy: 0.9015\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.6653 - accuracy: 0.7455 - val_loss: 0.2808 - val_accuracy: 0.8956\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 10s 167ms/step - loss: 0.6121 - accuracy: 0.7698 - val_loss: 0.2701 - val_accuracy: 0.9014\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 10s 175ms/step - loss: 0.5810 - accuracy: 0.7743 - val_loss: 0.2809 - val_accuracy: 0.9017\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 10s 165ms/step - loss: 0.5339 - accuracy: 0.8059 - val_loss: 0.3074 - val_accuracy: 0.8939\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 9s 162ms/step - loss: 0.5053 - accuracy: 0.8136 - val_loss: 0.2853 - val_accuracy: 0.9011\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 9s 161ms/step - loss: 0.4725 - accuracy: 0.8270 - val_loss: 0.2866 - val_accuracy: 0.9037\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 10s 164ms/step - loss: 0.4628 - accuracy: 0.8275 - val_loss: 0.2867 - val_accuracy: 0.9039\n",
      "Duration: 0:01:38.473745\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1d9ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 12s 156ms/step - loss: 0.9141 - accuracy: 0.6603 - val_loss: 0.2707 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 0.7261 - accuracy: 0.7184 - val_loss: 0.2835 - val_accuracy: 0.8905\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 10s 151ms/step - loss: 0.6706 - accuracy: 0.7512 - val_loss: 0.2754 - val_accuracy: 0.8963\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 9s 147ms/step - loss: 0.6121 - accuracy: 0.7738 - val_loss: 0.2782 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 0.5845 - accuracy: 0.7841 - val_loss: 0.2809 - val_accuracy: 0.8987\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 9s 149ms/step - loss: 0.5538 - accuracy: 0.8027 - val_loss: 0.2819 - val_accuracy: 0.9009\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 9s 149ms/step - loss: 0.5339 - accuracy: 0.8093 - val_loss: 0.2742 - val_accuracy: 0.9026\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 9s 149ms/step - loss: 0.4808 - accuracy: 0.8287 - val_loss: 0.3071 - val_accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 0.4736 - accuracy: 0.8341 - val_loss: 0.2749 - val_accuracy: 0.9024\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 0.4386 - accuracy: 0.8431 - val_loss: 0.2843 - val_accuracy: 0.9017\n",
      "Duration: 0:01:37.129163\n"
     ]
    }
   ],
   "source": [
    "n=11\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df0a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 11s 146ms/step - loss: 0.8458 - accuracy: 0.6925 - val_loss: 0.2820 - val_accuracy: 0.8904\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 10s 144ms/step - loss: 0.7028 - accuracy: 0.7308 - val_loss: 0.2753 - val_accuracy: 0.8964\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 10s 139ms/step - loss: 0.6250 - accuracy: 0.7647 - val_loss: 0.2762 - val_accuracy: 0.8984\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.5942 - accuracy: 0.7774 - val_loss: 0.2790 - val_accuracy: 0.8989\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 10s 142ms/step - loss: 0.5542 - accuracy: 0.7905 - val_loss: 0.2823 - val_accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 10s 139ms/step - loss: 0.5146 - accuracy: 0.8068 - val_loss: 0.2799 - val_accuracy: 0.8989\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 10s 140ms/step - loss: 0.4905 - accuracy: 0.8258 - val_loss: 0.2930 - val_accuracy: 0.8955\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 10s 143ms/step - loss: 0.4531 - accuracy: 0.8337 - val_loss: 0.2943 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 10s 140ms/step - loss: 0.4392 - accuracy: 0.8459 - val_loss: 0.3042 - val_accuracy: 0.8937\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 10s 140ms/step - loss: 0.3947 - accuracy: 0.8636 - val_loss: 0.3125 - val_accuracy: 0.9027\n",
      "Duration: 0:01:39.402427\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b156eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 12s 143ms/step - loss: 0.7979 - accuracy: 0.7149 - val_loss: 0.2673 - val_accuracy: 0.8965\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 10s 136ms/step - loss: 0.6525 - accuracy: 0.7601 - val_loss: 0.2768 - val_accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.5868 - accuracy: 0.7866 - val_loss: 0.2868 - val_accuracy: 0.8908\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.5522 - accuracy: 0.8019 - val_loss: 0.2786 - val_accuracy: 0.8982\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 10s 139ms/step - loss: 0.5219 - accuracy: 0.8122 - val_loss: 0.2840 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.4886 - accuracy: 0.8225 - val_loss: 0.2902 - val_accuracy: 0.8957\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.4674 - accuracy: 0.8376 - val_loss: 0.2928 - val_accuracy: 0.8965\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 10s 138ms/step - loss: 0.4313 - accuracy: 0.8435 - val_loss: 0.2796 - val_accuracy: 0.8994\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 10s 140ms/step - loss: 0.3944 - accuracy: 0.8599 - val_loss: 0.2800 - val_accuracy: 0.9035\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 10s 137ms/step - loss: 0.3767 - accuracy: 0.8697 - val_loss: 0.2936 - val_accuracy: 0.8994\n",
      "Duration: 0:01:44.848391\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c002d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 12s 136ms/step - loss: 0.7478 - accuracy: 0.7286 - val_loss: 0.2880 - val_accuracy: 0.8896\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 0.6102 - accuracy: 0.7712 - val_loss: 0.2861 - val_accuracy: 0.8949\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.5560 - accuracy: 0.8035 - val_loss: 0.2778 - val_accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.5228 - accuracy: 0.8153 - val_loss: 0.2720 - val_accuracy: 0.9031\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.4947 - accuracy: 0.8243 - val_loss: 0.2834 - val_accuracy: 0.8962\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.4567 - accuracy: 0.8408 - val_loss: 0.2738 - val_accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 0.4260 - accuracy: 0.8535 - val_loss: 0.2826 - val_accuracy: 0.8999\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.3944 - accuracy: 0.8618 - val_loss: 0.2769 - val_accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 11s 135ms/step - loss: 0.3733 - accuracy: 0.8731 - val_loss: 0.3045 - val_accuracy: 0.8997\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 11s 136ms/step - loss: 0.3490 - accuracy: 0.8763 - val_loss: 0.2822 - val_accuracy: 0.9045\n",
      "Duration: 0:01:48.320131\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f86550a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 13s 136ms/step - loss: 0.6948 - accuracy: 0.7498 - val_loss: 0.2846 - val_accuracy: 0.8942\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 11s 133ms/step - loss: 0.5669 - accuracy: 0.7917 - val_loss: 0.2893 - val_accuracy: 0.8948\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 11s 131ms/step - loss: 0.5224 - accuracy: 0.8165 - val_loss: 0.2808 - val_accuracy: 0.8970\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 11s 136ms/step - loss: 0.4836 - accuracy: 0.8206 - val_loss: 0.2721 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 11s 131ms/step - loss: 0.4552 - accuracy: 0.8382 - val_loss: 0.2811 - val_accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 11s 128ms/step - loss: 0.4222 - accuracy: 0.8528 - val_loss: 0.2886 - val_accuracy: 0.8964\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 11s 130ms/step - loss: 0.3879 - accuracy: 0.8625 - val_loss: 0.2858 - val_accuracy: 0.8954\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 11s 131ms/step - loss: 0.3600 - accuracy: 0.8717 - val_loss: 0.2933 - val_accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 11s 131ms/step - loss: 0.3529 - accuracy: 0.8772 - val_loss: 0.2881 - val_accuracy: 0.8999\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 11s 129ms/step - loss: 0.3283 - accuracy: 0.8855 - val_loss: 0.3093 - val_accuracy: 0.9021\n",
      "Duration: 0:01:52.670735\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d58ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 14s 134ms/step - loss: 0.6630 - accuracy: 0.7668 - val_loss: 0.2834 - val_accuracy: 0.8914\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 12s 129ms/step - loss: 0.5413 - accuracy: 0.8047 - val_loss: 0.2817 - val_accuracy: 0.8916\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 11s 126ms/step - loss: 0.4772 - accuracy: 0.8277 - val_loss: 0.2727 - val_accuracy: 0.8979\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 11s 126ms/step - loss: 0.4407 - accuracy: 0.8434 - val_loss: 0.2907 - val_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 12s 130ms/step - loss: 0.4215 - accuracy: 0.8460 - val_loss: 0.2842 - val_accuracy: 0.8959\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 12s 127ms/step - loss: 0.4012 - accuracy: 0.8567 - val_loss: 0.2968 - val_accuracy: 0.8975\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 12s 131ms/step - loss: 0.3843 - accuracy: 0.8649 - val_loss: 0.2932 - val_accuracy: 0.8971\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 12s 134ms/step - loss: 0.3533 - accuracy: 0.8787 - val_loss: 0.2959 - val_accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 12s 133ms/step - loss: 0.3348 - accuracy: 0.8824 - val_loss: 0.3058 - val_accuracy: 0.8999\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 11s 123ms/step - loss: 0.3091 - accuracy: 0.8946 - val_loss: 0.2987 - val_accuracy: 0.9026\n",
      "Duration: 0:01:58.752543\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7091e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 14s 125ms/step - loss: 0.6474 - accuracy: 0.7632 - val_loss: 0.2878 - val_accuracy: 0.8894\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.5166 - accuracy: 0.8126 - val_loss: 0.2774 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 11s 118ms/step - loss: 0.4661 - accuracy: 0.8324 - val_loss: 0.2798 - val_accuracy: 0.8971\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 12s 122ms/step - loss: 0.4287 - accuracy: 0.8412 - val_loss: 0.2897 - val_accuracy: 0.8923\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.4202 - accuracy: 0.8511 - val_loss: 0.2832 - val_accuracy: 0.8963\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 12s 125ms/step - loss: 0.3790 - accuracy: 0.8645 - val_loss: 0.2851 - val_accuracy: 0.8996\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.3618 - accuracy: 0.8745 - val_loss: 0.3055 - val_accuracy: 0.8954\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.3300 - accuracy: 0.8837 - val_loss: 0.2792 - val_accuracy: 0.9028\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 12s 126ms/step - loss: 0.3124 - accuracy: 0.8928 - val_loss: 0.2877 - val_accuracy: 0.9040\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 12s 124ms/step - loss: 0.2836 - accuracy: 0.9095 - val_loss: 0.2983 - val_accuracy: 0.9038\n",
      "Duration: 0:01:59.959826\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96e79448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 14s 127ms/step - loss: 0.6100 - accuracy: 0.7813 - val_loss: 0.2710 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 12s 122ms/step - loss: 0.4968 - accuracy: 0.8158 - val_loss: 0.2790 - val_accuracy: 0.8964\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 12s 124ms/step - loss: 0.4505 - accuracy: 0.8342 - val_loss: 0.2862 - val_accuracy: 0.8934\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 13s 125ms/step - loss: 0.4133 - accuracy: 0.8523 - val_loss: 0.2822 - val_accuracy: 0.8967\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 12s 120ms/step - loss: 0.3897 - accuracy: 0.8635 - val_loss: 0.2958 - val_accuracy: 0.8930\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 12s 122ms/step - loss: 0.3489 - accuracy: 0.8740 - val_loss: 0.2812 - val_accuracy: 0.9005\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 12s 123ms/step - loss: 0.3375 - accuracy: 0.8834 - val_loss: 0.2819 - val_accuracy: 0.9003\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 12s 122ms/step - loss: 0.3118 - accuracy: 0.8927 - val_loss: 0.2980 - val_accuracy: 0.9019\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 12s 123ms/step - loss: 0.2835 - accuracy: 0.9039 - val_loss: 0.3182 - val_accuracy: 0.9035\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 12s 122ms/step - loss: 0.2835 - accuracy: 0.9063 - val_loss: 0.3028 - val_accuracy: 0.9028\n",
      "Duration: 0:02:05.104847\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b3b88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 15s 122ms/step - loss: 0.5618 - accuracy: 0.8008 - val_loss: 0.2783 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.4472 - accuracy: 0.8368 - val_loss: 0.2785 - val_accuracy: 0.8941\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.4217 - accuracy: 0.8474 - val_loss: 0.2831 - val_accuracy: 0.8964\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.3814 - accuracy: 0.8656 - val_loss: 0.2811 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.3585 - accuracy: 0.8773 - val_loss: 0.2865 - val_accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.3351 - accuracy: 0.8798 - val_loss: 0.3146 - val_accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 13s 119ms/step - loss: 0.3146 - accuracy: 0.8911 - val_loss: 0.2924 - val_accuracy: 0.8951\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 13s 121ms/step - loss: 0.2955 - accuracy: 0.9026 - val_loss: 0.3158 - val_accuracy: 0.8946\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2741 - accuracy: 0.9050 - val_loss: 0.2992 - val_accuracy: 0.8953\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 13s 120ms/step - loss: 0.2536 - accuracy: 0.9141 - val_loss: 0.3406 - val_accuracy: 0.8984\n",
      "Duration: 0:02:12.801169\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_dg[n].fit_model(image_sets_dg[n],label_sets_dg[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "822aa540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_dg_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_dg_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_dg_e1\"\n",
    "new_model_dg_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_may_dg_e1\"\n",
    "\n",
    "i=11\n",
    "\n",
    "for model in models_dg[i:]:\n",
    "    model.save(new_model_dg_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2139719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del deep_gini_values\n",
    "    del top_images_by_dg\n",
    "    del top_labels_by_dg\n",
    "    del image_sets_dg\n",
    "    del label_sets_dg\n",
    "    del models_dg\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8986882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302604"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bfcff",
   "metadata": {},
   "source": [
    "### Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3b6b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "#softmax values\n",
    "#se_direction = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/softmax_values.npy\"\n",
    "se_direction = \"D:/guided-retraining/data/\"+dataset+\"/softmax_values.npy\"\n",
    "\n",
    "se_values = np.load(se_direction)[len(x_train):] \n",
    "print(len(se_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a389aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by LSA values\n",
    "top_images_by_se  = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),x_adversary_training)\n",
    "top_labels_by_se = utils.get_x_of_indexes(list(np.flip(np.argsort(se_values))),y_adversary_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74bdb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "\n",
    "n = 0\n",
    "image_sets_se = []\n",
    "label_sets_se = []\n",
    "\n",
    "# last\n",
    "#for i in range(0,len(top_images_by_lsa)//m):\n",
    "\n",
    "for i in range((len(top_images_by_se)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_se)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_se)%m))\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m+(len(top_images_by_se)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_se_n = np.array(top_images_by_se[:n+m])\n",
    "        top_labels_by_se_n = np.array(top_labels_by_se[:n+m])\n",
    "    image_sets_se.append(top_images_by_se_n)\n",
    "    label_sets_se.append(top_labels_by_se_n)\n",
    "    print(len(top_images_by_se_n))\n",
    "    n += m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14e3cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "models_se = []\n",
    "for i in range(len(label_sets_se)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_se.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f66277ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.4763 - accuracy: 0.4676 - val_loss: 0.2879 - val_accuracy: 0.8996\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.9949 - accuracy: 0.6794 - val_loss: 0.3045 - val_accuracy: 0.8944\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.9150 - accuracy: 0.6765 - val_loss: 0.3101 - val_accuracy: 0.8930\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 5s 993ms/step - loss: 0.7787 - accuracy: 0.7000 - val_loss: 0.3202 - val_accuracy: 0.8935\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 4s 834ms/step - loss: 0.7254 - accuracy: 0.7382 - val_loss: 0.3490 - val_accuracy: 0.8855\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 4s 853ms/step - loss: 0.6252 - accuracy: 0.7765 - val_loss: 0.3458 - val_accuracy: 0.8871\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 4s 803ms/step - loss: 0.5410 - accuracy: 0.7941 - val_loss: 0.3511 - val_accuracy: 0.8876\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 4s 734ms/step - loss: 0.5709 - accuracy: 0.7824 - val_loss: 0.3725 - val_accuracy: 0.8844\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 5s 912ms/step - loss: 0.5853 - accuracy: 0.8088 - val_loss: 0.3657 - val_accuracy: 0.8890\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 5s 895ms/step - loss: 0.5189 - accuracy: 0.8206 - val_loss: 0.3903 - val_accuracy: 0.8857\n",
      "Duration: 0:00:47.845494\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bb251b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 489ms/step - loss: 1.3165 - accuracy: 0.5059 - val_loss: 0.2896 - val_accuracy: 0.8953\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 5s 478ms/step - loss: 0.8922 - accuracy: 0.6426 - val_loss: 0.3031 - val_accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 5s 507ms/step - loss: 0.8102 - accuracy: 0.7015 - val_loss: 0.3204 - val_accuracy: 0.8881\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 5s 453ms/step - loss: 0.7684 - accuracy: 0.7206 - val_loss: 0.3127 - val_accuracy: 0.8971\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 5s 449ms/step - loss: 0.6811 - accuracy: 0.7412 - val_loss: 0.3201 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 4s 405ms/step - loss: 0.6375 - accuracy: 0.7441 - val_loss: 0.3466 - val_accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 4s 398ms/step - loss: 0.6279 - accuracy: 0.7500 - val_loss: 0.3455 - val_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 4s 365ms/step - loss: 0.5627 - accuracy: 0.7985 - val_loss: 0.3550 - val_accuracy: 0.8955\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 4s 373ms/step - loss: 0.5658 - accuracy: 0.7853 - val_loss: 0.3612 - val_accuracy: 0.8953\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 4s 377ms/step - loss: 0.4876 - accuracy: 0.8162 - val_loss: 0.3780 - val_accuracy: 0.8941\n",
      "Duration: 0:00:44.849694\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaa22c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 1.1948 - accuracy: 0.5647 - val_loss: 0.2728 - val_accuracy: 0.9040\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 0.9396 - accuracy: 0.6441 - val_loss: 0.2811 - val_accuracy: 0.9024\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.8695 - accuracy: 0.6775 - val_loss: 0.2873 - val_accuracy: 0.9001\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.7524 - accuracy: 0.7059 - val_loss: 0.3085 - val_accuracy: 0.8982\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.7399 - accuracy: 0.7284 - val_loss: 0.3175 - val_accuracy: 0.8951\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.6759 - accuracy: 0.7353 - val_loss: 0.3326 - val_accuracy: 0.8951\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.6242 - accuracy: 0.7578 - val_loss: 0.3303 - val_accuracy: 0.8951\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.6413 - accuracy: 0.7539 - val_loss: 0.3256 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.5967 - accuracy: 0.7716 - val_loss: 0.3435 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.5355 - accuracy: 0.7980 - val_loss: 0.3480 - val_accuracy: 0.8961\n",
      "Duration: 0:00:40.185118\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "674c7497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 5s 194ms/step - loss: 1.2128 - accuracy: 0.5294 - val_loss: 0.2800 - val_accuracy: 0.8973\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.9311 - accuracy: 0.6346 - val_loss: 0.2840 - val_accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.8427 - accuracy: 0.6640 - val_loss: 0.2959 - val_accuracy: 0.8959\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.7571 - accuracy: 0.7029 - val_loss: 0.2987 - val_accuracy: 0.8974\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.7059 - accuracy: 0.7353 - val_loss: 0.3047 - val_accuracy: 0.8962\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.6821 - accuracy: 0.7338 - val_loss: 0.3134 - val_accuracy: 0.8989\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.6855 - accuracy: 0.7287 - val_loss: 0.3114 - val_accuracy: 0.8971\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.6369 - accuracy: 0.7544 - val_loss: 0.3222 - val_accuracy: 0.8939\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.5988 - accuracy: 0.7713 - val_loss: 0.3347 - val_accuracy: 0.8959\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.5799 - accuracy: 0.7765 - val_loss: 0.3343 - val_accuracy: 0.8960\n",
      "Duration: 0:00:40.218398\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe9b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 5s 166ms/step - loss: 1.1311 - accuracy: 0.5671 - val_loss: 0.2739 - val_accuracy: 0.9019\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.9212 - accuracy: 0.6324 - val_loss: 0.2725 - val_accuracy: 0.9007\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.8086 - accuracy: 0.6506 - val_loss: 0.2750 - val_accuracy: 0.9014\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.7806 - accuracy: 0.6994 - val_loss: 0.2889 - val_accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.7267 - accuracy: 0.7141 - val_loss: 0.2895 - val_accuracy: 0.8980\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.6742 - accuracy: 0.7253 - val_loss: 0.2932 - val_accuracy: 0.8984\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.6577 - accuracy: 0.7518 - val_loss: 0.2836 - val_accuracy: 0.9021\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.6485 - accuracy: 0.7512 - val_loss: 0.3004 - val_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.6192 - accuracy: 0.7588 - val_loss: 0.2996 - val_accuracy: 0.9004\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 0.5616 - accuracy: 0.7735 - val_loss: 0.3108 - val_accuracy: 0.9018\n",
      "Duration: 0:00:43.002123\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ccc154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 1.0759 - accuracy: 0.5613 - val_loss: 0.2791 - val_accuracy: 0.8952\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.8939 - accuracy: 0.6574 - val_loss: 0.2804 - val_accuracy: 0.8934\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.7957 - accuracy: 0.6838 - val_loss: 0.2847 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.7302 - accuracy: 0.6975 - val_loss: 0.2852 - val_accuracy: 0.8986\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.6876 - accuracy: 0.7225 - val_loss: 0.2736 - val_accuracy: 0.9041\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6600 - accuracy: 0.7475 - val_loss: 0.2862 - val_accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6234 - accuracy: 0.7569 - val_loss: 0.2978 - val_accuracy: 0.8989\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.6204 - accuracy: 0.7613 - val_loss: 0.2844 - val_accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.5897 - accuracy: 0.7868 - val_loss: 0.2941 - val_accuracy: 0.9018\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.5551 - accuracy: 0.7775 - val_loss: 0.2985 - val_accuracy: 0.9018\n",
      "Duration: 0:00:47.460238\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9361b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 6s 140ms/step - loss: 1.0644 - accuracy: 0.5697 - val_loss: 0.2797 - val_accuracy: 0.8933\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.8630 - accuracy: 0.6580 - val_loss: 0.2723 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 0.8049 - accuracy: 0.6945 - val_loss: 0.2783 - val_accuracy: 0.8948\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.7151 - accuracy: 0.7265 - val_loss: 0.2743 - val_accuracy: 0.9029\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 0.6951 - accuracy: 0.7315 - val_loss: 0.2802 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.6656 - accuracy: 0.7483 - val_loss: 0.3054 - val_accuracy: 0.8911\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 0.6286 - accuracy: 0.7500 - val_loss: 0.2846 - val_accuracy: 0.8995\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 6s 154ms/step - loss: 0.5871 - accuracy: 0.7685 - val_loss: 0.2961 - val_accuracy: 0.8961\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 6s 149ms/step - loss: 0.5921 - accuracy: 0.7731 - val_loss: 0.2877 - val_accuracy: 0.9006\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 6s 149ms/step - loss: 0.5488 - accuracy: 0.7853 - val_loss: 0.3003 - val_accuracy: 0.9018\n",
      "Duration: 0:00:53.359141\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d018799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 8s 150ms/step - loss: 1.0242 - accuracy: 0.5923 - val_loss: 0.2749 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.8450 - accuracy: 0.6728 - val_loss: 0.2803 - val_accuracy: 0.8969\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 0.7465 - accuracy: 0.7018 - val_loss: 0.2685 - val_accuracy: 0.9007\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.7207 - accuracy: 0.7210 - val_loss: 0.2720 - val_accuracy: 0.9017\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 6s 150ms/step - loss: 0.6577 - accuracy: 0.7474 - val_loss: 0.2831 - val_accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 6s 135ms/step - loss: 0.6410 - accuracy: 0.7467 - val_loss: 0.2858 - val_accuracy: 0.8981\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.6277 - accuracy: 0.7533 - val_loss: 0.2805 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 6s 138ms/step - loss: 0.5737 - accuracy: 0.7827 - val_loss: 0.2835 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.5532 - accuracy: 0.7882 - val_loss: 0.2877 - val_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.5282 - accuracy: 0.8055 - val_loss: 0.2835 - val_accuracy: 0.8996\n",
      "Duration: 0:01:00.818996\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e73810d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 6s 123ms/step - loss: 1.0109 - accuracy: 0.6029 - val_loss: 0.2670 - val_accuracy: 0.9019\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.8195 - accuracy: 0.6859 - val_loss: 0.2656 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.7400 - accuracy: 0.7193 - val_loss: 0.2713 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.6895 - accuracy: 0.7386 - val_loss: 0.2770 - val_accuracy: 0.8977\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.6702 - accuracy: 0.7415 - val_loss: 0.2820 - val_accuracy: 0.8947\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 6s 119ms/step - loss: 0.6139 - accuracy: 0.7605 - val_loss: 0.2759 - val_accuracy: 0.9021\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.5959 - accuracy: 0.7729 - val_loss: 0.2774 - val_accuracy: 0.9003\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 6s 119ms/step - loss: 0.5667 - accuracy: 0.7859 - val_loss: 0.2811 - val_accuracy: 0.9049\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.5227 - accuracy: 0.8036 - val_loss: 0.2807 - val_accuracy: 0.9008\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 6s 119ms/step - loss: 0.5032 - accuracy: 0.8036 - val_loss: 0.2848 - val_accuracy: 0.9036\n",
      "Duration: 0:00:56.982013\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec33d8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 7s 114ms/step - loss: 0.9966 - accuracy: 0.6224 - val_loss: 0.2669 - val_accuracy: 0.8989\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 6s 111ms/step - loss: 0.7883 - accuracy: 0.6891 - val_loss: 0.2661 - val_accuracy: 0.8985\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 6s 110ms/step - loss: 0.7143 - accuracy: 0.7309 - val_loss: 0.2922 - val_accuracy: 0.8862\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 6s 110ms/step - loss: 0.6772 - accuracy: 0.7435 - val_loss: 0.2908 - val_accuracy: 0.8911\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 6s 115ms/step - loss: 0.6389 - accuracy: 0.7638 - val_loss: 0.2905 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 0.5813 - accuracy: 0.7791 - val_loss: 0.2875 - val_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 0.5581 - accuracy: 0.7906 - val_loss: 0.2745 - val_accuracy: 0.9026\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 0.5450 - accuracy: 0.7950 - val_loss: 0.2812 - val_accuracy: 0.9012\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 0.5074 - accuracy: 0.8071 - val_loss: 0.2995 - val_accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 6s 113ms/step - loss: 0.4801 - accuracy: 0.8232 - val_loss: 0.3088 - val_accuracy: 0.8966\n",
      "Duration: 0:01:00.731902\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8806a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 7s 109ms/step - loss: 0.9567 - accuracy: 0.6564 - val_loss: 0.2741 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 6s 107ms/step - loss: 0.7656 - accuracy: 0.7126 - val_loss: 0.2691 - val_accuracy: 0.8992\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.6873 - accuracy: 0.7441 - val_loss: 0.2686 - val_accuracy: 0.8983\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.6433 - accuracy: 0.7572 - val_loss: 0.2710 - val_accuracy: 0.9018\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 0.6175 - accuracy: 0.7642 - val_loss: 0.2847 - val_accuracy: 0.8962\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.5669 - accuracy: 0.7941 - val_loss: 0.2784 - val_accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 6s 106ms/step - loss: 0.5339 - accuracy: 0.8035 - val_loss: 0.2762 - val_accuracy: 0.9004\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 6s 108ms/step - loss: 0.5090 - accuracy: 0.8115 - val_loss: 0.2916 - val_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.4875 - accuracy: 0.8217 - val_loss: 0.2787 - val_accuracy: 0.9046\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 6s 108ms/step - loss: 0.4673 - accuracy: 0.8281 - val_loss: 0.2848 - val_accuracy: 0.9011\n",
      "Duration: 0:01:03.885325\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bf6fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 0.8781 - accuracy: 0.6846 - val_loss: 0.2746 - val_accuracy: 0.8982\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 7s 105ms/step - loss: 0.7208 - accuracy: 0.7299 - val_loss: 0.2768 - val_accuracy: 0.8948\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.6771 - accuracy: 0.7605 - val_loss: 0.2704 - val_accuracy: 0.9003\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 0.6129 - accuracy: 0.7711 - val_loss: 0.2762 - val_accuracy: 0.8986\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 7s 107ms/step - loss: 0.5677 - accuracy: 0.7848 - val_loss: 0.2812 - val_accuracy: 0.8969\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 0.5403 - accuracy: 0.8051 - val_loss: 0.2730 - val_accuracy: 0.9001\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 7s 108ms/step - loss: 0.5030 - accuracy: 0.8213 - val_loss: 0.2798 - val_accuracy: 0.9008\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 7s 107ms/step - loss: 0.4709 - accuracy: 0.8248 - val_loss: 0.2775 - val_accuracy: 0.9015\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.4493 - accuracy: 0.8377 - val_loss: 0.2860 - val_accuracy: 0.9008\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.4129 - accuracy: 0.8517 - val_loss: 0.2898 - val_accuracy: 0.9041\n",
      "Duration: 0:01:08.909320\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10a1fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 8s 104ms/step - loss: 0.8499 - accuracy: 0.6898 - val_loss: 0.2875 - val_accuracy: 0.8884\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.7251 - accuracy: 0.7303 - val_loss: 0.2872 - val_accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.6384 - accuracy: 0.7633 - val_loss: 0.2801 - val_accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.5891 - accuracy: 0.7846 - val_loss: 0.2841 - val_accuracy: 0.8931\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 7s 103ms/step - loss: 0.5634 - accuracy: 0.7968 - val_loss: 0.2767 - val_accuracy: 0.8978\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.5130 - accuracy: 0.8072 - val_loss: 0.2962 - val_accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 7s 104ms/step - loss: 0.5048 - accuracy: 0.8140 - val_loss: 0.2922 - val_accuracy: 0.8915\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.4709 - accuracy: 0.8267 - val_loss: 0.2878 - val_accuracy: 0.8977\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.4225 - accuracy: 0.8430 - val_loss: 0.2986 - val_accuracy: 0.9001\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 7s 105ms/step - loss: 0.4131 - accuracy: 0.8550 - val_loss: 0.2822 - val_accuracy: 0.8988\n",
      "Duration: 0:01:12.961838\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14517ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 8s 103ms/step - loss: 0.8137 - accuracy: 0.7078 - val_loss: 0.2871 - val_accuracy: 0.8912\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 8s 103ms/step - loss: 0.6637 - accuracy: 0.7590 - val_loss: 0.2838 - val_accuracy: 0.8927\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.5908 - accuracy: 0.7838 - val_loss: 0.2720 - val_accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 8s 105ms/step - loss: 0.5585 - accuracy: 0.7971 - val_loss: 0.2727 - val_accuracy: 0.8966\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.5194 - accuracy: 0.8090 - val_loss: 0.2795 - val_accuracy: 0.8946\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.4974 - accuracy: 0.8183 - val_loss: 0.2751 - val_accuracy: 0.9017\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.4595 - accuracy: 0.8313 - val_loss: 0.2725 - val_accuracy: 0.9027\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.4209 - accuracy: 0.8496 - val_loss: 0.2843 - val_accuracy: 0.9025\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 8s 104ms/step - loss: 0.4059 - accuracy: 0.8574 - val_loss: 0.2834 - val_accuracy: 0.9019\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 8s 103ms/step - loss: 0.3649 - accuracy: 0.8727 - val_loss: 0.2916 - val_accuracy: 0.9039\n",
      "Duration: 0:01:18.204326\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef9d752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 9s 102ms/step - loss: 0.7589 - accuracy: 0.7267 - val_loss: 0.2704 - val_accuracy: 0.8986\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.6134 - accuracy: 0.7747 - val_loss: 0.2923 - val_accuracy: 0.8902\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 0.5466 - accuracy: 0.7945 - val_loss: 0.2904 - val_accuracy: 0.8919\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.5262 - accuracy: 0.8094 - val_loss: 0.2821 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4813 - accuracy: 0.8227 - val_loss: 0.2777 - val_accuracy: 0.9011\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.4507 - accuracy: 0.8429 - val_loss: 0.2741 - val_accuracy: 0.8994\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.4216 - accuracy: 0.8488 - val_loss: 0.2866 - val_accuracy: 0.9025\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 0.4122 - accuracy: 0.8535 - val_loss: 0.2847 - val_accuracy: 0.9006\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 0.3921 - accuracy: 0.8655 - val_loss: 0.2868 - val_accuracy: 0.9025\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 0.3598 - accuracy: 0.8731 - val_loss: 0.2956 - val_accuracy: 0.8989\n",
      "Duration: 0:01:21.792878\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8866d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 9s 100ms/step - loss: 0.7072 - accuracy: 0.7447 - val_loss: 0.2911 - val_accuracy: 0.8945\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 8s 99ms/step - loss: 0.5615 - accuracy: 0.7869 - val_loss: 0.2838 - val_accuracy: 0.8944\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.5274 - accuracy: 0.8081 - val_loss: 0.2779 - val_accuracy: 0.8969\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.4921 - accuracy: 0.8221 - val_loss: 0.2783 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.4590 - accuracy: 0.8324 - val_loss: 0.2758 - val_accuracy: 0.9014\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 8s 99ms/step - loss: 0.4391 - accuracy: 0.8456 - val_loss: 0.2848 - val_accuracy: 0.8977\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.4018 - accuracy: 0.8557 - val_loss: 0.2889 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 10s 115ms/step - loss: 0.3730 - accuracy: 0.8664 - val_loss: 0.2910 - val_accuracy: 0.9026\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 9s 108ms/step - loss: 0.3426 - accuracy: 0.8763 - val_loss: 0.2928 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 8s 99ms/step - loss: 0.3255 - accuracy: 0.8838 - val_loss: 0.2844 - val_accuracy: 0.9026\n",
      "Duration: 0:01:26.234686\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20094079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.6693 - accuracy: 0.7557 - val_loss: 0.2806 - val_accuracy: 0.8905\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 9s 97ms/step - loss: 0.5479 - accuracy: 0.7998 - val_loss: 0.2883 - val_accuracy: 0.8898\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.4960 - accuracy: 0.8202 - val_loss: 0.2828 - val_accuracy: 0.8939\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.4580 - accuracy: 0.8336 - val_loss: 0.2822 - val_accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.4436 - accuracy: 0.8426 - val_loss: 0.2773 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.4047 - accuracy: 0.8533 - val_loss: 0.3104 - val_accuracy: 0.8922\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.3922 - accuracy: 0.8599 - val_loss: 0.2882 - val_accuracy: 0.8990\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.3638 - accuracy: 0.8702 - val_loss: 0.2846 - val_accuracy: 0.9016\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.3425 - accuracy: 0.8836 - val_loss: 0.3082 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 9s 96ms/step - loss: 0.3286 - accuracy: 0.8886 - val_loss: 0.2887 - val_accuracy: 0.8998\n",
      "Duration: 0:01:27.772026\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86a5bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 10s 95ms/step - loss: 0.6324 - accuracy: 0.7717 - val_loss: 0.2835 - val_accuracy: 0.8935\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.5206 - accuracy: 0.8111 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 10s 100ms/step - loss: 0.4709 - accuracy: 0.8310 - val_loss: 0.2804 - val_accuracy: 0.8946\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 9s 93ms/step - loss: 0.4244 - accuracy: 0.8474 - val_loss: 0.2728 - val_accuracy: 0.9019\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 9s 93ms/step - loss: 0.3976 - accuracy: 0.8577 - val_loss: 0.2785 - val_accuracy: 0.9021\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.3837 - accuracy: 0.8655 - val_loss: 0.2782 - val_accuracy: 0.9013\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 0.3456 - accuracy: 0.8778 - val_loss: 0.3006 - val_accuracy: 0.8933\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 9s 97ms/step - loss: 0.3201 - accuracy: 0.8891 - val_loss: 0.2895 - val_accuracy: 0.9005\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 9s 96ms/step - loss: 0.3087 - accuracy: 0.8977 - val_loss: 0.3402 - val_accuracy: 0.8903\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 9s 94ms/step - loss: 0.2852 - accuracy: 0.9018 - val_loss: 0.2959 - val_accuracy: 0.9016\n",
      "Duration: 0:01:31.723028\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff39111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 10s 94ms/step - loss: 0.6036 - accuracy: 0.7881 - val_loss: 0.2780 - val_accuracy: 0.8958\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 9s 91ms/step - loss: 0.4902 - accuracy: 0.8217 - val_loss: 0.2789 - val_accuracy: 0.8999\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 9s 92ms/step - loss: 0.4384 - accuracy: 0.8430 - val_loss: 0.2806 - val_accuracy: 0.8933\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 9s 92ms/step - loss: 0.4033 - accuracy: 0.8565 - val_loss: 0.2874 - val_accuracy: 0.8983\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 9s 92ms/step - loss: 0.3828 - accuracy: 0.8639 - val_loss: 0.2905 - val_accuracy: 0.8984\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.3676 - accuracy: 0.8715 - val_loss: 0.2821 - val_accuracy: 0.9019\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 10s 97ms/step - loss: 0.3397 - accuracy: 0.8807 - val_loss: 0.2847 - val_accuracy: 0.9011\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 9s 93ms/step - loss: 0.3107 - accuracy: 0.8937 - val_loss: 0.2880 - val_accuracy: 0.9034\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 9s 94ms/step - loss: 0.2909 - accuracy: 0.9020 - val_loss: 0.2877 - val_accuracy: 0.9049\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 10s 96ms/step - loss: 0.2696 - accuracy: 0.9070 - val_loss: 0.2933 - val_accuracy: 0.9039\n",
      "Duration: 0:01:34.934767\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5efc9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 11s 90ms/step - loss: 0.5467 - accuracy: 0.8004 - val_loss: 0.2810 - val_accuracy: 0.8983\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.4505 - accuracy: 0.8384 - val_loss: 0.2879 - val_accuracy: 0.8951\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.4235 - accuracy: 0.8537 - val_loss: 0.2790 - val_accuracy: 0.8994\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.3835 - accuracy: 0.8644 - val_loss: 0.2791 - val_accuracy: 0.8965\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.3557 - accuracy: 0.8751 - val_loss: 0.3057 - val_accuracy: 0.8895\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.3303 - accuracy: 0.8837 - val_loss: 0.3084 - val_accuracy: 0.8942\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.3100 - accuracy: 0.8891 - val_loss: 0.2914 - val_accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.2914 - accuracy: 0.8976 - val_loss: 0.3635 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.2766 - accuracy: 0.9056 - val_loss: 0.2973 - val_accuracy: 0.9009\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.2676 - accuracy: 0.9117 - val_loss: 0.3357 - val_accuracy: 0.8921\n",
      "Duration: 0:01:37.988487\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_se[n].fit_model(image_sets_se[n],label_sets_se[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "825c1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_may_se_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_se_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_se_e1\"\n",
    "new_model_se_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_may_se_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_se:\n",
    "    model.save(new_model_se_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95d86000",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del se_values\n",
    "    del top_images_by_se\n",
    "    del top_labels_by_se\n",
    "    del image_sets_se\n",
    "    del label_sets_se\n",
    "    del models_se\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcf7c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349909"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11198aa3",
   "metadata": {},
   "source": [
    "## Training guided by Random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0eca574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "#save_dir = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/random_values.npy\"\n",
    "save_dir = \"D:/guided-retraining/data/\"+dataset+\"/random_values.npy\"\n",
    "\n",
    "\n",
    "random_indexes = np.load(save_dir)[len(x_train):] \n",
    "print(len(random_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a735c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d13ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining top n images by random values\n",
    "top_images_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),x_adversary_training)\n",
    "top_labels_by_random = utils.get_x_of_indexes(list(np.flip(np.argsort(random_indexes))),y_adversary_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1209ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_random = []\n",
    "label_sets_random = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_random)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_random)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_random)%m))\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m+(len(top_images_by_random)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_random_n = np.array(top_images_by_random[:n+m])\n",
    "        top_labels_by_random_n = np.array(top_labels_by_random[:n+m])\n",
    "    image_sets_random.append(top_images_by_random_n)\n",
    "    label_sets_random.append(top_labels_by_random_n)\n",
    "    print(len(top_images_by_random_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ed47a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f03e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_random = []\n",
    "for i in range(len(label_sets_random)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_random.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14912c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 5s 851ms/step - loss: 0.7111 - accuracy: 0.7824 - val_loss: 0.2652 - val_accuracy: 0.9057\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 4s 822ms/step - loss: 0.5227 - accuracy: 0.8176 - val_loss: 0.2576 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 5s 890ms/step - loss: 0.4604 - accuracy: 0.8471 - val_loss: 0.2636 - val_accuracy: 0.9074\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 4s 870ms/step - loss: 0.4168 - accuracy: 0.8559 - val_loss: 0.2781 - val_accuracy: 0.9019\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 5s 887ms/step - loss: 0.3861 - accuracy: 0.8559 - val_loss: 0.2714 - val_accuracy: 0.9034\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 5s 893ms/step - loss: 0.3553 - accuracy: 0.8559 - val_loss: 0.2841 - val_accuracy: 0.8992\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 4s 828ms/step - loss: 0.3095 - accuracy: 0.8824 - val_loss: 0.2844 - val_accuracy: 0.9009\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 4s 865ms/step - loss: 0.3550 - accuracy: 0.8412 - val_loss: 0.3324 - val_accuracy: 0.8840\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 4s 846ms/step - loss: 0.2638 - accuracy: 0.8853 - val_loss: 0.2942 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 4s 863ms/step - loss: 0.3026 - accuracy: 0.8676 - val_loss: 0.2895 - val_accuracy: 0.9002\n",
      "Duration: 0:00:44.762657\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f28e27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 492ms/step - loss: 0.6658 - accuracy: 0.7779 - val_loss: 0.2640 - val_accuracy: 0.9060\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 5s 474ms/step - loss: 0.5346 - accuracy: 0.8088 - val_loss: 0.2619 - val_accuracy: 0.9014\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 5s 481ms/step - loss: 0.4868 - accuracy: 0.8191 - val_loss: 0.2779 - val_accuracy: 0.9019\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 5s 477ms/step - loss: 0.4697 - accuracy: 0.8162 - val_loss: 0.2797 - val_accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 5s 474ms/step - loss: 0.4252 - accuracy: 0.8324 - val_loss: 0.2752 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 5s 489ms/step - loss: 0.3853 - accuracy: 0.8368 - val_loss: 0.2785 - val_accuracy: 0.8967\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 5s 484ms/step - loss: 0.3724 - accuracy: 0.8544 - val_loss: 0.2756 - val_accuracy: 0.9033\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 5s 474ms/step - loss: 0.3433 - accuracy: 0.8868 - val_loss: 0.2823 - val_accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 5s 482ms/step - loss: 0.3463 - accuracy: 0.8618 - val_loss: 0.2931 - val_accuracy: 0.9001\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 5s 488ms/step - loss: 0.3253 - accuracy: 0.8706 - val_loss: 0.2964 - val_accuracy: 0.9009\n",
      "Duration: 0:00:50.039002\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9f5601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 6s 356ms/step - loss: 0.6825 - accuracy: 0.7873 - val_loss: 0.2594 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 5s 343ms/step - loss: 0.5504 - accuracy: 0.8088 - val_loss: 0.2717 - val_accuracy: 0.8979\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 5s 338ms/step - loss: 0.5068 - accuracy: 0.8167 - val_loss: 0.2657 - val_accuracy: 0.9015\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.4632 - accuracy: 0.8314 - val_loss: 0.2807 - val_accuracy: 0.8981\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 5s 346ms/step - loss: 0.4029 - accuracy: 0.8549 - val_loss: 0.2730 - val_accuracy: 0.9024\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.3849 - accuracy: 0.8471 - val_loss: 0.3017 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 5s 348ms/step - loss: 0.3619 - accuracy: 0.8559 - val_loss: 0.2776 - val_accuracy: 0.9040\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.3299 - accuracy: 0.8676 - val_loss: 0.2931 - val_accuracy: 0.9002\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 5s 345ms/step - loss: 0.3404 - accuracy: 0.8725 - val_loss: 0.2993 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 5s 339ms/step - loss: 0.3124 - accuracy: 0.8814 - val_loss: 0.2992 - val_accuracy: 0.9010\n",
      "Duration: 0:00:53.635461\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "383e5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 7s 270ms/step - loss: 0.6771 - accuracy: 0.7699 - val_loss: 0.2765 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 6s 266ms/step - loss: 0.5521 - accuracy: 0.8051 - val_loss: 0.2830 - val_accuracy: 0.8932\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 5s 254ms/step - loss: 0.4845 - accuracy: 0.8243 - val_loss: 0.2773 - val_accuracy: 0.8959\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 5s 255ms/step - loss: 0.4444 - accuracy: 0.8404 - val_loss: 0.2842 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 6s 260ms/step - loss: 0.3972 - accuracy: 0.8537 - val_loss: 0.2871 - val_accuracy: 0.8919\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.3885 - accuracy: 0.8632 - val_loss: 0.2921 - val_accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 6s 261ms/step - loss: 0.3728 - accuracy: 0.8676 - val_loss: 0.2910 - val_accuracy: 0.8941\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 5s 256ms/step - loss: 0.3444 - accuracy: 0.8699 - val_loss: 0.3119 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 6s 289ms/step - loss: 0.3297 - accuracy: 0.8838 - val_loss: 0.3087 - val_accuracy: 0.8934\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 7s 326ms/step - loss: 0.3134 - accuracy: 0.8860 - val_loss: 0.3069 - val_accuracy: 0.8972\n",
      "Duration: 0:00:58.448101\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc5c7384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 9s 270ms/step - loss: 0.6848 - accuracy: 0.7653 - val_loss: 0.2745 - val_accuracy: 0.9011\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 6s 245ms/step - loss: 0.5615 - accuracy: 0.8059 - val_loss: 0.2766 - val_accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 7s 250ms/step - loss: 0.4773 - accuracy: 0.8300 - val_loss: 0.2780 - val_accuracy: 0.8951\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 7s 252ms/step - loss: 0.4476 - accuracy: 0.8318 - val_loss: 0.2725 - val_accuracy: 0.8960\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 7s 254ms/step - loss: 0.4065 - accuracy: 0.8476 - val_loss: 0.2967 - val_accuracy: 0.8886\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 7s 254ms/step - loss: 0.3926 - accuracy: 0.8500 - val_loss: 0.2934 - val_accuracy: 0.8916\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 0.3808 - accuracy: 0.8688 - val_loss: 0.2811 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 6s 239ms/step - loss: 0.3632 - accuracy: 0.8565 - val_loss: 0.2854 - val_accuracy: 0.8970\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 6s 246ms/step - loss: 0.3316 - accuracy: 0.8765 - val_loss: 0.2989 - val_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 7s 255ms/step - loss: 0.3158 - accuracy: 0.8882 - val_loss: 0.3025 - val_accuracy: 0.8956\n",
      "Duration: 0:01:07.774274\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0481a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 8s 231ms/step - loss: 0.6578 - accuracy: 0.7784 - val_loss: 0.2678 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 0.5178 - accuracy: 0.8147 - val_loss: 0.2776 - val_accuracy: 0.8931\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 0.4956 - accuracy: 0.8333 - val_loss: 0.2693 - val_accuracy: 0.8991\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 0.4535 - accuracy: 0.8343 - val_loss: 0.2711 - val_accuracy: 0.8987\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 0.3993 - accuracy: 0.8529 - val_loss: 0.2697 - val_accuracy: 0.8996\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 0.4073 - accuracy: 0.8529 - val_loss: 0.2687 - val_accuracy: 0.8993\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 0.3708 - accuracy: 0.8559 - val_loss: 0.2774 - val_accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.3639 - accuracy: 0.8691 - val_loss: 0.2889 - val_accuracy: 0.8931\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 0.3450 - accuracy: 0.8784 - val_loss: 0.2849 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 0.3113 - accuracy: 0.8882 - val_loss: 0.3058 - val_accuracy: 0.8947\n",
      "Duration: 0:01:12.140862\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ba8de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 9s 208ms/step - loss: 0.6595 - accuracy: 0.7807 - val_loss: 0.3031 - val_accuracy: 0.8844\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7s 198ms/step - loss: 0.5139 - accuracy: 0.8134 - val_loss: 0.2773 - val_accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 7s 200ms/step - loss: 0.4696 - accuracy: 0.8374 - val_loss: 0.2819 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 7s 198ms/step - loss: 0.4308 - accuracy: 0.8450 - val_loss: 0.2774 - val_accuracy: 0.8957\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 8s 203ms/step - loss: 0.4001 - accuracy: 0.8588 - val_loss: 0.2848 - val_accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.3960 - accuracy: 0.8559 - val_loss: 0.2837 - val_accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 0.3691 - accuracy: 0.8697 - val_loss: 0.2951 - val_accuracy: 0.8959\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 8s 202ms/step - loss: 0.3609 - accuracy: 0.8782 - val_loss: 0.2880 - val_accuracy: 0.8941\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 8s 206ms/step - loss: 0.3317 - accuracy: 0.8832 - val_loss: 0.2931 - val_accuracy: 0.8986\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 8s 214ms/step - loss: 0.3210 - accuracy: 0.8899 - val_loss: 0.3028 - val_accuracy: 0.8967\n",
      "Duration: 0:01:17.885899\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "543c4799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 10s 195ms/step - loss: 0.6386 - accuracy: 0.7757 - val_loss: 0.2827 - val_accuracy: 0.8971\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 8s 189ms/step - loss: 0.5393 - accuracy: 0.8099 - val_loss: 0.2823 - val_accuracy: 0.8899\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 8s 189ms/step - loss: 0.4650 - accuracy: 0.8401 - val_loss: 0.2805 - val_accuracy: 0.8923\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 8s 193ms/step - loss: 0.4510 - accuracy: 0.8313 - val_loss: 0.2877 - val_accuracy: 0.8926\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 8s 189ms/step - loss: 0.4160 - accuracy: 0.8511 - val_loss: 0.2787 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 8s 193ms/step - loss: 0.3882 - accuracy: 0.8592 - val_loss: 0.2930 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 8s 190ms/step - loss: 0.3772 - accuracy: 0.8588 - val_loss: 0.2792 - val_accuracy: 0.8998\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 8s 190ms/step - loss: 0.3422 - accuracy: 0.8732 - val_loss: 0.2888 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 9s 208ms/step - loss: 0.3329 - accuracy: 0.8798 - val_loss: 0.2948 - val_accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 8s 197ms/step - loss: 0.3208 - accuracy: 0.8827 - val_loss: 0.2941 - val_accuracy: 0.8972\n",
      "Duration: 0:01:23.523994\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd83ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 11s 191ms/step - loss: 0.6252 - accuracy: 0.7804 - val_loss: 0.2777 - val_accuracy: 0.8919\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 9s 182ms/step - loss: 0.4967 - accuracy: 0.8229 - val_loss: 0.2702 - val_accuracy: 0.8976\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 9s 192ms/step - loss: 0.4361 - accuracy: 0.8412 - val_loss: 0.2787 - val_accuracy: 0.8989\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 9s 190ms/step - loss: 0.4185 - accuracy: 0.8546 - val_loss: 0.2870 - val_accuracy: 0.8924\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 9s 181ms/step - loss: 0.3922 - accuracy: 0.8592 - val_loss: 0.2755 - val_accuracy: 0.8974\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.3717 - accuracy: 0.8758 - val_loss: 0.2856 - val_accuracy: 0.8979\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.3718 - accuracy: 0.8709 - val_loss: 0.2836 - val_accuracy: 0.8971\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 8s 166ms/step - loss: 0.3435 - accuracy: 0.8771 - val_loss: 0.2873 - val_accuracy: 0.8959\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.3184 - accuracy: 0.8850 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 0.3190 - accuracy: 0.8882 - val_loss: 0.2970 - val_accuracy: 0.8986\n",
      "Duration: 0:01:25.169920\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "321027f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 9s 156ms/step - loss: 0.6294 - accuracy: 0.7850 - val_loss: 0.2749 - val_accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 8s 158ms/step - loss: 0.4969 - accuracy: 0.8165 - val_loss: 0.3076 - val_accuracy: 0.8799\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 8s 153ms/step - loss: 0.4461 - accuracy: 0.8359 - val_loss: 0.2706 - val_accuracy: 0.8980\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 0.4282 - accuracy: 0.8432 - val_loss: 0.2778 - val_accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 8s 152ms/step - loss: 0.3727 - accuracy: 0.8588 - val_loss: 0.2825 - val_accuracy: 0.9019\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 8s 159ms/step - loss: 0.3810 - accuracy: 0.8621 - val_loss: 0.2850 - val_accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 8s 154ms/step - loss: 0.3634 - accuracy: 0.8674 - val_loss: 0.2796 - val_accuracy: 0.8992\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 8s 155ms/step - loss: 0.3436 - accuracy: 0.8774 - val_loss: 0.2958 - val_accuracy: 0.8921\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 8s 156ms/step - loss: 0.3271 - accuracy: 0.8856 - val_loss: 0.3010 - val_accuracy: 0.8954\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 8s 157ms/step - loss: 0.3009 - accuracy: 0.8903 - val_loss: 0.2908 - val_accuracy: 0.9026\n",
      "Duration: 0:01:23.927531\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "453e04da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 10s 152ms/step - loss: 0.6213 - accuracy: 0.7909 - val_loss: 0.2769 - val_accuracy: 0.8952\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 9s 152ms/step - loss: 0.4887 - accuracy: 0.8211 - val_loss: 0.2861 - val_accuracy: 0.8903\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 9s 151ms/step - loss: 0.4442 - accuracy: 0.8393 - val_loss: 0.2756 - val_accuracy: 0.8953\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 9s 148ms/step - loss: 0.4253 - accuracy: 0.8500 - val_loss: 0.2779 - val_accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 9s 151ms/step - loss: 0.3831 - accuracy: 0.8660 - val_loss: 0.2866 - val_accuracy: 0.8946\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 9s 149ms/step - loss: 0.3701 - accuracy: 0.8674 - val_loss: 0.2850 - val_accuracy: 0.8959\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 9s 147ms/step - loss: 0.3653 - accuracy: 0.8757 - val_loss: 0.2924 - val_accuracy: 0.8975\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 9s 147ms/step - loss: 0.3317 - accuracy: 0.8791 - val_loss: 0.2866 - val_accuracy: 0.8982\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 9s 149ms/step - loss: 0.3300 - accuracy: 0.8842 - val_loss: 0.3026 - val_accuracy: 0.8941\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 9s 151ms/step - loss: 0.2935 - accuracy: 0.8933 - val_loss: 0.3013 - val_accuracy: 0.8994\n",
      "Duration: 0:01:28.498723\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bd63529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 10s 146ms/step - loss: 0.5906 - accuracy: 0.7924 - val_loss: 0.2752 - val_accuracy: 0.8985\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 9s 143ms/step - loss: 0.4790 - accuracy: 0.8282 - val_loss: 0.2762 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 9s 143ms/step - loss: 0.4399 - accuracy: 0.8431 - val_loss: 0.2766 - val_accuracy: 0.8979\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 9s 145ms/step - loss: 0.4140 - accuracy: 0.8534 - val_loss: 0.2699 - val_accuracy: 0.8999\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 9s 146ms/step - loss: 0.3777 - accuracy: 0.8613 - val_loss: 0.2710 - val_accuracy: 0.9028\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 9s 140ms/step - loss: 0.3817 - accuracy: 0.8654 - val_loss: 0.2808 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 9s 139ms/step - loss: 0.3484 - accuracy: 0.8750 - val_loss: 0.2911 - val_accuracy: 0.8948\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.3184 - accuracy: 0.8819 - val_loss: 0.2883 - val_accuracy: 0.9004\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.3222 - accuracy: 0.8897 - val_loss: 0.2857 - val_accuracy: 0.8989\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 9s 143ms/step - loss: 0.2823 - accuracy: 0.8985 - val_loss: 0.3074 - val_accuracy: 0.8949\n",
      "Duration: 0:01:31.668672\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c990f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 11s 140ms/step - loss: 0.6082 - accuracy: 0.7885 - val_loss: 0.2831 - val_accuracy: 0.8891\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 10s 138ms/step - loss: 0.4884 - accuracy: 0.8283 - val_loss: 0.2779 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.4317 - accuracy: 0.8416 - val_loss: 0.2789 - val_accuracy: 0.8966\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.4133 - accuracy: 0.8493 - val_loss: 0.2935 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.3847 - accuracy: 0.8586 - val_loss: 0.2795 - val_accuracy: 0.8973\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.3613 - accuracy: 0.8631 - val_loss: 0.2845 - val_accuracy: 0.8963\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.3383 - accuracy: 0.8781 - val_loss: 0.3022 - val_accuracy: 0.8966\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 10s 138ms/step - loss: 0.3090 - accuracy: 0.8864 - val_loss: 0.3056 - val_accuracy: 0.8965\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 10s 138ms/step - loss: 0.3068 - accuracy: 0.8914 - val_loss: 0.2949 - val_accuracy: 0.8937\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.2819 - accuracy: 0.9029 - val_loss: 0.3054 - val_accuracy: 0.8937\n",
      "Duration: 0:01:36.386422\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8018c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 11s 132ms/step - loss: 0.5792 - accuracy: 0.7947 - val_loss: 0.2828 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.4774 - accuracy: 0.8311 - val_loss: 0.2793 - val_accuracy: 0.8939\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.4342 - accuracy: 0.8458 - val_loss: 0.2907 - val_accuracy: 0.8914\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 10s 132ms/step - loss: 0.4084 - accuracy: 0.8563 - val_loss: 0.3012 - val_accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 10s 135ms/step - loss: 0.3846 - accuracy: 0.8624 - val_loss: 0.2938 - val_accuracy: 0.8957\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 10s 133ms/step - loss: 0.3521 - accuracy: 0.8731 - val_loss: 0.3052 - val_accuracy: 0.8943\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 10s 137ms/step - loss: 0.3387 - accuracy: 0.8771 - val_loss: 0.2966 - val_accuracy: 0.8958\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.3302 - accuracy: 0.8861 - val_loss: 0.2863 - val_accuracy: 0.9016\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.2919 - accuracy: 0.9013 - val_loss: 0.3076 - val_accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 10s 133ms/step - loss: 0.2828 - accuracy: 0.9008 - val_loss: 0.3121 - val_accuracy: 0.9016\n",
      "Duration: 0:01:39.830309\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33202163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 11s 132ms/step - loss: 0.5804 - accuracy: 0.7963 - val_loss: 0.2822 - val_accuracy: 0.8914\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.4726 - accuracy: 0.8296 - val_loss: 0.2782 - val_accuracy: 0.8981\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 0.4355 - accuracy: 0.8437 - val_loss: 0.2751 - val_accuracy: 0.8955\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3956 - accuracy: 0.8649 - val_loss: 0.2795 - val_accuracy: 0.8974\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3844 - accuracy: 0.8641 - val_loss: 0.2875 - val_accuracy: 0.8925\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3541 - accuracy: 0.8753 - val_loss: 0.2835 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 10s 130ms/step - loss: 0.3321 - accuracy: 0.8804 - val_loss: 0.2870 - val_accuracy: 0.8981\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.3153 - accuracy: 0.8875 - val_loss: 0.2887 - val_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3032 - accuracy: 0.8943 - val_loss: 0.2841 - val_accuracy: 0.9014\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.2806 - accuracy: 0.9010 - val_loss: 0.3164 - val_accuracy: 0.8958\n",
      "Duration: 0:01:42.514040\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f220f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 11s 126ms/step - loss: 0.5713 - accuracy: 0.7980 - val_loss: 0.2817 - val_accuracy: 0.8909\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 10s 123ms/step - loss: 0.4729 - accuracy: 0.8283 - val_loss: 0.2694 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.4226 - accuracy: 0.8454 - val_loss: 0.2840 - val_accuracy: 0.8930\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 10s 121ms/step - loss: 0.3898 - accuracy: 0.8607 - val_loss: 0.2777 - val_accuracy: 0.8976\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 10s 121ms/step - loss: 0.3644 - accuracy: 0.8667 - val_loss: 0.2819 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 10s 121ms/step - loss: 0.3512 - accuracy: 0.8820 - val_loss: 0.2773 - val_accuracy: 0.9009\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 10s 114ms/step - loss: 0.3314 - accuracy: 0.8746 - val_loss: 0.2875 - val_accuracy: 0.9011\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 10s 113ms/step - loss: 0.3088 - accuracy: 0.8923 - val_loss: 0.3090 - val_accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 10s 113ms/step - loss: 0.3026 - accuracy: 0.8976 - val_loss: 0.3066 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 10s 113ms/step - loss: 0.2762 - accuracy: 0.9064 - val_loss: 0.3093 - val_accuracy: 0.9017\n",
      "Duration: 0:01:41.210638\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f47aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 11s 112ms/step - loss: 0.5541 - accuracy: 0.8028 - val_loss: 0.2656 - val_accuracy: 0.9004\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 10s 112ms/step - loss: 0.4463 - accuracy: 0.8370 - val_loss: 0.2939 - val_accuracy: 0.8904\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 10s 113ms/step - loss: 0.4134 - accuracy: 0.8514 - val_loss: 0.2882 - val_accuracy: 0.8911\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 10s 113ms/step - loss: 0.3819 - accuracy: 0.8588 - val_loss: 0.3042 - val_accuracy: 0.8891\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 10s 115ms/step - loss: 0.3642 - accuracy: 0.8671 - val_loss: 0.2907 - val_accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 10s 112ms/step - loss: 0.3376 - accuracy: 0.8775 - val_loss: 0.2890 - val_accuracy: 0.9002\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 10s 109ms/step - loss: 0.3397 - accuracy: 0.8834 - val_loss: 0.2954 - val_accuracy: 0.8981\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 10s 110ms/step - loss: 0.3054 - accuracy: 0.8952 - val_loss: 0.3047 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 10s 108ms/step - loss: 0.2876 - accuracy: 0.9007 - val_loss: 0.2981 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 10s 109ms/step - loss: 0.2631 - accuracy: 0.9076 - val_loss: 0.3216 - val_accuracy: 0.8938\n",
      "Duration: 0:01:41.810550\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2092ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 11s 107ms/step - loss: 0.5508 - accuracy: 0.8059 - val_loss: 0.2734 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 10s 107ms/step - loss: 0.4662 - accuracy: 0.8330 - val_loss: 0.2738 - val_accuracy: 0.8991\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 10s 107ms/step - loss: 0.4170 - accuracy: 0.8515 - val_loss: 0.2735 - val_accuracy: 0.8971\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 10s 107ms/step - loss: 0.3806 - accuracy: 0.8660 - val_loss: 0.2830 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 10s 108ms/step - loss: 0.3622 - accuracy: 0.8699 - val_loss: 0.2769 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 10s 110ms/step - loss: 0.3388 - accuracy: 0.8807 - val_loss: 0.2919 - val_accuracy: 0.8978\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 10s 106ms/step - loss: 0.3012 - accuracy: 0.8959 - val_loss: 0.2969 - val_accuracy: 0.8964\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 10s 107ms/step - loss: 0.3089 - accuracy: 0.8900 - val_loss: 0.3224 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 10s 107ms/step - loss: 0.2772 - accuracy: 0.9016 - val_loss: 0.3098 - val_accuracy: 0.9014\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 10s 108ms/step - loss: 0.2631 - accuracy: 0.9116 - val_loss: 0.3108 - val_accuracy: 0.9037\n",
      "Duration: 0:01:43.509223\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7e42b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 12s 107ms/step - loss: 0.5596 - accuracy: 0.8014 - val_loss: 0.2902 - val_accuracy: 0.8903\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 11s 107ms/step - loss: 0.4595 - accuracy: 0.8367 - val_loss: 0.2814 - val_accuracy: 0.8932\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 11s 107ms/step - loss: 0.4225 - accuracy: 0.8498 - val_loss: 0.2761 - val_accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 11s 107ms/step - loss: 0.3900 - accuracy: 0.8601 - val_loss: 0.2820 - val_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 0.3637 - accuracy: 0.8732 - val_loss: 0.2776 - val_accuracy: 0.9009\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 11s 107ms/step - loss: 0.3478 - accuracy: 0.8793 - val_loss: 0.2868 - val_accuracy: 0.8998\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 11s 105ms/step - loss: 0.3052 - accuracy: 0.8912 - val_loss: 0.2870 - val_accuracy: 0.9034\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 11s 106ms/step - loss: 0.2954 - accuracy: 0.8946 - val_loss: 0.2937 - val_accuracy: 0.9013\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 10s 103ms/step - loss: 0.2784 - accuracy: 0.9060 - val_loss: 0.3037 - val_accuracy: 0.8965\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 11s 106ms/step - loss: 0.2512 - accuracy: 0.9133 - val_loss: 0.3145 - val_accuracy: 0.9001\n",
      "Duration: 0:01:48.393601\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2884c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 12s 101ms/step - loss: 0.5343 - accuracy: 0.8087 - val_loss: 0.2763 - val_accuracy: 0.8976\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.4421 - accuracy: 0.8430 - val_loss: 0.3056 - val_accuracy: 0.8899\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.3991 - accuracy: 0.8563 - val_loss: 0.2930 - val_accuracy: 0.8961\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.3800 - accuracy: 0.8644 - val_loss: 0.2920 - val_accuracy: 0.8959\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.3509 - accuracy: 0.8777 - val_loss: 0.2782 - val_accuracy: 0.9019\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.3222 - accuracy: 0.8856 - val_loss: 0.3183 - val_accuracy: 0.8947\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.3035 - accuracy: 0.8921 - val_loss: 0.3006 - val_accuracy: 0.9002\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.2865 - accuracy: 0.9027 - val_loss: 0.3005 - val_accuracy: 0.8986\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2596 - accuracy: 0.9077 - val_loss: 0.3428 - val_accuracy: 0.8936\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2478 - accuracy: 0.9197 - val_loss: 0.2925 - val_accuracy: 0.9009\n",
      "Duration: 0:01:53.355510\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_random[n].fit_model(image_sets_random[n],label_sets_random[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24dc2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_random_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_random_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C2/\"+dataset+\"_model_c2_aug_random_e1\"\n",
    "new_model_random_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_random_e1\"\n",
    "\n",
    "i=0\n",
    "\n",
    "for model in models_random:\n",
    "    model.save(new_model_random_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85078e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del random_indexes\n",
    "    del top_images_by_random\n",
    "    del top_labels_by_random\n",
    "    del image_sets_random\n",
    "    del label_sets_random\n",
    "    del models_random\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "deac767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a4c9d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405127"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a54b05",
   "metadata": {},
   "source": [
    "## Training guided by NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e53f2bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6999\n"
     ]
    }
   ],
   "source": [
    "# NC\n",
    "nc_values = []\n",
    "for i in range(1,17):\n",
    "    #save_dir = \"C:/Users/fjdur/Desktop/upc/project_notebooks/github_project/DL_notebooks/NC_values/nc_values_\"+str(i)+\".npy\"\n",
    "    #save_dir = \"C:/Users/fjdurlop/Documents/upc/upc-july/data/\"+dataset+\"/\"+dataset+\"_nc_values_\"+str(i)+\".npy\"\n",
    "    save_dir = \"D:/guided-retraining/data/\"+dataset+\"/\"+dataset+\"_nc_values_\"+str(i)+\".npy\"\n",
    "\n",
    "    #print(save_dir_rand)\n",
    "    tmp_values = np.load(save_dir)\n",
    "    #print(tmp_values.shape)\n",
    "    nc_values = np.append(nc_values,tmp_values)\n",
    "    \n",
    "nc_values = nc_values[len(x_train):] \n",
    "print(len(nc_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "637de522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6999,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "024f3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_images_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),x_adversary_training)\n",
    "top_labels_by_nc = utils.get_x_of_indexes(list(np.flip(np.argsort(nc_values))),y_adversary_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7490c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "0  ->  340\n",
      "340\n",
      "1 :\n",
      "0  ->  680\n",
      "680\n",
      "2 :\n",
      "0  ->  1020\n",
      "1020\n",
      "3 :\n",
      "0  ->  1360\n",
      "1360\n",
      "4 :\n",
      "0  ->  1700\n",
      "1700\n",
      "5 :\n",
      "0  ->  2040\n",
      "2040\n",
      "6 :\n",
      "0  ->  2380\n",
      "2380\n",
      "7 :\n",
      "0  ->  2720\n",
      "2720\n",
      "8 :\n",
      "0  ->  3060\n",
      "3060\n",
      "9 :\n",
      "0  ->  3400\n",
      "3400\n",
      "10 :\n",
      "0  ->  3740\n",
      "3740\n",
      "11 :\n",
      "0  ->  4080\n",
      "4080\n",
      "12 :\n",
      "0  ->  4420\n",
      "4420\n",
      "13 :\n",
      "0  ->  4760\n",
      "4760\n",
      "14 :\n",
      "0  ->  5100\n",
      "5100\n",
      "15 :\n",
      "0  ->  5440\n",
      "5440\n",
      "16 :\n",
      "0  ->  5780\n",
      "5780\n",
      "17 :\n",
      "0  ->  6120\n",
      "6120\n",
      "18 :\n",
      "0  ->  6460\n",
      "6460\n",
      "19 :\n",
      "Last\n",
      "0  ->  6999\n",
      "6999\n"
     ]
    }
   ],
   "source": [
    "m = n_data_points\n",
    "n = 0\n",
    "image_sets_nc = []\n",
    "label_sets_nc = []\n",
    "\n",
    "\n",
    "for i in range((len(top_images_by_nc)//m)):\n",
    "    print(i,\":\")\n",
    "    if (i+1 >= ((len(top_images_by_nc)//m))):\n",
    "        print(\"Last\")\n",
    "        print(0,\" -> \",n+m+(len(top_images_by_nc)%m))\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m+(len(top_images_by_nc)%m)])\n",
    "    else:\n",
    "        print(0,\" -> \",m+n)\n",
    "        top_images_by_nc_n = np.array(top_images_by_nc[:n+m])\n",
    "        top_labels_by_nc_n = np.array(top_labels_by_nc[:n+m])\n",
    "    image_sets_nc.append(top_images_by_nc_n)\n",
    "    label_sets_nc.append(top_labels_by_nc_n)\n",
    "    print(len(top_images_by_nc_n))\n",
    "    n += m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a65e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/guided-retraining/models/model_fashion_2\n",
      "0 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "1 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "2 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "3 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "4 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "5 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "6 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "7 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "8 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "9 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "10 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "11 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "12 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "13 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "14 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "15 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "16 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "17 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "18 :\n",
      "Model loaded correctly\n",
      "Model compiled\n",
      "19 :\n",
      "Model loaded correctly\n",
      "Model compiled\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)\n",
    "\n",
    "models_nc = []\n",
    "for i in range(len(label_sets_nc)):\n",
    "    print(i,\":\")\n",
    "    model = utils.My_model(dataset,True,model_dir)\n",
    "    model.compile_model()\n",
    "    models_nc.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df0b6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 5s 784ms/step - loss: 1.2026 - accuracy: 0.6412 - val_loss: 0.3062 - val_accuracy: 0.8859\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 4s 819ms/step - loss: 0.9614 - accuracy: 0.7235 - val_loss: 0.3051 - val_accuracy: 0.8854\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 4s 801ms/step - loss: 0.7783 - accuracy: 0.7676 - val_loss: 0.3143 - val_accuracy: 0.8821\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.6864 - accuracy: 0.7765 - val_loss: 0.3210 - val_accuracy: 0.8804\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 5s 991ms/step - loss: 0.6753 - accuracy: 0.7941 - val_loss: 0.3565 - val_accuracy: 0.8713\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 5s 962ms/step - loss: 0.6469 - accuracy: 0.7971 - val_loss: 0.3252 - val_accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 5s 979ms/step - loss: 0.5440 - accuracy: 0.8235 - val_loss: 0.3618 - val_accuracy: 0.8686\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 5s 941ms/step - loss: 0.5279 - accuracy: 0.8382 - val_loss: 0.3700 - val_accuracy: 0.8726\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.4785 - accuracy: 0.8559 - val_loss: 0.3707 - val_accuracy: 0.8691\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 5s 971ms/step - loss: 0.5192 - accuracy: 0.8559 - val_loss: 0.3653 - val_accuracy: 0.8737\n",
      "Duration: 0:00:48.694067\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(n)\n",
    "\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f4f3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 6s 460ms/step - loss: 1.0289 - accuracy: 0.6809 - val_loss: 0.2932 - val_accuracy: 0.8861\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 5s 458ms/step - loss: 0.8271 - accuracy: 0.7441 - val_loss: 0.3064 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 5s 457ms/step - loss: 0.6385 - accuracy: 0.7838 - val_loss: 0.3212 - val_accuracy: 0.8761\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 5s 453ms/step - loss: 0.5929 - accuracy: 0.8088 - val_loss: 0.3285 - val_accuracy: 0.8751\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 5s 454ms/step - loss: 0.5776 - accuracy: 0.8147 - val_loss: 0.3351 - val_accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 5s 452ms/step - loss: 0.5214 - accuracy: 0.8279 - val_loss: 0.3610 - val_accuracy: 0.8639\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 5s 503ms/step - loss: 0.4826 - accuracy: 0.8338 - val_loss: 0.3555 - val_accuracy: 0.8679\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 5s 458ms/step - loss: 0.4316 - accuracy: 0.8500 - val_loss: 0.3393 - val_accuracy: 0.8743\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 5s 452ms/step - loss: 0.4154 - accuracy: 0.8603 - val_loss: 0.3443 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 5s 451ms/step - loss: 0.4020 - accuracy: 0.8676 - val_loss: 0.3634 - val_accuracy: 0.8708\n",
      "Duration: 0:00:47.581452\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48322beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 6s 321ms/step - loss: 0.8779 - accuracy: 0.7333 - val_loss: 0.3092 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 5s 332ms/step - loss: 0.6635 - accuracy: 0.7961 - val_loss: 0.3198 - val_accuracy: 0.8759\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.5763 - accuracy: 0.8078 - val_loss: 0.3258 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.5436 - accuracy: 0.8265 - val_loss: 0.3267 - val_accuracy: 0.8748\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 5s 325ms/step - loss: 0.5007 - accuracy: 0.8490 - val_loss: 0.3317 - val_accuracy: 0.8798\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.4573 - accuracy: 0.8480 - val_loss: 0.3504 - val_accuracy: 0.8734\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 5s 328ms/step - loss: 0.4174 - accuracy: 0.8490 - val_loss: 0.3290 - val_accuracy: 0.8780\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 5s 328ms/step - loss: 0.4056 - accuracy: 0.8735 - val_loss: 0.3372 - val_accuracy: 0.8764\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.3776 - accuracy: 0.8696 - val_loss: 0.3414 - val_accuracy: 0.8791\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.3808 - accuracy: 0.8696 - val_loss: 0.3460 - val_accuracy: 0.8806\n",
      "Duration: 0:00:50.799461\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1bdcbb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 7s 268ms/step - loss: 0.7815 - accuracy: 0.7603 - val_loss: 0.3019 - val_accuracy: 0.8878\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 5s 255ms/step - loss: 0.5741 - accuracy: 0.8051 - val_loss: 0.3229 - val_accuracy: 0.8769\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 5s 255ms/step - loss: 0.5323 - accuracy: 0.8250 - val_loss: 0.3427 - val_accuracy: 0.8671\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 5s 257ms/step - loss: 0.5060 - accuracy: 0.8331 - val_loss: 0.3364 - val_accuracy: 0.8741\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 6s 261ms/step - loss: 0.4490 - accuracy: 0.8507 - val_loss: 0.3410 - val_accuracy: 0.8742\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 5s 256ms/step - loss: 0.4283 - accuracy: 0.8500 - val_loss: 0.3501 - val_accuracy: 0.8769\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 5s 256ms/step - loss: 0.3840 - accuracy: 0.8647 - val_loss: 0.3421 - val_accuracy: 0.8701\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 0.3672 - accuracy: 0.8735 - val_loss: 0.3781 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 5s 256ms/step - loss: 0.3578 - accuracy: 0.8787 - val_loss: 0.3775 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 5s 257ms/step - loss: 0.3376 - accuracy: 0.8772 - val_loss: 0.3856 - val_accuracy: 0.8666\n",
      "Duration: 0:00:55.990971\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8d722415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 7s 232ms/step - loss: 0.7094 - accuracy: 0.7729 - val_loss: 0.3204 - val_accuracy: 0.8786\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.5403 - accuracy: 0.8229 - val_loss: 0.3303 - val_accuracy: 0.8781\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.4803 - accuracy: 0.8471 - val_loss: 0.3282 - val_accuracy: 0.8771\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 0.4393 - accuracy: 0.8488 - val_loss: 0.3412 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.4117 - accuracy: 0.8612 - val_loss: 0.3527 - val_accuracy: 0.8734\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.3707 - accuracy: 0.8694 - val_loss: 0.3449 - val_accuracy: 0.8746\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.3607 - accuracy: 0.8776 - val_loss: 0.3441 - val_accuracy: 0.8741\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 6s 231ms/step - loss: 0.3387 - accuracy: 0.8853 - val_loss: 0.3520 - val_accuracy: 0.8787\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 6s 230ms/step - loss: 0.3196 - accuracy: 0.8906 - val_loss: 0.3614 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 6s 232ms/step - loss: 0.3123 - accuracy: 0.8976 - val_loss: 0.3595 - val_accuracy: 0.8798\n",
      "Duration: 0:01:01.856825\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c53a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 0.6534 - accuracy: 0.7966 - val_loss: 0.3244 - val_accuracy: 0.8749\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 0.4749 - accuracy: 0.8544 - val_loss: 0.3338 - val_accuracy: 0.8759\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.4315 - accuracy: 0.8691 - val_loss: 0.3257 - val_accuracy: 0.8779\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.3925 - accuracy: 0.8667 - val_loss: 0.3362 - val_accuracy: 0.8759\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.3651 - accuracy: 0.8819 - val_loss: 0.3534 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 0.3437 - accuracy: 0.8863 - val_loss: 0.3526 - val_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.3195 - accuracy: 0.8882 - val_loss: 0.3659 - val_accuracy: 0.8759\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 0.2927 - accuracy: 0.8961 - val_loss: 0.3661 - val_accuracy: 0.8782\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.2755 - accuracy: 0.9088 - val_loss: 0.3678 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 0.2603 - accuracy: 0.9108 - val_loss: 0.3677 - val_accuracy: 0.8787\n",
      "Duration: 0:01:06.453597\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39c3b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 8s 185ms/step - loss: 0.6110 - accuracy: 0.8227 - val_loss: 0.3177 - val_accuracy: 0.8789\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.4464 - accuracy: 0.8584 - val_loss: 0.3254 - val_accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.3820 - accuracy: 0.8744 - val_loss: 0.3335 - val_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.3498 - accuracy: 0.8857 - val_loss: 0.3406 - val_accuracy: 0.8723\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 7s 188ms/step - loss: 0.3152 - accuracy: 0.8929 - val_loss: 0.3355 - val_accuracy: 0.8761\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.2980 - accuracy: 0.8983 - val_loss: 0.3364 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.2791 - accuracy: 0.9042 - val_loss: 0.3946 - val_accuracy: 0.8751\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 7s 186ms/step - loss: 0.2700 - accuracy: 0.9071 - val_loss: 0.3897 - val_accuracy: 0.8784\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.2597 - accuracy: 0.9122 - val_loss: 0.3579 - val_accuracy: 0.8813\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 7s 187ms/step - loss: 0.2441 - accuracy: 0.9134 - val_loss: 0.3916 - val_accuracy: 0.8801\n",
      "Duration: 0:01:10.714122\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c9be677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 8s 173ms/step - loss: 0.5758 - accuracy: 0.8254 - val_loss: 0.3074 - val_accuracy: 0.8828\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.4433 - accuracy: 0.8566 - val_loss: 0.3124 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 7s 173ms/step - loss: 0.3861 - accuracy: 0.8706 - val_loss: 0.3213 - val_accuracy: 0.8801\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 8s 186ms/step - loss: 0.3531 - accuracy: 0.8757 - val_loss: 0.3451 - val_accuracy: 0.8756\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 8s 180ms/step - loss: 0.3253 - accuracy: 0.8915 - val_loss: 0.3584 - val_accuracy: 0.8806\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 7s 172ms/step - loss: 0.3095 - accuracy: 0.8974 - val_loss: 0.3307 - val_accuracy: 0.8849\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 7s 174ms/step - loss: 0.2806 - accuracy: 0.9033 - val_loss: 0.3248 - val_accuracy: 0.8859\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.2830 - accuracy: 0.9074 - val_loss: 0.3696 - val_accuracy: 0.8799\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 9s 215ms/step - loss: 0.2579 - accuracy: 0.9151 - val_loss: 0.3690 - val_accuracy: 0.8819\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 9s 218ms/step - loss: 0.2609 - accuracy: 0.9136 - val_loss: 0.3418 - val_accuracy: 0.8860\n",
      "Duration: 0:01:19.425520\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2cb1ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 11s 197ms/step - loss: 0.5339 - accuracy: 0.8297 - val_loss: 0.3120 - val_accuracy: 0.8814\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 9s 182ms/step - loss: 0.4252 - accuracy: 0.8644 - val_loss: 0.3137 - val_accuracy: 0.8821\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 8s 176ms/step - loss: 0.3877 - accuracy: 0.8722 - val_loss: 0.3233 - val_accuracy: 0.8811\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 8s 174ms/step - loss: 0.3387 - accuracy: 0.8889 - val_loss: 0.3141 - val_accuracy: 0.8841\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 8s 173ms/step - loss: 0.3062 - accuracy: 0.9029 - val_loss: 0.3430 - val_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 8s 171ms/step - loss: 0.2960 - accuracy: 0.8993 - val_loss: 0.3292 - val_accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 8s 168ms/step - loss: 0.2756 - accuracy: 0.9105 - val_loss: 0.3373 - val_accuracy: 0.8828\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 8s 165ms/step - loss: 0.2634 - accuracy: 0.9127 - val_loss: 0.3480 - val_accuracy: 0.8835\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.2501 - accuracy: 0.9193 - val_loss: 0.3465 - val_accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 8s 163ms/step - loss: 0.2417 - accuracy: 0.9239 - val_loss: 0.3668 - val_accuracy: 0.8804\n",
      "Duration: 0:01:24.160095\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d9f1000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 9s 151ms/step - loss: 0.5194 - accuracy: 0.8376 - val_loss: 0.3125 - val_accuracy: 0.8812\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 10s 180ms/step - loss: 0.4057 - accuracy: 0.8715 - val_loss: 0.2956 - val_accuracy: 0.8919\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 9s 160ms/step - loss: 0.3567 - accuracy: 0.8812 - val_loss: 0.3408 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 8s 149ms/step - loss: 0.3378 - accuracy: 0.8906 - val_loss: 0.3236 - val_accuracy: 0.8839\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 8s 149ms/step - loss: 0.2954 - accuracy: 0.8956 - val_loss: 0.3279 - val_accuracy: 0.8845\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 8s 149ms/step - loss: 0.2782 - accuracy: 0.9056 - val_loss: 0.3271 - val_accuracy: 0.8864\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 8s 149ms/step - loss: 0.2733 - accuracy: 0.9109 - val_loss: 0.3422 - val_accuracy: 0.8834\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.2470 - accuracy: 0.9197 - val_loss: 0.3478 - val_accuracy: 0.8835\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 0.2300 - accuracy: 0.9253 - val_loss: 0.3702 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 8s 150ms/step - loss: 0.2026 - accuracy: 0.9321 - val_loss: 0.4344 - val_accuracy: 0.8786\n",
      "Duration: 0:01:22.970015\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e1cc3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 9s 146ms/step - loss: 0.5287 - accuracy: 0.8361 - val_loss: 0.2996 - val_accuracy: 0.8882\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 9s 146ms/step - loss: 0.4182 - accuracy: 0.8623 - val_loss: 0.2946 - val_accuracy: 0.8869\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.3545 - accuracy: 0.8834 - val_loss: 0.3075 - val_accuracy: 0.8894\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.3359 - accuracy: 0.8874 - val_loss: 0.3092 - val_accuracy: 0.8856\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 8s 143ms/step - loss: 0.3165 - accuracy: 0.8939 - val_loss: 0.2918 - val_accuracy: 0.8900\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 8s 142ms/step - loss: 0.2933 - accuracy: 0.9008 - val_loss: 0.3336 - val_accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 8s 142ms/step - loss: 0.2702 - accuracy: 0.9070 - val_loss: 0.3142 - val_accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 8s 145ms/step - loss: 0.2607 - accuracy: 0.9171 - val_loss: 0.3440 - val_accuracy: 0.8851\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 8s 144ms/step - loss: 0.2401 - accuracy: 0.9201 - val_loss: 0.3391 - val_accuracy: 0.8882\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 8s 144ms/step - loss: 0.2227 - accuracy: 0.9238 - val_loss: 0.3424 - val_accuracy: 0.8884\n",
      "Duration: 0:01:25.064023\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e17d50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 10s 138ms/step - loss: 0.4959 - accuracy: 0.8417 - val_loss: 0.3099 - val_accuracy: 0.8813\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 9s 140ms/step - loss: 0.3828 - accuracy: 0.8728 - val_loss: 0.2862 - val_accuracy: 0.8861\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.3495 - accuracy: 0.8848 - val_loss: 0.2970 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 9s 138ms/step - loss: 0.3251 - accuracy: 0.8939 - val_loss: 0.2944 - val_accuracy: 0.8877\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.3035 - accuracy: 0.9037 - val_loss: 0.3106 - val_accuracy: 0.8874\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 9s 137ms/step - loss: 0.2804 - accuracy: 0.9108 - val_loss: 0.3104 - val_accuracy: 0.8867\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.2543 - accuracy: 0.9174 - val_loss: 0.3231 - val_accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 9s 139ms/step - loss: 0.2446 - accuracy: 0.9201 - val_loss: 0.3279 - val_accuracy: 0.8784\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 9s 138ms/step - loss: 0.2439 - accuracy: 0.9194 - val_loss: 0.3294 - val_accuracy: 0.8892\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 9s 139ms/step - loss: 0.2154 - accuracy: 0.9328 - val_loss: 0.3402 - val_accuracy: 0.8846\n",
      "Duration: 0:01:29.492231\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f12f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 10s 133ms/step - loss: 0.4833 - accuracy: 0.8423 - val_loss: 0.2963 - val_accuracy: 0.8859\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.3741 - accuracy: 0.8688 - val_loss: 0.3125 - val_accuracy: 0.8819\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.3420 - accuracy: 0.8921 - val_loss: 0.3054 - val_accuracy: 0.8869\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.3158 - accuracy: 0.8989 - val_loss: 0.3168 - val_accuracy: 0.8851\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 9s 133ms/step - loss: 0.2906 - accuracy: 0.9045 - val_loss: 0.3167 - val_accuracy: 0.8849\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.2774 - accuracy: 0.9070 - val_loss: 0.2988 - val_accuracy: 0.8891\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.2482 - accuracy: 0.9188 - val_loss: 0.3315 - val_accuracy: 0.8896\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 9s 136ms/step - loss: 0.2399 - accuracy: 0.9235 - val_loss: 0.3288 - val_accuracy: 0.8863\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 9s 135ms/step - loss: 0.2115 - accuracy: 0.9319 - val_loss: 0.3711 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.2053 - accuracy: 0.9348 - val_loss: 0.3439 - val_accuracy: 0.8843\n",
      "Duration: 0:01:34.150908\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8438733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 10s 128ms/step - loss: 0.4972 - accuracy: 0.8433 - val_loss: 0.2963 - val_accuracy: 0.8822\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.3674 - accuracy: 0.8805 - val_loss: 0.2988 - val_accuracy: 0.8844\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 10s 129ms/step - loss: 0.3502 - accuracy: 0.8878 - val_loss: 0.2893 - val_accuracy: 0.8917\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.3021 - accuracy: 0.8983 - val_loss: 0.3170 - val_accuracy: 0.8839\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.2788 - accuracy: 0.9088 - val_loss: 0.3149 - val_accuracy: 0.8855\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.2674 - accuracy: 0.9105 - val_loss: 0.3185 - val_accuracy: 0.8859\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.2494 - accuracy: 0.9179 - val_loss: 0.3236 - val_accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.2122 - accuracy: 0.9296 - val_loss: 0.3444 - val_accuracy: 0.8889\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 10s 130ms/step - loss: 0.2186 - accuracy: 0.9300 - val_loss: 0.3387 - val_accuracy: 0.8876\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 10s 131ms/step - loss: 0.2055 - accuracy: 0.9366 - val_loss: 0.3574 - val_accuracy: 0.8890\n",
      "Duration: 0:01:37.993818\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "87e95b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 11s 124ms/step - loss: 0.4921 - accuracy: 0.8445 - val_loss: 0.3000 - val_accuracy: 0.8866\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 0.3789 - accuracy: 0.8725 - val_loss: 0.2950 - val_accuracy: 0.8879\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.3454 - accuracy: 0.8825 - val_loss: 0.2890 - val_accuracy: 0.8897\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 0.3145 - accuracy: 0.8906 - val_loss: 0.2968 - val_accuracy: 0.8896\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.2884 - accuracy: 0.9029 - val_loss: 0.3016 - val_accuracy: 0.8917\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.2732 - accuracy: 0.9076 - val_loss: 0.3164 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 0.2533 - accuracy: 0.9176 - val_loss: 0.3019 - val_accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 10s 130ms/step - loss: 0.2244 - accuracy: 0.9255 - val_loss: 0.3503 - val_accuracy: 0.8821\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 0.2244 - accuracy: 0.9278 - val_loss: 0.3056 - val_accuracy: 0.8931\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 10s 125ms/step - loss: 0.2138 - accuracy: 0.9284 - val_loss: 0.3375 - val_accuracy: 0.8941\n",
      "Duration: 0:01:42.456670\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43b1e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Epoch 1/10\n",
      "85/85 [==============================] - 11s 123ms/step - loss: 0.4680 - accuracy: 0.8436 - val_loss: 0.2869 - val_accuracy: 0.8922\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 10s 124ms/step - loss: 0.3828 - accuracy: 0.8765 - val_loss: 0.2853 - val_accuracy: 0.8917\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.3441 - accuracy: 0.8864 - val_loss: 0.3068 - val_accuracy: 0.8861\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.3066 - accuracy: 0.8919 - val_loss: 0.3233 - val_accuracy: 0.8910\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 10s 121ms/step - loss: 0.2890 - accuracy: 0.9006 - val_loss: 0.3056 - val_accuracy: 0.8904\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.2704 - accuracy: 0.9134 - val_loss: 0.2974 - val_accuracy: 0.8934\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 10s 124ms/step - loss: 0.2504 - accuracy: 0.9154 - val_loss: 0.3319 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 10s 120ms/step - loss: 0.2404 - accuracy: 0.9213 - val_loss: 0.3009 - val_accuracy: 0.8917\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 10s 121ms/step - loss: 0.2168 - accuracy: 0.9289 - val_loss: 0.3288 - val_accuracy: 0.8947\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.2076 - accuracy: 0.9340 - val_loss: 0.3413 - val_accuracy: 0.8952\n",
      "Duration: 0:01:44.153759\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7de153f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/10\n",
      "91/91 [==============================] - 12s 121ms/step - loss: 0.4930 - accuracy: 0.8343 - val_loss: 0.2826 - val_accuracy: 0.8916\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.3861 - accuracy: 0.8656 - val_loss: 0.2813 - val_accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 11s 122ms/step - loss: 0.3633 - accuracy: 0.8780 - val_loss: 0.2931 - val_accuracy: 0.8932\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.3234 - accuracy: 0.8860 - val_loss: 0.2896 - val_accuracy: 0.8939\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.2995 - accuracy: 0.8983 - val_loss: 0.2976 - val_accuracy: 0.8969\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.2871 - accuracy: 0.9054 - val_loss: 0.3167 - val_accuracy: 0.8912\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 11s 122ms/step - loss: 0.2671 - accuracy: 0.9121 - val_loss: 0.3068 - val_accuracy: 0.8944\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 11s 121ms/step - loss: 0.2517 - accuracy: 0.9202 - val_loss: 0.3284 - val_accuracy: 0.8979\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 11s 122ms/step - loss: 0.2294 - accuracy: 0.9282 - val_loss: 0.3181 - val_accuracy: 0.8964\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 11s 122ms/step - loss: 0.2157 - accuracy: 0.9311 - val_loss: 0.3440 - val_accuracy: 0.8959\n",
      "Duration: 0:01:50.878062\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "814d3a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 12s 120ms/step - loss: 0.5223 - accuracy: 0.8242 - val_loss: 0.2856 - val_accuracy: 0.8888\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.3996 - accuracy: 0.8636 - val_loss: 0.2836 - val_accuracy: 0.8919\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 12s 121ms/step - loss: 0.3770 - accuracy: 0.8708 - val_loss: 0.2845 - val_accuracy: 0.8926\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 11s 120ms/step - loss: 0.3494 - accuracy: 0.8802 - val_loss: 0.3031 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.3122 - accuracy: 0.8938 - val_loss: 0.2950 - val_accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 12s 123ms/step - loss: 0.2835 - accuracy: 0.9015 - val_loss: 0.3047 - val_accuracy: 0.8945\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 11s 115ms/step - loss: 0.2690 - accuracy: 0.9083 - val_loss: 0.3236 - val_accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 11s 119ms/step - loss: 0.2652 - accuracy: 0.9167 - val_loss: 0.3040 - val_accuracy: 0.8979\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.2456 - accuracy: 0.9239 - val_loss: 0.3190 - val_accuracy: 0.8957\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 11s 116ms/step - loss: 0.2181 - accuracy: 0.9261 - val_loss: 0.3170 - val_accuracy: 0.8966\n",
      "Duration: 0:01:54.556014\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5db2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 13s 117ms/step - loss: 0.5424 - accuracy: 0.8116 - val_loss: 0.2820 - val_accuracy: 0.8951\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 0.4285 - accuracy: 0.8511 - val_loss: 0.2774 - val_accuracy: 0.8961\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 12s 118ms/step - loss: 0.3865 - accuracy: 0.8625 - val_loss: 0.2842 - val_accuracy: 0.8941\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 12s 118ms/step - loss: 0.3507 - accuracy: 0.8763 - val_loss: 0.2794 - val_accuracy: 0.8997\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 12s 117ms/step - loss: 0.3359 - accuracy: 0.8845 - val_loss: 0.2883 - val_accuracy: 0.8965\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 0.3007 - accuracy: 0.8958 - val_loss: 0.3086 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 0.2938 - accuracy: 0.8983 - val_loss: 0.2851 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 0.2598 - accuracy: 0.9098 - val_loss: 0.3047 - val_accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 12s 117ms/step - loss: 0.2491 - accuracy: 0.9176 - val_loss: 0.3080 - val_accuracy: 0.9011\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 12s 117ms/step - loss: 0.2234 - accuracy: 0.9226 - val_loss: 0.3318 - val_accuracy: 0.9032\n",
      "Duration: 0:01:58.439324\n"
     ]
    }
   ],
   "source": [
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5b7e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 13s 113ms/step - loss: 0.5562 - accuracy: 0.8055 - val_loss: 0.2834 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.4476 - accuracy: 0.8364 - val_loss: 0.2711 - val_accuracy: 0.8997\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.4114 - accuracy: 0.8544 - val_loss: 0.2884 - val_accuracy: 0.8974\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 0.3829 - accuracy: 0.8654 - val_loss: 0.2840 - val_accuracy: 0.9001\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 12s 114ms/step - loss: 0.3488 - accuracy: 0.8758 - val_loss: 0.2967 - val_accuracy: 0.8961\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 0.3344 - accuracy: 0.8847 - val_loss: 0.2898 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 0.3067 - accuracy: 0.8976 - val_loss: 0.2933 - val_accuracy: 0.8980\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 0.2773 - accuracy: 0.9077 - val_loss: 0.3171 - val_accuracy: 0.8865\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 12s 112ms/step - loss: 0.2610 - accuracy: 0.9118 - val_loss: 0.3468 - val_accuracy: 0.8944\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 13s 115ms/step - loss: 0.2554 - accuracy: 0.9178 - val_loss: 0.2994 - val_accuracy: 0.9009\n",
      "Duration: 0:02:05.416623\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(n)\n",
    "models_nc[n].fit_model(image_sets_nc[n],label_sets_nc[n],x_val,y_val)\n",
    "n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43bd398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_0\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_1\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_2\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_3\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_4\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_5\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_6\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_7\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_8\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_9\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_10\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_11\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_12\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_13\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_14\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_15\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_16\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_17\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_18\\assets\n",
      "Model has been saved\n",
      "INFO:tensorflow:Assets written to: D:/models/aug_22/fashion/C3/fashion_model_c3_aug_nc_e1_19\\assets\n",
      "Model has been saved\n"
     ]
    }
   ],
   "source": [
    "#new_model_nc_dir  = \"C:/Users/fjdurlop/Documents/upc/models/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_nc_e1\"\n",
    "new_model_nc_dir  = \"D:/models/aug_22/\"+dataset+\"/C3/\"+dataset+\"_model_c3_aug_nc_e1\"\n",
    "i=0\n",
    "\n",
    "for model in models_nc:\n",
    "    model.save(new_model_nc_dir+\"_\"+str(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47e2faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del nc_values\n",
    "    del top_images_by_nc\n",
    "    del top_labels_by_nc\n",
    "    del image_sets_nc\n",
    "    del label_sets_nc\n",
    "    del models_nc\n",
    "except:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98f93725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372064"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f769ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
